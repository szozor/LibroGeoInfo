\seccion{Leyes condicionales}
\label{Sec:MP:LeyesCondicionales}

Al  considerar un  par de  vectores aleatorios  \ $X$  \ e  \ $Y$,  una pregunta
natural puede ser  c\'omo caracterizar el vector $Y$ si  ``observamos $X = x$''.
En otras palabras,  la pregunta es describir la ley  de $Y$ ``sabiendo \modif{(o
  observando)}  que  $X  =  x$''.   En  lo que  sigue,  para  fijar  notaci\'on,
consideramos $(X,Y): (  \Omega , \A) \mapsto (\Rset^{d_X}  \! \times \Rset^{d_Y}
\,   ,  \,  \B(\Rset^{d_X}   \!   \times   \Rset^{d_Y})  )$   tal  que   $X$  es
$d_X$-dimensional   e   $Y$   es   $d_Y$-dimensional   (incluyendo   los   casos
escalares).  \modif{Escribiremos  de nuevo  \  $\X  = X(\Omega)$  \  e  \ $\Y  =
  Y(\Omega)$.}


% ---------- Caso discreto

\paragraph{Caso $\boldsymbol{X}$ discreta:}
Un caso  sencillo a estudiar  es cuando \  \modif{$\X$} \ es discreto.   En este
caso, para  cualquier $x  \in \X$, tenemos  $P_X(x) = P(X  = x)  \ne 0$ y  de la
definici\'on de  la probabilidad condicional Def.~\ref{Def:MP:ProbaCondicional},
\modif{$\displaystyle \forall \: B \in \B(\Rset^{d_Y}), \quad P(Y \in B | X = x)
  = \frac{P\big(  (Y \in B) \cap (X  = x) \big)}{P(X=x)}$} define  una medida de
probabilidad que llamamos medida de probabilidad condicional.  Siendo una medida
de  probabilidad, nos  referimos a  la  subsecci\'on anterior  para definir  una
funci\'on  de  repartici\'on tomando  $\displaystyle  \modif{B} =  \prod_{i=1}^d
(-\infty \; y_i]$, caracterizando completamente la medida de probabilidad:
%
\begin{definicion}[Medida de probabilidad y funci\'on de repartici\'on condicional ($X$ discreto)]
\label{Def:MP:ReparticionCondicionalDiscreta}
%
  \modif{Por   cualquier   $x  \in   \X$,   la   medida   condicional  de   $Y$,
    condicionalmente a $(X = x)$, se define por
    %
    \[
    \forall \: B \in \B\left( \Rset^{d_X} \right), \qquad P_{Y|X=x}(B) = P(Y \in
    B | X = x),
    \]
}
  %
  y la funci\'on de repartici\'on condicional \modif{se define por},
  %
  \[
  \forall \:  x \in  \X, \: y  \in \Y, \qquad  F_{Y|X=x}(y) =  P( \left. Y  \le y
  \right| X = x ) = \frac{P\left(  \left(Y \le y \right) \cap \left(X = x\right)
    \right)}{P\left(X = x\right)}.
  \]
\end{definicion}

Ahora, cuando  \ $Y$ \ tambi\'en es  discreta, se puede definir  la funci\'on de
masa discreta de probabilidad condicional, y si \ $Y$ \ es continua y admite una
densidad  de  probabilidad,  se  puede  definir  una  densidad  de  probabilidad
condicional:
%
\begin{definicion}[Funci\'on de masa o densidad de probabilidad condicional ($X$
  discreta)]
\label{Def:MP:ReparticionCondicionalDiscreta}
%
  Por  definici\'on,  cuando  $\Y$  es   discreta,  la  funci\'on  de  masa  de
  probabilidad condicional \modif{de $Y$ condicionalmente a $X = x$} es,
  %
  \[
  \forall \: x \in \X, \: y \in \Y, \quad p_{Y|X=x}(y) = P\left( \left. Y = y \right|
  X  =  x \right)  =  \frac{P\big(  (Y  = y)  \cap  (X =  x) \big)}{P(X = x)}.
  \]
  %
  Si  \ $Y$  \  es continua,  es sencillo  ver  que $P_{Y|X=x}  \ll P_Y$,  i.e.,
  \modif{para  $B   \in  \B(\Rset^{d_Y})$,  $P_Y(B)   =  0  \:   \Rightarrow  \:
    P_{Y|X=x}(B) = 0$.}   Si $Y$ admite una densidad con respecto  a la medida de
    Lebesgue,  $P_Y  \ll \mu_L$  medida  de  Lebesgue,  es claro  que  tambi\'en
    $P_{Y|X=x}       \ll       \mu_L$,        y       por       teorema       de
    Radon-Nikod\'ym~\ref{Teo:MP:RadonNikodym},  $P_{Y|X=x}$ admite  una densidad
    de  probabilidad (con  respecto a  la  medida de  Lebesgue) que  denotaremos
    $p_{Y|X=x}$,
  %
  \[
  \forall  \:  B  \modif{\in   \B(\Rset^{d_Y})},  \quad  P_{Y|X=x}(B)  =  \int_B
  p_{Y|X=x}(y) \, dy.
  \]
  %
  A partir de la funci\'on de repartici\'on, obtenemos
  %
  \[
  p_{Y|X=x}(y) = \frac{\partial^{d_Y} F_{Y|X=x}(y)}{\partial y_1 \ldots \partial
    y_{d_Y}}.
  \]
\end{definicion}


% ---------- Caso continuo

\paragraph{\modif{Caso general:}}
Cuando  $X$  es   continua,  el  problema  es  m\'as   sutil  porque  $P(X=x)  =
0$. Entonces, no  se puede usar la definici\'on  de la probabilidad condicional,
siendo el  evento $(X=x)$ de probabilidad  nula.  Sin embargo,  se pueden seguir
los pasos de R\'enyi~\cite[Cap.~5]{Ren07}, de Feller~\cite[Cap.~10]{Fel71} o Ash
\&  Dol{\'e}ans-Dade~\cite[Sec.~5.3]{AshDol99}  por  ejemplo  para  resolver  el
problema, llegando \modif{en el contexto continuo} a un resultado intuitivo como
en el caso discreto.

\modif{Sea  \ $B  \in \B(\Rset^{d_Y})$  \  tal que  \ $P(Y  \in  B) \ne  0$ \  y
  definimos \  $\nu_B(A) = P\big(  \left( X  \in A \right)  \cap \left( Y  \in B
  \right)   \big)$  sobre   $\left(   \Rset^{d_X}  ,
    \B(\Rset^{d_X})  \right)$.  Es  sencillo ver  que siendo  dado  $B$, $\nu_B$
  define  una medida}.  Adem\'as,  $\nu_B  \ll P_X$,  i.e.,  \modif{para $A  \in
  \B(\Rset^{d_X})$,} $P_X(A) =  P(X \in A) =  0 \: \Rightarrow \: 0  = P\Big( (X
\in   A)   \cap    (Y   \in   B)   \Big)   =    \nu_B(A)$.    Por   teorema   de
Radon-Nikod\'ym~\ref{Teo:MP:RadonNikodym},   $\nu_B$  admite   una   densidad  \
\modif{$g_B = \frac{d \nu_B}{d P_X}$} \ con respecto a $P_X$,
%
\[
\forall \:  A \in \B\left( \Rset^{d_X} \right),  \quad P\big( (X \in  A) \cap (Y
\in B) \big) = \int_A g_B(x) \, dP_X(x).
\]
%
Claramente \ $g_B \ge 0$, \ y de \ \modif{$P(X \in A) = P\big( (X \in A) \cap (Y
  \in B)  \big) +  P\big( (X \in  A) \cap  (Y \in \overline{B}  ) \big)$  \ para
  cualquier  $A \in  \B\left(  \Rset^{d_X} \right)$,  se escribe  $\displaystyle
  \forall \:  A \in \B\left( \Rset^{d_X} \right),  \quad 0 \le P\big(  (X \in A)
  \cap (Y \in \overline{B}) \big) =  \int_A dP_X(x) - \int_A g_B(x) \, dP_X(x)$,
  lo  que permite  concluire que}  \ $0  \le g_B  \le 1$.   \modif{Con  el mismo
  razonamiento,  se puede ver  que $g_B(\Rset^{d_Y})  = 1$  y que  \ $g_B$  \ es
  $\sigma$-aditiva.} En realidad, $g_B \le 1$ $P_X$-casi siempre, pero olvidando
esta subtilesa,  \modif{$g_B$ define una medida de  probabilidad, que llamaremos
  {\it medida  de probabilidad condicional}.   Por continuaci\'on se  define una
  funci\'on de repartici\'on  condicional de la misma manera  que se defin\'o la
  funci\'on de repartici\'on. En resumen:}
%
\begin{definicion}[Medida   de  probabilidad   y   funci\'on  de   repartici\'on
  condicional]
\label{Def:MP:MedidaCondicional}
%
  La medida de probabilidad condicional de $P_{Y|X=x}$ es definida tal que
  %
  \[
  \forall \: (A,B) \in  \B\left( \Rset^{d_X} \right) \times \B\left( \Rset^{d_Y}
  \right), \quad P\big( (X \in A) \cap  (Y \in B) \big) = \int_A P_{Y|X=x}(B) \,
  dP_X(x).
  \]
  %
  Tomando $B = \optimes_i \left( -\infty \; y_i \right]$ se obtiene la funci\'on
  de repartici\'on condicional a partir de
  %
  \[
  \forall \:  A \in  \B\left( \Rset^{d_X} \right),  \: y \in  \Y, \quad
  P\big( (X \in A) \cap (Y \le y) \big) = \int_A F_{Y|X=x}(y) \, dP_X(x).
  \]
  %
  Ad\'emas, si $X$ admite una densidad  de probabilidad $p_X$, $dP_X = p_X dx$ y
  tomando $A = \optimes_i (-\infty \; x_i]$ se obtiene
  %
  \[
  F_{X,Y}(x,y) = \int_{\optimes_i (-\infty \; x_i]} F_{Y|X=x}(y) \, p_X(x)
  \, dx
  \]
  %
  o, por diferenciaci\'on, para  cualquier $y \in \Y$ \modif{\ y \  $x \in \X$ \
    (\ie tal que \ $p_X(x) \ne 0$)},
  %
  \[
  F_{Y|X=x}(y)         =        \frac{\displaystyle        \frac{\partial^{d_X}
      F_{X,Y}(x,y)}{\partial x_1 \ldots \partial x_{d_X}}}{p_X(x)}.
  \]
\end{definicion}
%
\modif{ Claramente,  $\left( \Rset^{d_Y} , \B(\Rset^{d_Y})  , P_{Y|X=x} \right)$
  define  un  espacio  de probabilidad  y,  a  veces,  por abuso  de  escritura,
  denotaremos $Y|X=x$  la variable aleatoria $(\Omega,\A,P) \to  \left( \Rset^{d_Y} ,
  \B(\Rset^{d_Y}) , P_{Y|X=x} \right)$.

\

  En el  contexto de  variable aleatorias  independientes, intuitivamente
  conocer a $X$ no va a  llevar ``informaci\'on'' sobre $Y$, lo que se formaliza
  de la manera siguiente:
%
\begin{lema}[Probabilidad condicional e independencia]
\label{Lem:MP:MedidaCondicionalIndependencia}
%
  Sean \ $X$ \ e \ $Y$ \ vectores aleatorios independientes, entonces
%
  \[
  \forall \: x \in \X, \: B \in \B(\Rset^{d_Y}), \quad P_{Y|X=x}(B) = P_Y(B)
  \]
  %
  A continuaci\'on, obviamente,
  %
  \[
  F_{Y|X=x}(y) = F_Y(y)
  \]
\end{lema}
\begin{proof}
  Inmediatamente, de la independencia, tenemos
  %
  \begin{eqnarray*}
  P\big( ( X \in A) \cap (Y \in B) \big) & = &  P(X \in A) \, P(Y \in B)\\
  %
  & = & P_Y(B) \, \int_A dP_X(x)\\
  %
  & = & \int_A  P_Y(B) \, dP_X(x)
  \end{eqnarray*}
  %
  lo que cierra la prueba.
\end{proof}

Ahora,  tomando  $A  = \X$ en  la  primera  f\'ormula  que  define la  medida  de
probabilidad condicional se recupera el  equivalente continuo de la f\'ormula de
probabilidad total:
%
\begin{teorema}[F\'ormula de probabilidad total (caso general)]
\label{Teo:MP:ProbaTotalGeneral}
%
  Sean \  $X$ \  e \ $Y$  \ vectores aleatorias  y $\X  = X(\Omega), \quad  \Y =
  Y(\Omega)$. Entonces
  %
  \[
  \forall \  B \in  \B\left( \Rset^{d_Y}  \right), \qquad P(Y  \in B)  = \int_\X
  P_{Y|X=x}(B) \, dP_X(x)
  \]
  %
  lo que da en termino de funci\'on de repartici\'on condicional
  %
  \[
  F_Y(y) = \int_\X F_{Y|X=x}(y) \, dP_X(x)
  \]
  %
  Si $P_X$  admite una densidad, se  escribe todo notando que  $dP_X(x) = p_X(x)
  d\mu_L(x) \equiv p_X(x) dx$.
\end{teorema}
}

Por \'ultimo, si $(X,Y)$ admite una densidad, en sencillo ver que $P_{Y|X=x} \ll
\mu_L$,  y entonces  \ $P_{Y|X=x}$  \ admite  una densidad  que  llamaremos {\it
  densidad  de  probabilidad  condicional}.  Sean $A  \in  \B\left(  \Rset^{d_X}
\right)$ y $B \in \B\left( \Rset^{d_Y} \right)$,
%
\begin{eqnarray*}
P\Big( (X \in A) \cap (Y \in B) \Big) & = & \int_{A \times B} p_{X,Y}(x,y) \, dx
\, dy\\[2mm]
%
& = & \int_B \left( \int_A \frac{p_{X,Y}(x,y)}{p_X(x)} \, dy \right) p_X(x) \, dx
\end{eqnarray*}
%
Entonces, si $p_X(x) \ne 0$, tenemos
%
\[
P_{Y|X=x}(A) = \int_A \frac{p_{X,Y}(x,y)}{p_X(x)} \, dy.
\]
%
\begin{teorema}[Densidad de probabilidad condicional]
\label{Def:MP:DensidadCondicional}
%
  Si  $(X,Y)$ admite  una densidad  de probabilidad,  la medida  de probabilidad
  condicional  $P_{Y|X=x}$  admite  una   densidad,  llamada  {\it  densidad  de
    probabilidad condicional} definida por
  %
  \[
  \forall \: x \in \X, \quad p_{Y|X=x}(y) = \frac{p_{X,Y}(x,y)}{p_X(x)}
  \]
  %
  definida  sobre $\Y$. Claramente,  a partir de  la funci\'on  de repartici\'on
  condicional resulta que
  %
  \[
  p_{Y|X=x} = \frac{\partial^{d_Y}  F_{Y|X=x}}{\partial y_1 \ldots \partial y_{d_Y}}.
  \]
\end{teorema}

De hecho, esta  construcci\'on rigurosa coincide con la  intuici\'on que podemos
tener en este  caso continuo. Por ejemplo, podemos  pensar a $F_{Y|X=x}(y)$ como
caso l\'imite de $\displaystyle P\left( Y \le y \: \Big| \: x \le X \le x+\delta
  x \right) = \frac{P\big( \left( Y \le y  \right) \: \cap \: \left( x \le X \le
    x+\delta  x  \right)  \big)}{P\left( x  \le  X  \le  x+\delta x  \right)}  =
\frac{F_{X,Y}(x+\delta  x ,  y) -  F_{X,Y}(x  , y)}{F_X(x+\delta  x) -  F_X(x)}$
cuando \ $\delta  x$ \ tiende a 0.   En el caso escalar, se  calcula por ejemplo
haciendo un  desarrollo de Taylor del numerador  y del denominador a  orden 1, o
usando la regla de l'H\^opital~\footnote{De hecho, esta regla es debido al suizo
  J.  Bernoulli  que tuvo  un acuerdo financiero  con el  Guillaume Fran\c{c}ois
  Antoine, marqu\'es  de l'H\^opital, permitiendolo de  publicar unos resultados
  de Bernoulli bajo  su nombre.}  para re-obtener la  funci\'on de repartici\'on
condicional   de  la   definici\'on~\ref{Def:MP:FRCondicional}.    En  el   caso
multivariado,  hace  falta  hacer  los  desarollos hasta  el  orden  $d_X$  para
concluir.

Notar  que:
%
\begin{itemize}
\item si $X$ e $Y$ son independientes,
  %
  \[
  p_{Y|X=x} = p_Y;
  \]
%
\item por  la expresi\'on \ $p_{Y|X=x}(y) =  \frac{p_{X,Y}(x,y)}{p_X(x)}$, \ por
  integraci\'on con respecto a $y$ obtenemos la condici\'on de normalizaci\'on
  %
  \[
  \int_{\modif{\Y}} p_{Y|X=x}(y) \, dy = 1.
  \]
  %
\end{itemize}

\modif{Tambi\'en, se  escribe la f\'ormula  de probabilidad total a  trav\'es de
  las densidades por la expresi\'on  \ $p_{X,Y}(x,y) = p_{Y|X=x}(y) \, p_X(x)$ \
  y luego por integraci\'on con respecto a $x$:
%
\begin{teorema}[F\'ormula de probabilidad total (caso con densidades)]
\label{Teo:MP:ProbaTotalContinuo}
%
  Si  \  $(X,Y)$ \  admite  una  densidad  de probabilidad  conjunta  $p_{X,Y}$,
  entonces \ $Y$ \ tiene una  densidad de probabilida que se recupera a trav\'es
  de la f\'ormula
  %
  \[
  p_Y(y) = \int_\X p_{Y|X=x}(y) \, p_X(x) \, dx.
  \]
\end{teorema}

De  la expresi\'on  la  densidad condicional,  $p_{X,Y}(x,y)  = p_{Y|X=x}(y)  \,
p_X(x) =  p_{X|Y=y}(x) \, p_Y(y)$,  y de la  f\'ormula de probabilidad  total se
recupera sencillamente el equivalente continuo de la formula de Bay\'es:
%
\begin{teorema}[F\'ormula de Bayes (caso continuo)]\label{Teo:MP:BayesContinuo}
%
%  Sean  \ $X$  \ e  \ $Y$  \  vectores aleatorias  que admiten  una densidad  de
%  probabilidad  conjunta   $p_{X,Y}$,  y   \  $\X  =   X(\Omega),  \quad   \Y  =
%  Y(\Omega)$. Entonces
  %
  \[
  \forall \, y \in \Y\modif{, \:  x \in \X,} \qquad p_{Y|X=x}(y) = \frac{p_{X|Y=y}(x) \,
    p_Y(y)}{\displaystyle \int_\Y p_{X|Y=y}(x) \, p_Y(y) \, dy}.
  \]
\end{teorema}
}

Volvemos \modif{ahora} al ejemplo~\ref{Ej:MP:Suma}:
%, pagina~\pageref{Ej:MP:Suma}:
%
\begin{ejemplo}[Distribuci\'on condicional de la suma de vectores aleatorios]
\label{Ej:MP:SumaCond}
%
  Sea   \   $V  =   X   +   Y$,  \   con   \   $X$  \   e   \   $Y$  \   vectores
  $d$-dimensionales.  Introduciendo \  $U =  X$  \ obtuvimos  \ $p_{U,V}(u,v)  =
  p_{X,Y}(u,v-u)$  \ dando  tambi\'en \  $\displaystyle p_V(v)  = \int_{\Rset^d}
  p_{X,Y}(u,v-u) \, du$. Entonces, recordando que $U = X$, se obtiene
  %
  \[
  p_{V|X=x}(v)            =            \frac{p_{X,Y}(x,v-x)}{p_X(x)}           =
  \frac{p_{X,Y}(x,v-x)}{\displaystyle \int_{\Rset^d} p_{X,Y}(x,v-x) \, dv},
  \]
  %
  dando en el caso \ $X$ \ e \ $Y$ \ independientes
  %
  \[
  p_{V|X=x}(v) = p_Y(v-x).
  \]
  %
  Esto corresponde a la  intuci\'on de que, con $V = X + Y$,  fijando $X = x$ el
  vector aleatorio  $V$ es nada  m\'as que $Y$  desplazado en $x$. Pero  hay que
  tomar muchas precauciones con  este razonamiento, valido \'unicamente cuando \
  $X$  \ e  \  $Y$ \  son independientes.   En  caso contrario,  fijando $X$  no
  coincide con un desplazamiento por la dependencia (esquemat\'icamente, fijando
  $X$ no s\'olo mueve \ $Y$ \ sino que ``cambia'' su estad\'istica).
\end{ejemplo}
