\seccion{Probabilidades}
\label{s:MP:Probabilidad}

El  concepto  de  {\it  probabilidad}  es importante  en  situaciones  donde  el
resultado (o {\it outcome}) de un  dado proceso o medici\'on es incierto, cuando
la salida de una experiencia no  es totalmente previsible. La probabilidad de un
evento es una medida que se asocia con cu\'an probable es el evento o resultado.

Una  definici\'on de  probabilidad puede  obtenerse en  base a  la enumeraci\'on
exhaustiva de los resultados posibles de un experimento o proceso,
%lo que no siempre es factible
suponiendo que el conjunto de posibilidades es completo en el sentido de que una
de  ellas debe ser  verdad. Si  el proceso  tiene $K$  resultados distinguibles,
mutuamente  excluyentes e  igualmente probables  (esto  es, no  se prefiere  una
posibilidad frente a  otras), y si $k$  de esos $K$ tienen un  dado atributo, la
probabilidad asociada a dicho atributo en un dado procesos es $\frac{k}{K}$. Por
ejemplo, sorteando un n\'umero entre los  naturales del 1 al 10, la probabilidad
de ``obtener un n\'umero par'' es $\frac5{10} = \frac12$.

Otra  definici\'on  de  probabilidad  se  basa  en  la  frecuencia  relativa  de
ocurrencia  de  un evento.   Si  en  una cantidad  $K$  muy  grande de  procesos
independientes  cierto   atributo  aparece  $k$   veces,  se  identifica   a  la
probabilidad  asociada a  un  proceso o  ensayo  con la  frecuencia relativa  de
ocurrencia    $\frac{k}{K}$    del    atributo~\cite[\&   Ref.]{Bra76,    Hal90,
  ShaVov06}~\footnote{A pesar de que la  noci\'on de azar (viniendo del arabe) o
  de  alea  (en  latin)  es   muy  antiguo,  el  italiano  Gerolamo  Cardano  es
  ``probablemente'' un de los  primeros tratando matematicamente del concepto de
  probabilidad en el siglo XVI, escribiando un libro sobre los juegos de azar en
  1564~\cite{Bel05}  o~\cite[Cap.~4]{Hal90}.   Entre  los numerosos  matematicos
  desarollando  la teoria  de las  probabildades, (en  particular  los franceses
  Pierre de  Fermat y Blaise  Pascal~\cite[Cap.~5]{Hal90}) hay que  mencionar el
  suizo  Jacob Bernoulli  y el  franc\'es Abraham  de Moivre,  quizas un  de los
  primeros  llevandos un  aporte importante  al desarollo  de la  teoria  de las
  probabilidades  en  el  siglo  XVIII   a  trav\'es  de  este  punto  de  vista
  ``frequencista''  y combinatorial~\cite[en  latin]{Ber1713} o~\cite{Ber1713:2,
    Dem56} y~\cite[Cap.~13, 15 \&~22]{Hal90}.}.
%lim N->infty n/N indef.

Los axiomas de Kolmogorov~\footnote{Un paso importante es debido a Kolmogorov en
  1933  que  se apoy\'o  sobre  trabajos  de  Richard von  Mises~\cite{Mis32}  y
  tambi\'en sobre  la teoria de  la medida y  de la integraci\'ion  debido entre
  otros a Emile Borel y Henri-L\'eon Lebesgues~\cite{Bor98, Bor09, Leb04, Leb18,
    Hal50}    para    formalizar    anal\'iticamente    la   teoria    de    las
  probabilidades~\cite{Kol56,    BarNov78,   JacPro03}.}    proveen   requisitos
suficientes  para  determinar completamente  las  propiedades  de  la medida  de
probabilidad $P(A)$  que se puede asociar a  un evento $A$ entre  un conjunto de
resultados o eventos de un proceso.

Llamemos $\Omega$ al {\it espacio  muestral} o {\it espacio fundamental}, que es
el espacio de  {\it muestras (outcomes en ingl\'es)} \  $\omega \in \Omega$.  Se
asocia \ $\A$ \ una colecci\'on  de conjuntos de \ $\Omega$, donde los elementos
de $\A$ son llamados {\it eventos}.
% total de eventos.
Por ejemplo, $\Omega$ puede  ser las caras de un dado de  6 caras (los n\'umeros
naturales del 1 al  6, o las letras {\it a, b, c, d,  e, f}, u otro etiquetado),
$\A$ teniendo los eventos
% si $A$ es el evento
$A$ ``es  un n\'umero  natural par''  y $B$ indicando  ``es un  n\'umero natural
impar''.
% ,  el espacio  muestral  $\Omega  = \{  A  , B  \}$  indica  ``es un  n\'umero
% natural'';
En el caso de analizar el tiempo de vida de un aparato, $\Omega \equiv \Rset_+$.
% en el  lanzamiento de un  dado de 6  caras es $\Omega$  es el conjunto  de las
% etiquetas que se asigne a cada una de las caras (los n\'umeros naturales del 1
% al 6, o las letras {\it a, b, c, d, e, f}, u otro etiquetado).
El  conjunto  de  resultados  posibles  se  supone  conocido,  a\'un  cuando  se
desconozca de antemano el resultado de una prueba.

Entre  los eventos  se  pueden considerar  operaciones  an\'alogas a  las de  la
teor\'ia de  conjuntos (ej.~\cite{Spi76,  Bre88, ManWol95, Sie75,  Sie76, Bor98,
  Bor09}):
%
\begin{itemize}
\item Combinaci\'on  o uni\'on de  eventos: \ $A  \cup B$, implicando que  se da
  $A$, \'o $B$, o ambos (ej. por  un dado, $A$ eventos ``cara par'' y $B$ evento
  ``cara menor o igual a 3'' tal que $A \cup B = \{1 \, , \, 2 \, , \, 3 \, , \,
  4 \,  , \, 6\}$); Seg\'un la  literatura, se denota a  veces \ $A+B$ \  o \ $A
  \wedge B$.
%
\item  Intersecci\'on de  eventos:  \ $A\cap  B$,  implicando que  se dan  ambos
  $A$~y~$B$ (con  el ejemplo precediente,  $A \cap  B = \{  2 \}$); Se  denota a
  veces \ $(A,B)$ \ o \ $A \vee B$.
%
\item Complemento de un evento: \ $\bar{A}$ e indica que no se da $A$; Se denota
  a veces \ $-A$  \ o \ $A^c$ (con el ejemplo precediente, $\bar{A}  = \{ 1 \, ,
  \, 3 \, , \, 5 \}$).
%
\item  Eventos  {\it  disjuntos}  o   {\it  mutuamente  excluyentes}  o  {\it  o
    incompatibles}: \ son aquellos que no se  superponen, se anota \ $A \cap B =
  \emptyset$  \ donde  \  $\emptyset =  \bar{\Omega}$  \ denota  el evento  nulo
  (evento que no  puede ocurrir, es el complemento de  $\Omega$, por ejemplo $A$
  ``cara par'' y $B$ ``cara impar'').
\end{itemize}
%
\noindent Eso es ilustrado  en la figura Fig.~\ref{fig:MP:Ensembles}. La uni\'on
e intersecci\'on satisfacen a las mismas reglas que en la teoria ensemblista, es
decir cada una es comutativa \ $A \cup B = B \cup A$, \ $A \cap B = B \cap A$, \
asociativa \ $(A \cup B)  \cup C = A \cup (B \cup C)$, \ $(A  \cap B) \cap C = A
\cap (B \cap C)$, \ distributiva con respeto a la otra \ $(A \cup B) \cap C = (A
\cap C) \cup (B \cap C)$ \ y \ $(A  \cap B) \cup C = (A \cup C) \cap (B \cup C)$
\  (ver  ej.~\cite{Jef48,  Jef73,   Hal50,  Fel71,  Bre88,  ManWol95,  IbaPar97,
  LehCas98, AthLah06, Coh13}).

\begin{figure}[h!]
\begin{center} \input{TIKZ_MP/Ensembles} \end{center}
%
\leyenda{Ilustraci\'on   de  la  operaciones   de  uni\'on   $A  \cup   B$  (a),
  intersecci\'on $A \cap B$ (b), complemento $\bar{A}$ (c), enventos excluyentes
  $A \cap B =  \emptyset$ (d). $A$ es representado en linea  llena, $B$ en linea
  discontinua; (a)-(c)  el resultado de  la operaci\'on es  la zona en  grise. A
  veces, esta representaci\'on ensemblista se  denota {\it diagrama de Venn o de
    Euler}.}
\label{fig:MP:Ensembles}
\end{figure}


Formalmente, se define  de manera abstracta un espacio  medible $(\Omega,\A)$ de
la  manera   siguiente~\cite{Hal50,  Bre88,  IbaPar97,   AthLah06,  Coh13}  (ver
tambi\'en~\cite[\&  Ref.]{BarNov78,  Bor98,  Sie18,  Sie75,  Sie76}  para  notas
hist\'oricas):
%
\begin{definicion}[Espacio medible]
  $(\Omega, \A)$ \ formado de un espacio muestral \ $\Omega$ \ y una colecci\'on
  \ $\A$  \ de conjuntos  de \  $\Omega$ \ es  llamado {\it espacio  medible} si
  satisface a los requisitos
  %
  \begin{enumerate}%[label={(\Roman*)}]
  \item $\emptyset \in \A$,
  %
  \item si $A \in \A$, entonces \ $\bar{A} \in \A$,
  %
  \item la uni\'on numerable de conjuntos de $\A$ queda en $\A$ ($\A$ es cerrado
    por la un\'ion numerable).
  %
  \end{enumerate}
  %
  Con esta propiedades, $\A$  es llamado {\it $\sigma$-\'algebra}. Los elementos
  de $\A$ son dichos {\it medibles}.
\end{definicion}
%
\noindent Es  sencillo mostrar de  que $\Omega$ tambi\'en  es en $\A$, y  de que
$\A$   est   cerrado  por   la   intersecci\'on   numerable.    Un  ejemplo   de
$\sigma$-\'algebra sobre \ $\Omega = \{ 1 \, , \,  2 \, , \, 3 \, , \, 4 \, , \,
5 \, , \, 6 \}$ \ puede ser \ $\big\{ \emptyset \, , \, \Omega \, , \, \{ 1 \, ,
\, 2 \, , \, 3 \} \, , \, \{ 4 \, , \, 5 \, , \, 6 \} \big\}$.

Las propiedades de la probabilidad $P$ de un dado evento quedan determinadas por
los siguientes (ej.~\cite{Spi76, Kol56, ShaVov06, Pla05}):

\noindent {\it Axiomas de Kolmogorov}
%
\begin{enumerate}
\item $P(A_i) \geq 0 \ \ \forall \ A_i \A$
%
\item  Si $\{ A_i  \}_i$ son  eventos mutuamente  excluyentes de  $\A$, entonces
  $\displaystyle P\left( \bigcup_i A_i \right) = \sum_i P(A_i)$
%
\item $P(\Omega) = 1$
\end{enumerate}
%
Formalmente,  se  define  un  {\it  espacio  de  probabilidad}  o  {\it  espacio
  probabil\'istico}  de   la  manera  siguiente~\cite{Hal50,   Bre88,  IbaPar97,
  AthLah06, JacPro03, Coh13}:
%
\begin{definicion}[Espacio probabil\'istico]
  Sea $(\Omega,\A)$ un espacio medible.  Una funci\'on $\mu: \A \mapsto \Rset_+$
  tal que
  %
  \begin{enumerate}
  \item $\mu(\emptyset) = 0$, y
  \item para cualquier  conjunto numerable $\{ A_i \}$  de elementos mutualmente
    excluyentes  de $\A$  se tiene  $\mu\left(  \bigcup_i A_i  \right) =  \sum_i
    \mu(A_i)$
  \end{enumerate}
  %
  es  llamada {\it  funci\'on  medida}  o {\it  medida  $\sigma$-aditiva} y  el
  espacio $(\Omega,\A,\mu)$ es  llamado {\it espacio de medida}.

  Cuando $\mu$  es acotada por  arriba, $\mu(\Omega) <  + \infty$, la  medida es
  dicha  {\it  finita} y  el  espacio tambi\'n  es  dicho  finito. Adem\'as,  si
  \[ P \equiv  \mu, \quad \P(\Omega) = 1  \], la medida es dicha  medida de {\it
    probabilidad}, $\mu \equiv P$.  En  este caso, el espacio $(\Omega,\A,P)$ es
  llamado {\it espacio probabil\'istico}.
\end{definicion}


A  partir de  los axiomas  de Kolmogorov  se pueden  probar varios  corolarios y
propiedades:
%
\begin{itemize}
\item la probabilidad de un evento seguro o cierto es 1;
%
\item  la   probabilidad  de   un  evento   que  no  puede   ocurrir  es   0:  \
  $P(\emptyset) = 0$;
%
\item el rango  de las probabilidades est\'a  acotado: \ $0 \leq P(A)  \leq 1\ \
  \forall \ A \in \A$;
%
\item condici\'on de  normalizaci\'on: \ si $\Omega =  \bigcup_{i=1}^n A_i$, con
  $A_i$  mutuamente  excluyentes,  entonces  \  $\sum_{i=1}^n P(A_i)  =  1$;  el
  conjunto  $\{ A_i  \}_{i=1}^n$  es  dicho {\it  conjunto  completo de  eventos
    posibles      excluyentes      entre      s\'i}     y      es      ilustrado
  figure~\ref{fig:MP:CompletoSub};
%
\item si $A$ es subconjunto de $B$,  lo que escribiremos $A \subset B$, es decir
  si  $B$  se realiza,  $A$  se realiza  tambi\'en  (pero  no necesariamente  al
  rev\'es),     entonces     \     $P(A)     \leq    P(B)$;     Es     ilustrado
  figure~\ref{fig:MP:CompletoSub};
\end{itemize}

\begin{figure}[h!]
\begin{center} \input{TIKZ_MP/CompletoSub} \end{center}
%
\leyenda{Ilustraci\'on  de  conjunto completo  de  eventos posibles  excluyentes
  entre s\'i  (a), y de  la inclusi\'on  (b) donde $A$  es en grise  (claro como
  oscuro) mientras de que $B$ es en grise oscuro.}
\label{fig:MP:CompletoSub}
\end{figure}

Nota:  la probabilidad  \ $P(A  \cap B)$  \ del  evento $A  \cap B$  \  se llama
tambi\'en {\it probabilidad conjunta} de \ $A$ \ y \ $B$.
%$P(A  \cap B)  = P(B  \cap A)$}  es la
%probabilidad del evento conjunto dado por  la composici\'on de los eventos $A$ y
%$B$. 

Se demuestra que
%
\begin{itemize}
\item $P(A  \cap B)$ est\'a acotada:  \ $0 \leq P(A  \cap B) \leq  \min\{ P(A) ,
  P(B)\}$; (viene de \ $A \cap B \subset A$ \ y \ $A \cap B \subset B$).
%
\item Si  $A$ y $B$ son  mutuamente excluyentes, entonces  \ $p(A \cap B)  = 0$;
  (viene de \ $A \cap B = \emptyset$).
%
\item  si  $\{ B_j  \}_{j=1}^m$  es un  conjunto  completo  de eventos  posibles
  excluyentes entre s\'i, entonces \ $\sum_{j=1}^m P(A \cap B_j) = P(A)$; (viene
  de  $\{ A  \cap B_j  \}$ mutualmente  excluyentes y  $\bigcup_j \left(  A \cap
    B_j\right) = A \cap \left( \bigcup_j B_j \right) = A \cap \Omega = A$).
\end{itemize}

En el caso de eventos no necesariamente mutuamente excluyentes, se prueba que la
{\it ley de composici\'on} o {\it formula de inclusi\'on-exclusi\'on} es
%
\[
P(A \cup B) = P(A) + P(B) - P(A \cap B) \leq P(A) + P(B), 
\]
%
y que para $n$ eventos resulta
%
\[
P\left( \bigcup_{i=1}^n A_i \right) \leq \sum_{i=1}^n P\left( A_i \right).
\]
%
La  igualdad  vale  en  el  caso  especial  de  eventos  mutuamente  excluyentes
(recuperando el segundo axioma de Kolmogorov).

Se  prueba tambi\'en  de que  si $\{  A_i \}_{i=1}^{+\infty}$  es  una secuencia
creciente  de eventos,  \ie $\forall  \, i  \ge 1,  \quad A_i  \subset A_{i+1}$,
entonces
%
\[
P\left( \bigcup_{i=1}^{+\infty} A_i \right) = \lim_{i \to +\infty} P(A_i)
\]
%
Similarmente,  si $\{ A_i  \}_{i=1}^{+\infty}$ es  una secuencia  decreciente de
eventos, \ie $\forall \, i \ge 1, \quad A_{i+1} \subset A_i$, entonces
%
\[
P\left( \bigcap_{i=1}^{+\infty} A_i \right) = \lim_{i \to +\infty} P(A_i)
\]


Se puede preguntarse de cual es la probabilidad de un evento $A$, si sabemos que
tenemos un evento $B$, dado.  Por  ejemplo, por un dado de 6 caras equilibriado,
cual es la probabilidad de tener  un n\'umero par sabiendo que tenemos un numero
menor  a igual  a  3.   La respuesta  es  en la  noci\'on  de {\it  probabilidad
  condicional}~\cite{Hau01, Jef48, Jef73, Bre88, ManWol95, JacPro03, ShaVov06}:
%
\begin{definicion}[Probabilidad condicional]
  \underline{Por definici\'on},  la {\it  probabilidad condicional} de  $A$ dado
  $B$ es la raz\'on entre la  probabilidad del evento conjunto y la probabilidad
  de que se d\'e $B$ (cuando \'este es un evento no nulo):
  %
  \[
  P(A|B) = \frac{P(A \cap B)}{P(B)}.
  \]
\end{definicion}
%
En  el  ejemplo precediente,  la  probabilidad  va a  ser  $P(A|B)  = \frac13  =
\frac{\frac16}{\frac12}  = \frac{P(A  \cup B)}{P(B)}$. 

Es f\'acil demostrar %% <-- ejercicio
que esta  cantidad toma valores  entre 0 y  1, con $P(\Omega|B)  = 1$, y  que es
aditiva  para  una  uni\'on  de  eventos  mutuamente  excluyentes  referidos  al
cumplimiento de $B$.  Luego, $P(A|B)$ es una medida de probabilidad~\footnote{Se
  puede  definir un  espacio de  probabilidad $(  \Omega_B, \A_B  ,  P_B)$ donde
  $P_B(A)  \equiv P(A|B)$.};  Por eso,  a veces  en la  literatura se  la denota
$P_B(A)$.  Diversas  situaciones de probabilidades  condicionales son ilustradas
en la figura siguiente, Fig.~\ref{fig:MP:Condicional}.

\begin{figure}[h!]
\begin{center} \input{TIKZ_MP/Condicional} \end{center}
%
\leyenda{Ilustraci\'on  de  la probabilidad  condicional  con  $A$ interior  del
  elipse  en linea  llena  y unos  $B_i$  interiores de  los  elipses en  lineas
  discontinuas.   \ $\omega  \in B_1  \Rightarrow \omega  \in A$  \ as\'i  que \
  $P(A|B_1) = 1$. Al rev\'es, \  $\omega \in B_3 \Rightarrow \omega \not\in A$ \
  as\'i que \  $P(A|B_3) = 0$.  Entre estas  situaciones extremas, si $P(\bar{A}
  \cap B_2)  \ne 0$ \ y  \ $P(A \cap  B_2) \ne 0$ \  tenemos $0 < P(A|B_2)  < 1$
  (ej.  con   probabilidades  iguales  a   las  superficias  relativas   de  los
  conjuntos).}
\label{fig:MP:Condicional}
\end{figure}

Algunas propiedades interesantes son las siguientes:
%
\begin{itemize}
\item condici\'on  de normalizaci\'on: \  $\sum_{i=1}^n P(A_i|B) = 1$,  siendo \
  $\{ A_i \}_{i=1}^n$  \ un conjunto completo de  resultados posibles mutuamente
  excluyentes;
%
\item relaci\'on  entre probabilidades condicionales  inversas: \ $\displaystyle
  P(B|A)  = \frac{P(B)}{P(A)}  P(A|B)$, de  donde \  $p(A|B)$ \  y \  $p(B|A)$ \
  coinciden s\'olo cuando \ $A$ \ y \ $B$ \ tienen la misma probabilidad;
%
\item {\it f\'ormula de probabilidades totales}: \ si $\{ B_j \}$ es un conjunto
  completo de eventos no nulos mutuamente excluyentes, entonces
  %
  \[
  P(A) = \sum_j P(A|B_j) P(B_j)
  \]
  %
  Viene de \ $A = A \cap  \left( \bigcup_j B_j \right) = \bigcup_j \left( A \cap
    B_j \right)$  \ donde  los \ $A  \cap B_j$  \ son mutuamente  excluyentes, y
  $P\left( A \cap B_j \right) = P(A|B_j) P(B_j)$.
%
\item {\it  f\'ormula de Bayes}:  \ si  $\{ B_j \}$  es un conjunto  completo de
  eventos no nulos mutuamente excluyentes, entonces
  %
  \[
  P(B_i|A) = \frac{P(A \cap B_i)}{P(A)} = \frac{P(A|B_i) P(B_i)}{\sum_j P(A|B_j)
    P(B_j)} .
  \]
  %
  (ver~\cite{Bre88, JacPro03, Bay63, Bar58}).
\end{itemize}

Terminamos  esta   secci\'on  por  la   noci\'on  de  independencia   entre  dos
eventos. Por ejemplo, si dos dados son tirado sobre dos mesas diferentes, no hay
ninguna raz\'on de que la muestra de  uno ``influye'' la del otro. Dicho de otra
manera,  dos  eventos  son  indeêndientes  si conciendo  uno  no  lleva  ninguna
``informaci\'on'' sobre el otro~\cite{Bre88, ManWol95, Hau01, JacPro03, Bor09}:
%
\begin{definicion}[Independencia estad\'istica]
  Dos eventos \ $A$ \ y \ $B$ \ se dicen {\it estad\'isticamente independientes}
  si la  probabilidad condicional  de $A$  dado $B$ es  igual a  la probabilidad
  incondicional de $A$:
  %
  \[
   P(A|B) = P(A).
   \]
  %
   Es equivalente al hecho de que la probabilidad conjunta se factoriza,
  %
  \[
   P(A \cap B) = P(A) P(B).
   \]
\end{definicion}
%
Por  inducci\'on, la  condici\'on necesaria  y suficiente  para que  $n$ eventos
$A_1,\ldots,A_n$ sean  estad\'isticamente independientes es  que la probabilidad
conjunta se factorice como
%
\[
P\left( \bigcap_{i=1}^n A_i \right) = \prod_{i=1}^n P(A_i).
\]
%
Se  deduce que  los  eventos mutuamente  excluyentes  no son  estad\'isticamente
independientes.