% --------------------------------- Familia  eliptica
\subseccion{Familia eliptica real}

% --------------------
% Bilingsley p. 
% Kay p.
% Lehman & Casela p. 
% Kotz & Balakrishnan p.
% Robert p.
% van den Bos p.
% Cencov p.
% Ibarola Perez p.
% Mukhopadhyay p.

El estudio de  estos vectores es bastante antigua. Hace  falta volver a trabajos
de Maxwell en 1867  sobre la teoria del gas para encontrar  unas de las primeras
menciones  a este  formalismo~\cite{Max67}  o~\cite[pp.~377--391]{Nie52:v1}.  El
problema de Maxwell era de encontrar una distribuci\'on (tridimensional) que sea
isotropica  y  separable   a  la  vez:  monstr\'o  que   tal  distribuci\'on  es
necesariamente    gausiana    (es     ahora    conocido    como    teorema    de
Maxwell-Hershel~\footnote{Ver~\cite[Prop.~4.11]{BilBre99}.   Se notar\'a  que no
  hay muchas menciones  de este teorema bajo esta  denominaci\'on. no sabemos si
  la raz\'on es que  no tienen ni Maxwell, ni Herschel la  partenidad o si no lo
  revendicaron.}.   La clase  de las  distribuciones eliptical,  o  a simetr\'ia
eliptica   en    estad\'istica   o   procesamiento   de    la   se\~nal,   entre
otros~\cite{Bar34, Bar34:07, Kel71, Chu73, CamHua81, Eat81, Kan94, Yao73, Lau75,
  Lor54,  Ver64,  ArePin06,   BlaTho68,  ChiPas08,  Gol76,  RanWei93,  RanWei95,
  ZozVig, Zoz, Mui82, BilBre99, KotNad01}.

Empezamos  por  la  definici\'on,  antes  de  ir  m\'as  all\'a  estudiando  sus
propiedades remarcables.

\begin{definicion}[Vector esfericamente invariante]
  Sea  \  $X$  \  vector   aleatorio  $d$-dimensional  real.   $X$  \  es  dicho
  esfericamente  invariante,  o   rotacionalmente  invariante,  o  a  simetr\'ia
  esferica, o de distribuci\'on esferica \ si para cualquier matriz ortogonal (o
  de rotaci\'on)~\footnote{Recordarse que \ $O$  \ es ortogonal o de rotaci\'on
    si \ $O O^t = O^t O = I$.} \ $O$,
  %
  \[
  O  X  \: \egald  \: X
  \]
  %
\end{definicion}

Tales vectores modelizan naturalmente  fenomenos isotropicos. Pero m\'as all\'a,
se puede que haya direcciones  privilegiadas ortogonales pero con simetrias, \ie
en  lugar  de   simetr\'ias  esfericas,  simetr\'ias  como  en   una  pelota  de
rugby. Adem\'as, se puede que eso se pasa al torno de un punto no cero.
%
\begin{definicion}[Vector a simetr\'ia eliptica]
  Sea  \  $X$  \ vector  aleatorio  $d$-dimensional  real.   $X$  \ es  dicho  a
  simetr\'ia  eliptica,   o  elipticalmente  invariante,   o  de  distribuci\'on
  eliptica, al torno de \ $m \in  \Rset^d$, \ si existe una matriz \ $\Sigma \in
  P_d^+(\Rset)$ \ tal que para cualquier matriz ortogonal \ $O$,
  %
  \[
  O  \,   \Delta^{-\frac12}  \,  Q^t  \left(   X  -  m  \right)   \:  \egald  \:
  \Delta^{-\frac12} \, Q^t \left( X - m \right)
  \]
  %
  donde la  matriz diagonal \ $\Delta  > 0$ \ es  la matriz de  autovalores de \
  $\Sigma$ \  y \ $Q$ \  la matriz de los  autovectores correspondientes (matriz
  ortogonal~\cite{Bha97, Bha07, HorJoh13}), \ $\Sigma  = Q \Delta Q^t$. Dicho de
  otra manera, \ $\Delta^{-\frac12} Q^t \left(  X - m \right)$ \ es a simetr\'ia
  esferica.

  $m$ \ es llamado {\em par\'ametro de posici\'on} y \ la matriz \ $\Sigma$ \ es
  llamada {\em matriz caracter\'istica}.
\end{definicion}
%
Se puede inmediatamente  ver que \ $\Sigma$ \ es definida  por lo menos mediante
un factor escalar. De hecho, si un \ $\Sigma$ \ conviene, cualquier \ $a \Sigma$
\ con \ $a > 0$ \ conviene tambi\'en.

Comparativamente a un  vector esfericamente invariante, \ $m$ \  es el centro de
simetr\'ia,   $P$   contiene   las   direciones   de   ``estiramientos''   y   \
$\Delta^{\frac12}$  \   los  factores  de   estiramientos,  $X  \egald  m   +  P
\Delta^{\frac12} Y$ \  con \ $Y$ \ a simetr\'ia  esferica. Para \ $m =  0$ \ y \
$\Delta \propto I$, se recupera obviamente un vector a simetr\'ia esferica.

Como lo hemos visto, un vector aleatorio es completamente definido por su medida
de  probabilidad,  o  equivalentemente  por su  funci\'on  car\'acteristica.  La
\'ultima tiene una forma particular en el contexto eliptico:
%
\begin{teorema}[Funci\'ones y generadoras caracter\'isticas]\label{Teo:MP:GeneradorasCaracteristicas}
%
  Sea \ $X$ \ vector aleatorio $d$-dimensional a simetr\'ia eliptica al torno de
  \   $m  \in  \Rset^d$   \  y   de  matriz   caracter\'istica  \   $\Sigma  \in
  P_d^+(\Rset)$. Entonces la funci\'on caract\'eristica se escribe bajo la forma
  %
  \[
  \Phi_X(\omega)  = e^{\imath  \,  \omega^t m}  \varphi_X\left( \omega^t  \Sigma
    \omega \right)
  \]
  %
  donde  \  $\varphi_X:  \Rset_+  \mapsto  \Rset$ \  escalar,  es  llamado  {\em
    generadora  caracter\'istica}. Tomando el  logaritmo, obviamente  la secunda
  funci\'on caracteristica se escribe
  %
  \[
  \Psi_X(\omega) =  \imath \, \omega^t  m + \psi_X\left( \omega^t  \Sigma \omega
  \right)
  \]
  %
  donde  \ $\psi_X  =  \log \varphi_X:  \Rset_+  \mapsto \Rset$  \ escalar.   La
  llamaremos  {\em secunda generadora  caracter\'istica}. Reciprocamente,  si la
  funci\'on caracter\'istica tiene esta forma, \ $X$ \ es a simetr\'ia eliptica.
\end{teorema}
%
\begin{proof}
  Sea \  $Y = \Delta^{-\frac12} Q^t  \left( X - m  \right)$ \ con \  $\Sigma = Q
  \Delta  Q^t$  \ diagonalizaci\'on  de  \  $\Sigma$.   Por definici\'on  y  del
  teorema~\ref{Teo:MP:PropiedadesFuncionCaracteristica},  por  cualquier  matriz
  ortogonal $O$ y cualquier $\omega \in \Rset^d$
  %
  \[
  \Phi_Y(\omega) = \Phi_{O Y}(\omega) = \Phi_Y(O^t \omega)
  \]
  %
  En  otros  terminos,  la  funci\'on  caracter\'istica  queda  invariante  bajo
  cualquier transformaci\'on  ortogonal (rotaci\'on) sobre  $\omega$, y entonces
  depende solamente de  la norma euclideana de \ $\omega$.  Es decir, existe una
  funci\'on escalar \ $\varphi_X$ \ tal que
  %
  \[
  \Phi_Y(\omega) = \varphi_X(\omega^t \omega)
  \]
  %
  De nuevo, del teorema~\ref{Teo:MP:PropiedadesFuncionCaracteristica},
  %
  \[
  \Phi_X(\omega)  \:  = \:  \Phi_{Q  \Delta^{\frac12} Y  +  m}(\omega)  \: =  \:
  e^{\imath  \, \omega^t  m} \,  \Phi_Y( \Delta^{\frac12}  Q^t \omega)  \:  = \:
  e^{\imath \, \omega^t m} \, \varphi_x( \omega^t Q \Delta Q^t \omega)
  \]
  % 
  lo que  cierra la prueba  directa. Reciproca, si  \ $\Phi_X$ \ tiene  la forma
  dada, para  cualquier matriz ortogonal \  $O$ \ $\Phi_{O  Y}(\omega) = \Phi_Y(
  O^t \omega ) = \Phi_Y(\omega)$ \  y, por relaci\'on uno-uno entre la medida de
  probabilidad  de una variable  aleatorio y  su funci\'on  caracter\'istica, $Y
  \egald O Y$.
\end{proof}
%
Se notar\'a que si tomamos  una matriz caracter\'istica $\Sigma$ y la generadora
correspondiente  $\varphi$, \  $a  \Sigma$ \  y  \ $\varphi_X\left(  \frac{u}{a}
\right)$ \ conviene tambi\'en, lo que  es de acuerdo con la indeterminencia de \
$\Sigma$ \ bajo un factor positivo.  Se puede a\~nadir un v\'inculo, por ejemplo
fijando  \  $\Tr \Sigma$  \  para  que  \ $\Sigma$  \  y  \ $\varphi_X$  \  sean
\'unicamente definidas. Entonces, \ $X$ \ ser\'a completamente caracterizado por
\ $m, \: \Sigma$ \ y \ $\varphi_X$, y escribiremos
%
\[
X \, \sim \, \ED \left( m , \Sigma , \varphi_X \right)
\]

Varias vectores que hemos visto caen en esta familia:
%
\begin{ejemplo}[Distribuci\'on gausiana]
  Sea \  $X \sim \N(m,\Sigma)$.  Entonces, \ $X \sim  \ED(m,\Sigma,\varphi_X)$ \
  con
  %
  \[
  \varphi_X(u) = e^{-\frac{u}{2}}
  \]
  %
\end{ejemplo}
%
\begin{ejemplo}[Distribuci\'on Student-t]
  Sea \  $X \sim \T_\nu(m,\Sigma)$.  Entonces, \ $X \sim  \ED(m,\Sigma,\varphi_X)$ \
  con
  %
  \[
  \varphi_X(u)   =  \frac{\nu^{\frac{\nu}{4}}}{2^{\frac{\nu}{2}-1}  \Gamma\left(
      \frac{\nu}{2}   \right)}   \,  u^{\frac{\nu}{4}}   K_{\frac{\nu}{2}}\left(
    \sqrt{\nu \, u} \right)
  \]
\end{ejemplo}
%
\begin{ejemplo}[Distribuci\'on Student-r]
  Sea \  $X \sim \R_\nu(m,\Sigma)$.  Entonces, \ $X \sim  \ED(m,\Sigma,\varphi_X)$ \
  con
  %
  \[
  \varphi_X(u)   =   \frac{2^{\frac{\nu}{2}}   \Gamma\left(   \frac{\nu}{2}   +1
    \right)}{(\nu+2)^{\frac{\nu}{4}}}            \,           u^{-\frac{\nu}{4}}
  J_{\frac{\nu}{2}}\left( \sqrt{(\nu+2) \, u} \right)
  \]
\end{ejemplo}

Un  caso particular que  va a  jugar un  rol importante  es el  de un  vector de
distribuci\'on uniforme sobre la esfera \ $\Sset_d$, \ $U \sim \U(\Sset_d)$~\SZ{\cite{toto, titi, FanKot90}:}
%
\begin{ejemplo}[Distribuci\'on uniforme sobre la esfera unitaria]\label{Ej:MP:GeneCaracUniformeEsfera}
%
  Sea \  $U \sim \U(\Sset_d)$. Entonces  \ $U \sim  \ED\left( 0 , I  , \varphi_U
  \right)$ \ con
  %
  \[
  \varphi_U(u)   =  2^{\frac{d}{2}-1}   \Gamma\left(   \frac{d}{2}  \right)   \,
  u^{-\frac{d-2}{4}} \, J_{\frac{d}{2}-1}\left( \sqrt{u} \right)
  \]
  %
  con \  $J_\nu$ \  funci\'on de Bessel  primera especie  y de orden  $\nu$ (ver
  notaciones).
  
  De hecho, de la definici\'on de la funci\'on caracter\'istica, tenemos
  %
  \[
  \Phi_U(\omega) =  \frac{1}{|\Sset_d|} \int_{\Sset_d} e^{\imath  \, \omega^t s}
  d\mu_H(s)
  \]
  %
  con \ $\mu_H$ \ la medida de Haar~\footnote{Para \ $S \subset \Sset$ \ $\mu(S)
    =    |S|$.}     sobre    la    esfera    y   \    $|\Sset_d|    =    \frac{2
    \pi^{\frac{d}{2}}}{\Gamma\left(  \frac{d}{2} \right)}$  \ la  surfaca  de la
  esfera  unitaria~\cite{GraRyz15}.   Ahora,  denotanto  \  $\Sset_d^+$  \  y  \
  $\Sset_d^-$  \ respectivamente  la semiesfera  superior y  inferior,  se puede
  parametrizar \  $s \in \Sset_d^{\pm}$ \  bajo la forma \  $s = \begin{bmatrix}
    b^t & \pm \sqrt{1-\|b\|^2} \end{bmatrix}^t, \quad b \in \Bset_{d-1}$, lo que
  da,  siguiendo~\cite[ec.~4.644]{GraRyz15}  (cambio  de  variables)  y  notando
  $\mu_L$ \ la medida de Lebesgue,
  %
  \begin{eqnarray*}
  \Phi_U(\omega) & = & \frac{2 \, \Gamma\left( \frac{d}{2}
  \right)}{\pi^{\frac{d}{2}}} \int_{\Bset_{d-1}} \frac{e^{\imath \, \omega^t
  s}}{\sqrt{1-\|b\|^2}} d\mu_L(b)\\[2mm]
  %
  & = & \frac{\Gamma\left( \frac{d}{2} \right)}{\sqrt{\pi} \, \Gamma\left(
  \frac{d-1}{2} \right)} \int_0^{\pi} e^{\imath \, \| \omega \| \cos\theta} \,
  \sin^{d-2}\theta \, d\theta
  \end{eqnarray*}
  %
  Al final,  de la forma de la  funci\'on de Bessel~\cite[Ec.~8.411-7]{GraRyz15}
  (ver tambi\'en~\cite{AbrSte70, Wat22, GraMat95}), se obtiene
  %
  \[
  \Phi_U(\omega) =  \frac{2^{\frac{d}{2}-1} \Gamma\left( \frac{d}{2} \right)}{\|
    \omega \|^{\frac{d}{2}-1}} \, J_{\frac{d}{2}-1}\left( \|\omega\| \right)
  \]
  %
  lo que cierra  la prueba. Volveremos a esta  funci\'on caracteristica tratando
  de las coordenadas esfericas.
\end{ejemplo}

La forma de la funci\'on caracter\'istica tiene varias consecuencias. La primera
es  que se  puede escribir  estocaticamente un  vector a  simetr\'ia  eliptica a
partir de un vector esfericamente invariante de varias maneras, entre otros:
%
\begin{corolario}
  Sea  \ $Y  \sim  \ED(0,I,\varphi_Y)$, \  $m \in  \Rset^d$  \ y  \ $\Sigma  \in
  P_d^+(\Rset)$. \ Sean \ $\Sigma = Q \Delta Q^t$ \ la descomposici\'on diagonal
  de \ $\Sigma$, \ $\Sigma^{\frac12} = Q \Delta^{\frac12} Q^t$ \'unica matriz de
  \  $P_d^+(\Rset)$ \  raiz cuadrada  de \  $\Sigma$,  y \  $\Sigma =  L L^t$  \
  descomposici\'on  de  Cholesky   de  \  $\Sigma$,  con  \   $L$  \  triangular
  inferior~\cite{HorJoh13, Bha07}.  Entonces
  %
  \[
  Q \Delta^{\frac12} Y + m \: \egald \:  \Sigma^{\frac12} Y + m \: \egald \: L Y
  + m \: \sim \: \ED(m,\Sigma,\varphi_Y)
  \]
\end{corolario}
%
\begin{proof}
  El             resultado            es             consecuencia            del
  teorema~\ref{Teo:MP:PropiedadesFuncionCaracteristica}  y  de  la forma  de  la
  funci\'on caracter\'istica del teorema~\ref{Teo:MP:GeneradorasCaracteristicas}.
\end{proof}

Una otra consecuencia es que, dado el orden, el tensor de los momentos tiene una
structura dada para cualquier ley, bajo un factor escalar que depende de la ley.
Eso vale tambi\'en para los cumulantes:
%
\begin{teorema}[Momentos centrales y cumulantes]\label{Teo:MP:MomentosCumulantesEliptica}
%
  Sea \  $X$ \  vector aleatorio $d$-dimensional  de distribuci\'on  eliptica al
  torno  de  un  vector \  $m$,  y  de  matriz  caracter\'istica \  $\Sigma  \in
  P_d^+(\Rset)$.  Entonces, si  estos momentos y cumulantes existen,  \ $m$ \ es
  la media de \ $X$, \ie
  %
  \[
  \zeta_1[X] = 0, \qquad \kappa_1[X] = m
  \]
  %
  y para cualquier orden superior a  $2$, los momentos centrales y cumulantes de
  orden impares son ceros,
  %
  \[
  \zeta_{2 k + 1}[X] = \kappa_{2 k + 1}[X] = 0, \qquad k \ge 1
  %_{i_1,\ldots,i_{2  k  +1}}[X] =  \kappa_{i_1,\ldots,i_{2  k  +1}}[X] =  0,
  %\qquad k \ge 1
  \]
  %
  y los de orden pare son dados para \ $k \ge 1$, por
  %
  \[
  \zeta_{2 k}[X] = \alpha_k\left(  \varphi_X   \right) \T_k(\Sigma)
  %{i_1,\ldots,i_{2   k}}[X]   =   \alpha_k\left(  \varphi_X   \right)   \,
  %c_{i_1,\ldots,i_{2 k}}(\Sigma)
 \qquad  y \qquad \kappa_{2 k}[X] = \alpha_k\left(  \psi_X   \right) \T_k(\Sigma)
%_{i_1,\ldots,i_{2 k}}[X]
%  = \alpha_k\left( \psi_X \right) \, c_{i_1,\ldots,i_{2 k}}(\Sigma)
  % (-2)^k \, \varphi_X^{(k)}(0)  \sum_{\pi \in \Pi_{2 k ,  2}} \prod_{(l,n) \in
  %   \pi} \Sigma_{i_l,i_n}
  \]
  %
  % y
  %  %
  % \[
  %  \kappa_{i_1,\ldots,i_{2 k}}[X]  = (-2)^k  \, \psi_X^{(k)}(0)  \sum_{\pi \in
  %   \Pi_{2 k , 2}} \prod_{(l,n) \in \pi} \Sigma_{i_l,i_n}
  % \]
  %
  con el coefficient \ $\alpha_k$ \ dado por
  %
  \[
  \alpha_k(f) = (-2)^k f^{(k)}(0)
  \]
  %
  y el tensor \ $\T_k(\Sigma)$ \ de orden \ $2 k$ \ de componentes
  %
  \[
  \T_{i_1,\ldots,i_{2k}}(\Sigma) = \sum_{\pi \in \Pi_{2 k , 2}} \prod_{(l,n) \in
    \pi} \Sigma_{i_l,i_n}
  % \qquad \mbox{y} \qquad \alpha_k(f) = (-2)^k f^{(k)}(0)
  \]
  %
  donde   \  $\Pi_{2   k  ,   2}$   \  es   el  conjunto   de  particiones   por
  pares~\footnote{Por ejemplo,  $\Pi_{4,2} =  \big\{ \{1,2\} ,  \{3,4\} \:  , \:
    \{1,3\} , \{2,4\} \: , \: \{1,4\}  , \{2,3\} \big\}$; cuando \ $\pi = \big\{
    \{1,3\} , \{2,4\} \big\}$, el  t\'ermino del producto es \ $\Sigma_{i_1,i_3}
    \Sigma_{i_2,i_4}$.} de $\{ 1 , \ldots , 2 k \}$.
\end{teorema}
%
Una prueba  es dada  por inducci\'on en~\cite{BerBen86}  para los  momentos (ver
tambi\'en~\cite[p.~44]{FanKot90} para el resultat  con los momentos).  Damos una
prueba m\'as directa, valida para ambos momentos y cumulantes.
%
\begin{proof}
  Recordamosnos que para \ $k \in \Nset^*, \quad (i_1 , \ldots , i_k) \in \{ 1 ,
  \ldots , d \}^k$,
  %
  \[
  \zeta_{i_1,\ldots,i_k}[X]     =     (-    \imath)^k     \left.\frac{\partial^k
      \Phi_X}{\partial          \omega_{i_1}          \cdots          \partial
      \omega_{i_k}}\right|_{\omega=0}       \qquad       \mbox{y}       \qquad
  \kappa_{i_1,\ldots,i_k}[X]     =    (-     \imath)^k    \left.\frac{\partial^k
      \Psi_X}{\partial          \omega_{i_1}          \cdots          \partial
      \omega_{i_k}}\right|_{\omega=0}
  \]
  
  Por  definici\'on  de  los  momentos  centrales  $\zeta_1  =  0$.   Luego,  de
  $\Psi_X(\omega)  =  \imath \,  \omega^t  m  +  \log\left( \varphi_X(  \omega^t
    \omega) \right)$ \ tenemos
  %
  \[
  \nabla_\omega \Psi_X(\omega) =  \imath \, m + \frac{2  \, \varphi_X'( \omega^t
    \omega)}{\varphi_X'( \omega^t \omega)} \, \omega
  \]
  %
  Recordandose que \ $\Phi_X(0) = \Esp\left[  e^{\imath \, 0^t X} \right] = 1$ \
  y \ $m =  - \imath \, \nabla_\omega \Psi_X(0)$: \ $m$ \ es  la media de \ $X$\
  lo que corresponde a la intuici\'on.

  Luego, salimos de la  formula de Hardy~\cite[Prop.~1]{Har06}, generalizando la
  formula de  Fa\`a di  Bruno~\cite{Faa55, Faa57}: Para  \ $h(\omega)  = f\left(
    g(\omega) \right), \quad  \forall \: n \in \Nset^*, \quad  \forall \: (i_1 ,
  \ldots , i_n ) \in \{ 1 , \ldots , d \}^n$,
  %
  \[
  \frac{\partial^n  h}{\partial  \omega_{i_1}  \cdots \partial  \omega_{i_n}}  =
  \sum_{\pi  \in \Pi_n}  f^{(|\pi|)}\left( g(\omega)  \right) \prod_{B  \in \pi}
  \frac{\partial^{|B|} g}{\displaystyle \prod_{j \in B} \partial \omega_{i_j}}
  \]
  %
  donde \ $\Pi_n$  \ es el conjunto de las  particiones de \ $\{ 1  , \ldots , n
  \}$,  $f^{(l)}$  la $l$-esima  derivada  de $f$.   En  la  expresi\'on de  los
  momentos centrales y cumulantes tenemos
  %
  \[
  g(\omega) = \sum_{i,j=1}^d \omega_i \omega_j \Sigma_{i,j}
  \]
  %
  as\'i que, por simetr\'ia de $\Sigma$,
  %
  \[
  \frac{\partial  g}{\partial   \omega_{j_1}}  =  2   \sum_{l=1}^d  \omega_{j_1}
  \Sigma_{j_1,l},  \qquad  \frac{\partial^2  g}{\partial  \omega_{j_1}  \partial
    \omega_{j_2}}  =  2 \Sigma_{j_1,j_2},  \qquad  \forall  \:  n \ge  3,  \quad
  \frac{\partial^n g}{\prod_{l=1}^n \partial \omega_{j_l}} = 0
  \]
  %
  Es decir que, para $n \ge 1$,
  %
  \[
  \left.      \frac{\partial^n    g}{\prod_{l=1}^n     \partial    \omega_{j_l}}
  \right|_{\omega = 0} = \left\{\begin{array}{ccl}
  %
  2   \Sigma_{j_1,j_2} & \mbox{si} & n = 2\\[2mm]
  %
  0 & \mbox{si} & n \ne 2
  %
  \end{array}\right.
  \]
  %
  Entonces,  en la formula  de Hardy  tomada en  $\omega =  0$ quedan  solas las
  particiones  que  contienen unicamente  pares  de  indices.   Eso da  momentos
  centrales y cumulantes nulos para $k$ impar (obvio por sim\'etria). Adema\'as,
  siendo \  $\Pi_{2 k , 2}$  \ el conjunto de  particiones por pares de  $\{ 1 ,
  \ldots , 2 k \}$, notando que necesariamente cada partici\'on de \ $\Pi_{2 k ,
    2}$ \ contiene \ $k$ \ pares,
  %
  \[
  \left.   \frac{\partial^{2  k}   h}{\partial   \omega_{i_1}  \cdots   \partial
      \omega_{i_{2  k}}}\right|_{\omega =  0} =  \sum_{\pi  \in \Pi_{2  k ,  2}}
  f^{(k)}(0) \prod_{(l,n) \in \pi} \left( 2 \Sigma_{i_l,i_n} \right)
  \]
  %
  La prueba  se cierra  tomando respectivamente  \ $f =  \varphi_X$ \  y \  $f =
  \psi_X$.
\end{proof}
%
Veremos m\'as adelante una prueba a\'un m\'as directa y obvia que, a orden dado,
el tensor  de los  momentos centrales  tiene una structura  dada bajo  un factor
escalar  dependiendo  de la  ley.   Lo  que es  menos  obvio,  de la  relaci\'on
momentos-cumulantes, que eso vale para el tensor de los cumulantes, y que, m\'as
que eso, estas structuras son las mismas.

De este  resultado se puede tambi\'en  explicitar la matriz de  covariancia y el
tensor curtosis para un vector a simetr\'ia eliptica~\cite[p.~44]{FanKot90}:
%
\begin{corolario}
  Sea \  $X$ \  vector aleatorio $d$-dimensional  de distribuci\'on  eliptica al
  torno   de   $0$   \   y    de   matriz   caracter\'istica   \   $\Sigma   \in
  P_d^+(\Rset)$. Entonces
  %
  \[
  \Sigma_X = - 2 \,  \varphi_X'(0) \Sigma
  \]
  %
  y
  %
  \[
  \kappa_X   =   \frac{\varphi_X''(0)}{4    \,   \big(   \varphi_X(0)   \big)^2}
  \sum_{i,j=1}^d \Big( \left( \un_i \un_i^t \right) \otimes \left( \un_j \un_j^t
  \right) + \left( \un_i \un_j^t  \right) \otimes \left( \un_i \un_j^t \right) +
  \left( \un_i \un_j^t \right) \otimes \left( \un_j \un_i^t \right) \Big)
  \]
  %
\end{corolario}
\begin{proof}
  El resultado es inmediato por lo  de la covarianza.  Para la curtosis, momento
  central de  orden cuatro del  vector normalizado, es equivalente  considerar \
  $\Sigma  = -  \frac{1}{2  \, \varphi_X(0)}  I$,  lo que  da  el resultado  del
  corrolario.
\end{proof}
%
Nota: de $\Tr(\Sigma_X) = \Tr\left( \Esp\left[ (X-m_X) (X-m_X)^t \right] \right)
= \Esp\left[ (X-m_X)^t  (X-m_X) \right]$ \ tenemos para  $U \sim \U(\Sset_d)$, \
$\Tr(\Sigma_U) = 1$, \ie
%
\[
\mbox{Para } \: U \sim \U(\Sset_d), \quad \Sigma_U = \frac{1}{d} I
\]
%Se  notar\'a  que  $\varphi_X(0)  =  1$  \  m\'axima,  y  que  necesariamente  \
%$\varphi_X'(0)  < 0$,  o, tambi\'en,  que $\varphi_X''(0)  > 0$:  $\phi_X$  \ es
%(localmente) concava al torno de $0$;

Se  puede  ver  de  este  corolario  que  la  covarianza  es  proporcional  a  \
$\Sigma$. Es decir que un v\'inculo que se puede poner tambi\'en para fijar \ $(
\Sigma , \varphi_X )$ \ es de  imponer un homotecia a \ $\varphi_X$ \ para tener
$\varphi_X'(0) = - \frac12$, para que \ $\Sigma$ \ y \ $\Sigma_X$ \ coincidan.

De  la  forma de  la  funci\'on caracter\'istica  se  proba  tambi\'en que  para
cualquier transformaci\'on  af\'in de un  vector a simetr\'ia eliptica  queda un
vector a simetr\'ia eliptica:
%
\begin{teorema}
  Sea  \  $X \,  \sim  \,  \ED(m,\Sigma,\varphi_X)$  \ $d$-dimensional,  $A  \in
  \M_{d',d}$  \  de  rango   lleno  tal  que  \  $d'  \le  d$   \  y  \  $c  \in
  \Rset^{d'}$. Entonces
  %
  \[
  A X + c \: \sim \: \ED(A m + c , A \Sigma A^t , \varphi_X)
  \]
  %
\end{teorema}
%
\begin{proof}
  El  resultado es  inmediato  de  la forma  de  la funci\'on  caracter\'istica,
  teorema~\ref{Teo:MP:GeneradorasCaracteristicas}   y   como  consecuencia   del
  teorema~\ref{Teo:MP:PropiedadesFuncionCaracteristica}.
\end{proof}
%
En particular, la proyecci\'on de  un vector a simetr\'ia eliptica queda eliptica
al  torno de  la proyecci\'on  del vector  posici\'on, con  la  misma generadora
caracter\'istica.

Eso  v\'incula   tambi\'n  un  vector  a  simetr\'ia   eliptica  coin  cualquier
proyecci\'on:
%
\begin{teorema}[Proyecci\'on y componentes]
  Sea \ $X$, vector aleatorio $d$-dimensonal de componentes $X_i$. Entonces
  %
  \[
  X \sim \ED(m,\Sigma,\varphi_X) \qquad  \Longleftrightarrow \qquad \forall \: a
  \in \Rset^d, \quad a^t (X - m) \egald \sqrt{\frac{a^t \Sigma a}{\Sigma_{i,i}}}
  (X_i - m_i)
  \]
\end{teorema}
%
\begin{proof}
  Sea \ $X \sim \ED(m,\Sigma,\varphi_X)$, entonces
  %
  \[
  \Phi_{a^t (X - m)}(\omega) = \Phi_{X - m}(\omega a) = \varphi_X\left( \omega^2
    a^t \Sigma  a \right)  = \Phi_{X_i-m_i}\left( \omega  \sqrt{\frac{a^t \Sigma
        a}{\Sigma_{i,i}}}\right)  = \Phi_{\sqrt{\frac{a^t \Sigma
        a}{\Sigma_{i,i}}} (X_i-m_i)}\left( \omega  \right)
  \]
  %
  (se puede sacar el valor absoluto a $\omega$ porque, necesariamente, $X_i-m_i$
  es     a     simetr\'ia    eliptica,     es     decir    $(X_i-m_i)     \egald
  -(X_i-m_i)$). Reciprocamente,  si para cualquier $a \in  \Rset^d$ tenemos $a^t
  (X  -  m)  \egald  \sqrt{\frac{a^t  \Sigma  a}{\Sigma_{i,i}}}  (X_i  -  m_i)$,
  necesariamente
  %
  \[
  \Phi_{X  - m}(a) =  \Esp\left[ e^{\imath  \, a^t  (X-m)} \right]  = \Esp\left[
    e^{\imath \, \sqrt{\frac{a^t \Sigma a}{\Sigma_{i,i}}} (X_i - m_i)} \right] =
  \Phi_{X_i-m_i}\left( \sqrt{\frac{a^t \Sigma a}{\Sigma_{i,i}}}\right)
  \]
  %
  Es  una  funci\'on  de  $a^t  \Sigma  a$,  lo que  cierra  la  prueba  por  el
  teorema~\ref{Teo:MP:GeneradorasCaracteristicas}.
\end{proof}

Una consecuencia importante de la  forma de la funci\'on caracter\'istica es que
sirve a probar  que un vector a simetr\'ia  esferica se escribe estocasticamente
como  una mezcla de  escala de  un vector  uniforme sobre  la esfera  unitaria \
$\Sset_d$. Este resultado es  debido a Sch{\oe}nberg~\cite{Sch38, FanKot90} y se
enuncia como sigue:
%
\begin{teorema}[Mezcla de escala de base uniforme]\label{Teo:MP:MezclaUniforme}
  Sea  \ $X$ \  $d$-dimensional a  simetria esferica.  Entonces, este  vector se
  escribe estocasticamente como
  %
  \[
  X \egald R \, U \qquad \mbox{con} \qquad U \sim \U(\Sset_d), \quad R > 0 \quad \mbox{independientes}
  \]
  %
  M\'as generalmente, para \ $Y \sim \ED(m,\Sigma,\varphi_Y)$,
  %
  \[
  Y \egald \Sigma^{\frac12} R \, U + m
  \]
  %
  Adem\'as, inmediatamente
  %
  \[
  R \egald \| X \|
  \]
  %
  (obviamente, $\frac{X}{\| X \|} \egald U$).
\end{teorema}
%
\begin{proof}
  Escribimos \  $\omega = \rho u$ \  con \ $\rho \ge  0$ \ y \  $u \in \Sset_d$.
  Entonces, con  \ $\mu_H$ \ la  medida de Haar sobre  la esfera y \  $P_X$ \ la
  medida de probabilidad de \ $X$, tenemos
  %
  \begin{eqnarray*}
  \Phi_X(\omega) & = & \varphi_X(\rho^2)\\[2mm]
  %
  & = & \frac{1}{|\Sset_d|} \int_{\Sset_d} \varphi_X(\rho^2) \, d\mu(v)\\[2mm]
  %
  & = & \frac{1}{|\Sset_d|} \int_{\Sset_d} \Phi_X(\rho v) \, d\mu(v)\\[2mm]
  %
  & = & \frac{1}{|\Sset_d|} \int_{\Sset_d} \left( \int_{\Rset^d} e^{\imath \,
  \rho v^t x} \, dP_X(x) \right) \, d\mu(v)\\[2mm]
  %
  & = & \int_{\Rset^d} \left( \int_{\Sset_d} e^{\imath \, \rho v^t x} \,
  \frac{1}{|\Sset_d|} \, d\mu(v) \right) \, dP_X(x)\\[2mm]
  %
  & = & \int_{\Rset^d} \Phi_U(\rho x) \, dP_X(x)\\[2mm]
  %
  & = & \int_{\Rset^d} \varphi_U(\rho^2 \|x\|^2) \, dP_X(x)
  \end{eqnarray*}
  %
  con \ $\Phi_U$ \ funci\'on caracteristica  de un vector \ $U \sim \U(\Sset_d)$
  \ y  \ $\varphi_U$  \ la generadora  caracter\'istica correspondiente.   Sea \
  $F_R(r) = 0$ \ para \ $r \le 0$ \ y
  %
  \[
  F_R(r) = \int_{\Bset(0,r)} dP_X(x)
  \]
  %
  si no.  Claramente  \ $F_R$ \ es creciente  de $0$ a $1$: es  una funci\'on de
  repartici\'on. Notando \ $R$ \  la variable aleatoria positiva de funci\'on de
  repartici\'on \ $F_R$,
  %
  \begin{eqnarray*}
  \Phi_X(\omega) & = & \int_{\Rset_+} \varphi_U( \rho^2 r^2) \, dF_R(r)\\[2mm]
  %
  & = & \int_{\Rset_+} \Phi_U(r \omega) \, dF_R(r)\\[2mm]
  %
  & = & \Esp\left[ \Esp\left[ \left. e^{\imath \, \omega^t R U} \right | R \right] \right]
  \end{eqnarray*}
  %
  el paso  de la ante\'ultima  a la  \'ultima linea siendo  valido para \  $R$ \
  independiente  de \  $U$.  En otros  terminos, con  \  $R$ \  de funci\'on  de
  repartici\'on \  $F_R$ \ y  \ $U \sim  \U(\Sset_d)$ \ independiente de  \ $R$,
  tenemos del teorema de esperanza total~\ref{Teo:MP:EsperanzaTotal},
  %
  \[
  \Phi_X(\omega) = \Phi_{R U}(\omega)
  \]
  %
  La prueba se  cierra de la relaci\'on uno-uno entre  la medida de probabilidad
  de un vector aleatorio y la funci\'on caracter\'istica. De \ $X \egald R \, U$
  \ y \ $\| U \| = 1$ \ viene \ $R \egald \| X \|$.
\end{proof}

De esta escritura, se puede ir un paso m\'as all\'a~\cite[Teo~2.3]{FanKot90}:
%
\begin{corolario}
  Sea  \ $X$ \  $d$-dimensional a  simetria esferica.  Entonces, este  vector se
  escribe estocasticamente como
  %
  \[
  X =  \|X\| \: \frac{X}{\|X\|}
  \]
  %
  tales  que  \ $\|  X  \|  \egald  R$ \  y  \  $\frac{X}{\|X\|} \egald  U  \sim
  \U(\Sset_d)$ \ son independientes.
\end{corolario}
%
\begin{proof}
  Seg\'un~\cite{FanKot90, Zol86}, si  dos vectores aleatorios \ $A$ \  y \ $B$ \
  son iguales en distribuci\'on, para cualquier conjunto de funciones medibles \
  $f_1, \ldots ,f_n$, $\begin{bmatrix}  f_1(A) & \cdots & f_n(A) \end{bmatrix}^t
  \egald \begin{bmatrix} f_1(B) & \cdots & f_n(B) \end{bmatrix}^t$. Se lo aplica
  a \ $f_1(x) = \|x\|$, \ $f_2(x) = \frac{x}{\|x\|}$ \ con \ $X \egald R \ U$.
\end{proof}.

De la escritura  $X \egald R \,  U$, se puede ver $X  \sim \ED(0,I,\varphi_X)$ \
como mu\~necas rusas: a cada escala  $R = r$ tenemos una distribuci\'on uniforma
sobre la esfera de este rayo $r$. Por eso, $X$ es tambi\'en dicho {\em mezcla de
  escala}  de una  {\em base}  \ uniforme  y \  $R$ \  es llamada  {\em variable
  generadora}.

De  esta escritura,  queda ahora  claro que  cada tensor  de  momentos centrales
tienen  una estrctura  fija: de  \ $X  =  R \Sigma  U$ \  tenemos $\zeta_l[X]  =
\Esp\left[  R^l \right]  \zeta_l[\Sigma  U]$ (ver  ej.~\cite[teo.~2.8]{FanKot90}
para $\Sigma \propto I$): la estructura, com\'un a cualquier vector aleatorio de
$\ED(m,\Sigma,\varphi_X)$ es dada por \  $\zeta_k[\Sigma U]$ (cero cuando $l = 2
k + 1$, por  simetr\'ia central) y el factor, dependiente de  la ley es dada por
el  momento  del  ``rayo'' $R$.  Adem\'as,  se  puede  dar  una otra  forma  del
coefficiente $\alpha_k$:
%
\begin{lema}
  El  coeficiente  \  $\alpha_k$ \  del  tensor  de  los monetos  centrales  del
  teorema~\ref{Teo:MP:MomentosCumulantesEliptica} es tambi\'en dado por
  %
  \[
  \alpha_k   =    \frac{\Gamma\left(   \frac{d}{2}   \right)}{2^k   \Gamma\left(
      \frac{d}{2}  + k\right)}  \, \Esp\left[  \left( (X-m)^t  \Sigma^{-1} (X-m)
    \right)^k \right]
  \]
\end{lema}
%
\begin{proof}
  Por ejemplo, del desarollo  de Taylor  de la funci\'on  de Bessel  dado en~\cite{GraRyz15},
  aplicado a \ $\varphi_U(u)  = 2^{\frac{d}{2}} \Gamma\left( \frac{d}{2} \right)
  u^{-\frac{d-2}{4}} J_{\frac{d}{2}-1} \left( \sqrt{u} \right)$ \ se obtiene
  %
  \[
  \varphi_U^{(k)}(0)   =  \frac{(-1)^k   \Gamma\left(   \frac{d}{2}  \right)}{4^k
  \Gamma\left( \frac{d}{2} + k\right)}
  \]
  %
  A  continuaci\'on, para  \ $X  \sim \ED(m,\Sigma,\varphi_X)$,  de $X-m  =  R \
  \Sigma  \ U$  \  ($R$ es  escalar)  y de  la formula  del  tensor de  momentos
  centrales se obtiene
  %
  \[
  \zeta_{2    k}[X]     =    \Esp\left[    R^{2     k}    \right]
  \zeta_{2   k}[\Sigma   U]   =   \Esp\left[  R^{2   k}   \right]
  \alpha_k(\varphi_U) \T_k(\Sigma)
  \]
  %
  es decir
  %
  \[
  \alpha_k(\varphi_X) = (-2)^k \varphi_U^{(k)}(0) \Esp\left[ R^{2 k} \right]
  \]
  %
  Ahora, $(X-m)^t \Sigma^{-1} (X-m) = R^2 U^t U = R^2$, lo que cierra la prueba.
\end{proof}

Fijense  que  un vector  a  simetr\'ia  eliptica  no admite  necesariamente  una
densidad con respeto a la medida de  Lebesgue, como por ejemplo en el caso de un
vector uniforme  sobre $\Sset_d$  (pero esa tiene  una densidad,  constante, con
respeto a la medida de Haar sobre la esfera). Un otro ejemplo puede ser \ $X = B
G$  \ con  \  $B \sim  \B(p)$  \  y \  $G  \sim \N(0,I)$  \  independiente de  \
$B$. $\Phi_X(\omega)  = p \, e^{-\frac{\|  \omega \|^2}{2}} + 1  - p$ \  no es \
$L_1$,  \ie no tiene  una transformada  de Fourier  inversa usual.  Sin embargo,
cuando un vector eliptici admite una densidad, esa tiene propiedades remarcables
tambi\'en.
%
\begin{teorema}
%
  Sea \ $X \sim \ED(m,\Sigma,\varphi_X)$. Si  admite una  densidad~\footnote{De hecho, sufice  que admita
    una densidad  con respeto  a una medida  que depende solamente  del volumen,
    como la de Lebesgue pero  tambi\'en, de Haar.}, entonces esta densidad tiene
  la forma
  %
  \[
  p_X(x)  = |\Sigma|^{-\frac12} d_X\left( (x-m)^t \Sigma^{-1} (x-m) \right)
  \]
  %
  donde \ $d_X:  \Rset_+ \mapsto \Rset_+$ \ escalar,  es llamada {\em generadora
    de densidad}. Reciprocamente, si la densidad  tiene esta forma, \ $X$ \ es a
  simetr\'ia eliptica.
\end{teorema}
%
\begin{proof}
  Si perdida de generalidad, se puede considerar \ $X \sim \ED(0,I,\varphi_X)$ \
  y recuperar el  caso general por cambio de variables.  Entonces, por cambio de
  variables  (ver secci\'on~\ref{Sec:MP:Transformacion}) tenemos  para cualquier
  matriz ortogonal \ $O$ \ y cualquier \ $x$
  %
  \[
  p_X(x) = \Phi_{O X}(x) = |O|^{-\frac12} p_X\left( O^{-\frac12} x \right) = p_X\left( O^{-\frac12} x \right)
  \]
  %
  siendo \ $|O|  = 1$~\cite{Bha97, HorJoh13}. $O^{-\frac12}$ \  es tambi\'en una
  matriz  de  rotaci\'on,  probando de  que  \  $p_X$  \ queda  invariante  bajo
  cualquier roraci\'on  de su  argumento, es decir  que depende solamente  de la
  norma de $x$.
\end{proof}

De este resultado, cuando \ $X$ \ admite una densidad de probablidad, se escribe tambien
%
\[
X \sim \ED(m,\Sigma,d_X)
\]
%
a\'un que puede ser confuso.
% (el uso de la letra $d$ o $\varphi$ permite diferenciar).

Claramente, para \ $X \sim  \ED(m,\Sigma,d_X)$, los niveles de probabildad \ $\{
x \tq p_X(x)  = c \} = \left\{  x \tq (x-m)^t \Sigma^{-1} (x-m) =  c \right\}$ \
son   elipsiodes  centrados   en   \  $m$,   de   direcciones  y   estiramientos
respectivamente  dados  por los  autovectores  y  autovalores  de $\Sigma$.  Eso
justifica tambi\'en la denominaci\'on ``$X$ \ a distribuci\'on eliptica''.

Como lo vimos, de una forma, toda las caracterisricas estadisticas de \ $X$ \ es
en el  ``rayo'' \ $R \egald  \sqrt{(X-m)^t \Sigma^{1} (X-m)}$. En  lo que sigue,
sin perdida de generalidad, se puede concentrarse en $X \ED(0,I,d_X)$.

Primero, se puede escribir la ley de $R$ a partir de $d_X$:
%
\begin{teorema}[Densidad del rayo]\label{Teo:MP:DensidadRayo}
  Sea $X \sim \ED(0,I,d_X)$ y $R  \egald \|X\|$. Si $X$ admite una densidad, $R$
  admite tambi\'en una densidad que se escribe
  %
  \[
  p_R(r)  =  \frac{2  \pi^{\frac{d}{2}}}{\Gamma\left(  \frac{d}{2}  \right)}  \,
  r^{d-1} \, d_X\left( r^2 \right)
  \]
\end{teorema}
%
\begin{proof}
  Como lo  hemos visto en la prueba  del teorema~\ref{Teo:MP:MezclaUniforme}, la
  funci\'on de repartici\'on de $R$ se escribe
  %
  \[
  F_R(r) = \int_{\Bset_d(0,r)} dP_X(x)
  \]
  %
  es decir, $P_X$ admitiendo una densidad
  %
  \[
  F_R(r) = \int_{\Bset_d(0,r)} d_X\left( x^t x \right) \, dx
  \]
  %
  lo que da, de~\cite[Ec.~4.642]{GraRyz15}
  %
  \[
  F_R(r)  =  \frac{2  \pi^{\frac{d}{2}}}{\Gamma\left(  \frac{d}{2}  \right)}  \,
  \int_0^r \rho^{d-1} d_X\left( \rho^2 \right) \, d\rho
  \]
  %
  $F_R$   es    continua   y   diferenciable,   llegando    al   resultado   del
  teorema.  Volveremos   a  este  resultado  m\'as  adelante   tratando  de  las
  coordenadas esfericas.
\end{proof}

De  este  resultado,  se puede  ahora  dar  la  relaci\'on  que existe  entre  \
$\varphi_X$ \  y \ $d_X$  \ siendos \  $\Phi_X$ \ y  \ $p_X$ \  relacionados por
transformada de Fourier.
%
\begin{teorema}
%
  Sea  \  $X  \sim   \ED(m,\Sigma,\varphi_X)  \equiv  \ED(m,\Sigma,d_X)$  \  las
  generadoras caracter\'isticas y de densidad son relacionadas por
  %
  \[
  \varphi_X\left(   w^2   \right)   =   \left(   2   \pi   \right)^{\frac{d}{2}}
  w^{1-\frac{d}{2}}  \int_{\Rset_+}  r^{\frac{d}{2}}  d_X\left( r^2  \right)  \,
  J_{\frac{d}{2}-1}( r w) \, dr
  \]
  %
  y reciprocamente
  %
  \[
  d_X\left( r^2 \right) =  \left( 2 \pi \right)^{-\frac{d}{2}} r^{1-\frac{d}{2}}
  \int_{\Rset_+}     w^{\frac{d}{2}}    \varphi_X\left(    w^2     \right)    \,
  J_{\frac{d}{2}-1}( r w) \, dw
  \]
  %
  La transformaci\'on dando \  $w^{\frac{d}{2}-1} \varphi_X\left( w^2 \right)$ \
  a partir  de \  $r^{\frac{d}{2}-1} d_X\left( r^2  \right)$ \ es  conocida como
  {\em transformada de Hankel} de orden \ $\frac{d}{2}-1$~\cite{Lor54, Pou10}. A
  veces, la transformaci\'on dando \ $\varphi_X\left( w^2 \right)$ \ a partir de
  \ $d_X\left( r^2 \right)$ \ es llamada {\em transformada de Hankel modificada}
  de orden \ $\frac{d}{2}-1$.
\end{teorema}
%
\begin{proof}
  Hay varias pruebas de este resultado. Una elegante se basa sobre la generadora
  caracteristica  de variable  $U  \sim \U(\Sset_d)$.  Primero,  sin perdida  de
  generalidad, consideramos $m = 0, \:  \Sigma = I$. Entonces, de la escritura \
  $X \egald R \, U$ \ tenemos
  %
  \begin{eqnarray*}
  \Phi_X(\omega) & = & \Esp\left[ e^{\imath \, R \omega^t U} \right]\\[2mm]
  %
  & = & \Esp\left[ \Esp\left[ \left. e^{\imath \, R \omega^t U} \right| R \right]
  \right]\\[2mm]
  %
  & = & \Esp\left[ \Phi_U\left( R^2 \| \omega \|^2 \right)  \right]
  \end{eqnarray*}
  %
  Es    decir,    del    ejemplo~\ref{Ej:MP:GeneCaracUniformeEsfera}    y    del
  teorema~\ref{Teo:MP:DensidadRayo} se obtiene
  %
  \[
  \varphi_X\left(  \|  \omega  \|^2  \right)  =  2^{\frac{d}{2}-1}  \Gamma\left(
    \frac{d}{2}  \right)  \int_{\Rset_+}  \left(   r  \|  \omega  \|  \right)^{-
    \frac{d-2}{2}}  J_{\frac{d}{2}-1}  \left( r  \|  \omega  \| \right)  \frac{2
    \pi^{\frac{d}{2}}}{\Gamma\left(  \frac{d}{2} \right)}  r^{d-1}  \, d_X\left(
    r^2 \right) \, dr
  \]
  %
  Eso da  la expresi\'on  de \ $\varphi_X$  \ comp  transformada de Hankel  de \
  $d_X$. Para la transformaci\'on inversa, sufice recordarse que $\Phi_X$ siendo
  transformada  de  Fourier  de  $p_X$,  tenemos $p_X$  tranformada  inversa  de
  $\Phi_X$.  Luego,  por  simetr\'ia  (cambio  de variables  $w  \to  -w$,  esta
  transformada inversa  es nada mas que  la transformada directa,  por un factor
  $(2 \pi)^{-d}$ (ver teoremas~\ref{Teo:MP:InversionDensidad}).
\end{proof}

Volvemos a los ejemplos:
%
\begin{ejemplo}[Distribuci\'on gausiana - continuaci\'on]
%
  En el caso gausiano, se obtiene sencillamente
  %
  \[
  d_X\left(r^2\right) \propto e^{- \frac{r^2}{2}}
  \]
  %
  dando
  %
  \[
  p_R(r) \propto r^{d-1} e^{- \frac{r^2}{2}}
  \]
  %
  En conclusi\'on, $R^2 \sim \G\left( \frac{d}{2} , \frac12\right)$ ley Gamma.
\end{ejemplo}
%
\begin{ejemplo}[Distribuci\'on Student-t]
%
  En el caso Student-t con $\nu$ grados de libertad, se obtiene sencillamente
  %
  \[
  d_X\left(r^2\right) \propto \left( 1 + \frac{r^2}{\nu} \right)^{-\frac{d+\nu}{2}}
  \]
  %
  dando
  %
  \[
  p_R(r) \propto \frac{r^{d-1}}{\left( 1 + \frac{r^2}{\nu} \right)^{\frac{d+\nu}{2}}}
  \]
  %
  Con \ $F = \frac{R^2}{d}$ \ se obtiene por transformaci\'on
  %
  \[
  p_F(f)   \propto   \frac{f^{\frac{d}{2}-1}}{\left(   1   +   \frac{d}{\nu}   f
    \right)^{\frac{d+\nu}{2}}}
  \]
  %
  conocido como ley de Fisher-Snedecor (o $F$), de grados de libertad $(d,\nu)$,
  o tipo Pearson VI, o  beta de secunda especie~\cite{JohKot95:v2, Muk00, Bre88,
    IbaPer12} (ratio de Gamma independientes).
\end{ejemplo}
%
\begin{ejemplo}[Distribuci\'on Student-r]
%
  En el caso Student-r con $\nu$ grados de libertad, se obtiene sencillamente
  %
  \[
  d_X\left(r^2\right)      \propto     \left(     1      -     \frac{r^2}{\nu+2}
  \right)^{\frac{\nu-d}{2}} \un_{(0 \; \nu+2)}\left( r^2 \right)
  \]
  %
  dando
  %
  \[
  p_R(r) \propto r^{d-1}  \left( 1 - \frac{r^2}{\nu+2} \right)^{\frac{\nu-d}{2}}
  \un_{(0 \; \nu+2)}\left( r^2 \right)
  \]
  %
  as\'i    que   \   $\frac{R^2}{\nu+2}    \sim   \beta\left(    \frac{d}{2}   ,
    \frac{\nu-d}{2}+1 \right)$ \ distribuci\'on beta.
\end{ejemplo}

Tratando de  vector a simetr\'ia  esferica, resuelte frecuentemente  m\'as comodo
tratarlo en su representaci\'on en coordenadas hiperesfericas, es decir, para $d
\ge 2$
%
\[
x_i = r \left( \prod_{k=1}^{i-1} \sin\theta_k \right) \cos \theta_i, \quad 1 \le
i \le d
\]
%
con
%
\[
(r,\theta_1,\ldots,\theta_{d-1}) \in \Rset_+ \times [0 \; \pi)^{d-2} \times [0 \; 2 \pi)
\]
%
y las convenciones
%
\[
\theta_d = 0, \quad \prod_{k=1}^{0} = 1
\]
%
\SZ{HAcer un dibujo para $d = 2, 3$}

En  el caso  de vector  a simetr\'ia  esferica, aparece  que el  rayo $R$  y los
angulos     son     independientes      y     se     puede     calcular     cada
distribuci\'on~\cite{FanKot90, Lor54, Zoz, toto, titi}:
%
\begin{teorema}
  Sea  \  $X  \sim  \ED(0,I,d_X)$  \  y \  su  representaci\'on  en  coordenadas
  hiperesfericas \  $X_i = R \left( \prod_{k=1}^{i-1}  \sin\Theta_k \right) \cos
  \Theta_i, \quad 1 \le  i \le d$. Entonces $R$ y los $\Theta_i,  \: 1 \le i \le
  d-1$ \ son independientes y
  %
  \[
  p_R(r) = \frac{2  \pi^{\frac{d}{2}}}{\Gamma\left( \frac{d}{2} \right)} r^{d-1}
  d_X\left( r^2 \right)
  \]
  %
  \[
  p_{\Theta_i}(\theta_i)        =       \frac{\Gamma\left(       \frac{d-j+1}{2}
    \right)}{\sqrt{\pi}   \,  \Gamma\left(   \frac{d-j}{2}  \right)}   \,  \big(
  \sin\theta_i \big)^{d-i-1}  \, \un_{[0 \;  \pi)}(\theta_i), \quad 1 \le  i \le
  d-2 , \qquad p_{\Theta_{d-1}}(\theta_{d-1}) =  \frac{1}{2 \pi} \, \un_{[0 \; 2
    \pi)}(\theta_{d-1})
  \]
  %
%  y
%  %
%  \[
%  p_{\Theta_{d-1}}(\theta_{d-1})   =   \frac{1}{2   \pi}   \,   \un_{[0   \;   2
%    \pi)}(\theta_{d-1})
%  \]
\end{teorema}
%
\begin{proof}
  Sea      la       transformaci\'on      $g:      (x_1,\ldots,x_d)      \mapsto
  (r,\theta_1,\ldots,\theta_{d-1})$. La jacobiana de $g^{-1}$ tiene la forma
  %
  \[
  \Jac_{g^{-1}} = \begin{bmatrix}
  %
    \frac{\partial x_1}{\partial r} & \frac{\partial x_1}{\partial \theta_1} & 0 & \cdots & 0\\
  %
    \vdots & \vdots & \ddots & \ddots & \vdots\\
  %
    \vdots & \vdots &  & \ddots  & 0\\
  %
    \frac{\partial x_{d-1}}{\partial r} & \frac{\partial x_{d-1}}{\partial
    \theta_1} & \cdots & & \frac{\partial x_{d-1}}{\partial \theta_{d-1}}\\
  %
    \frac{\partial x_d}{\partial  r} & \frac{\partial  x_d}{\partial \theta_1} &
    \cdots & \cdots & \frac{\partial x_d}{\partial \theta_{d-1}}
  %
  \end{bmatrix}
  \]
  %
  Desarrolando   el   determinante  por   la   \'ultima   columna  por   ejemplo
  (ver~\cite{Bha97, HorJoh13}), y as\'i por inducci\'on se obtiene
  %
  \[
  \left|   \Jac_{g^{-1}}  \right|  =   r^{d-1}  \prod_{j=1}^{d-2}   \left(  \sin
    \theta_i\right)^{d-j-1}
  \]
  %
  Entonces,  por  transformaci\'on  (ver  secci\'on~\ref{Sec:MP:Transformacion})
  tenemos
  %
  \[
  f_{R,\Theta_1,\ldots,\Theta_{d-1}}(r,\theta_1,\ldots,\theta_{d-1}) = d_X\left(
    r^2    \right)     r^{d-1}    \prod_{j=1}^{d-2}    \left(     \left(    \sin
      \theta_i\right)^{d-j-1} \un_{[0 \; \pi)}(\theta_i) \right) \, \un_{[0 \; 2
    \pi)}(\theta_{d-1})
  \]
  %
  Claramente  se  factoriza  probando  la  independencia  y  la  forma  de  cada
  distribuci\'on   marginal.    El   factor   viene    de   la   normalizaci\'on
  (ver~\cite[Ec.~8.380-2]{GraRyz15}   para  los   angulos,   lo  que   determina
  necesariamente el del rayo).
\end{proof}
%
Obviamente,   se   recupera   la   ley   de   \   $R   \egald   \|X\|$   \   que
encontramos.  Ad\'emas, estas coordenadas  hiperesfericas, a  $r=1$, parametriza
$\Sset_d$  y permite  por ejemplo  de probar  la independencia  entre  $\|X\|$ y
$\frac{X}{\|X\|}$ (y entonces la  escritura en mezcla), de calcular directamente
\ $\Phi_U(\omega)$ \ para \ $U  \sim \U(\Sset_d)$, o de vincular las generadoras
caracter\'istica y de densidad entre otros.

En la familia  eliptica, hay una subfamilia particular  que queda invariante por
marginalizaci\'on, como la gausiana por ejemplo:
%
\begin{definicion}[Consistencia~\cite{Yao73, Kan94}]
%
  Sea \  $X = \begin{bmatrix} X_1 &  \cdots & X_d \end{bmatrix}$  \ a simetr\'ia
  eliptica  de  generadora  de  densidad  $d_X$.   Este  vector  es  dicho  {\em
    consistente}  si  la  generadora  de  densidad \  $d_{\widetilde{X}}$  \  de
  $\widetilde{X} = \begin{bmatrix} X_1 &  \cdots & X_{d'} \end{bmatrix}, \: d' <
  d$ \ tiene la misma forma que \ $d_X$ \ donde el par\'ametro dimensional \ $d$
  \ es  reemplazado por  \ $d'$.

  Se proba  que, equivalentemente, la generadora caracteristica  \ $\varphi_X$ \
  no  es relacionada explicitamente  a $d$  (ver~\cite{Kan94, FanKot90}  para la
  prueba).   Entonces,  m\'as  all\'a,  $\varphi_X$  va  a  ser  una  generadora
  caracter\'istica  de  un vector  aleatorio  de  cualquier  dimensi\'on $d  \in
  \Nset^*$,  \ie por  marginalizaci\'on, pero  tambi\'en por  ``extensi\'on'' de
  dimensi\'on (a dimensi\'on dada, puede  ser vista como marginales de un vector
  de misma ley de dimensi\'on m\'as grande).
\end{definicion}


\begin{ejemplo}[Distribuci\'on gausiana - continuaci\'on]
%
  La gausiana es consistente. De hecho, tenemos para cualquier dimensi\'on $d$
  %
  \[
  d_X\left(r^2\right)  =  (2   \pi)^{-\frac{d}{2}}  e^{-  \frac{r^2}{2}}
  %    \qquad     \mbox{y}    \qquad    \forall    \,    d'     <    d,    \quad
  % d_{\widetilde{X}}\left(r^2\right) = (2
  % \pi)^{-\frac{d'}{2}} e^{- \frac{r^2}{2}}
  \]
  %
  forma dada.  Las marginales de  una gausiana es gausiana, y cualquier gausiana
  puede ser vista como marginale de una gausiana de dimensi\'on m\'as grande.

  Por un otro lado tenemos
  \[
  \varphi_X\left( w^2 \right) =  e^{- \frac{w^2}{2}}
  \]
  %
  independiente de la dimensiona $d$.
\end{ejemplo}
%
\begin{ejemplo}[Distribuci\'on Student-t - continuaci\'on]
%
  La Student-t es tambi\'en consistence: tenemos
  %
  \[
  \varphi_X\left(  w^2 \right)  = \frac{\nu^{\frac{\nu}{4}}}{2^{\frac{\nu}{2}-1}
    \,   \Gamma\left(    \frac{\nu}{2}   \right)}   \,    w^{\frac{\nu}{2}}   \,
  K_{\frac{\nu}{2}}(\sqrt{\nu} w)
  \]
  %
  independiente de  la dimension $d$.

  Por  un  otro  lado,  por  transformada  inversa  de  Hankel,  para  cualquier
  dimensi\'on $d$ (ver~\cite[Ec.~6.576-7]{GraRyz})
  %
  \[
  d_X\left( r^2 \right)    =   \frac{\Gamma\left(   \frac{d+\nu}{2}
    \right)}{(\pi \nu)^{\frac{d'}{2}} \Gamma\left( \frac{\nu}{2} \right)} \left(
    1 + \frac{r^2}{\nu} \right)^{- \frac{d+\nu}{2}}
  \]
  %
  Las marginales  de un Student-t con  $\nu$ grados de  libertad queda Student-t
  con  $\nu$  grados de  libertad  y cualquier  Student-t  con  $\nu$ grados  de
  libertad pued  ser vista  como marginal  de un Student-t  con $\nu$  grados de
  libertad de dimensi\'on m\'as grande.
\end{ejemplo}

\begin{ejemplo}[Distribuci\'on student-$r$ - continuaci\'on]
  $X \sim \R_\nu(m,\Sigma)$ no es consistente. Puede parecer contradictorio porque las  marginales de $X$ son student-$r$ con grado de libertad $\nu$. \SZ{Sin embarfgo}

%  En  calculos, recuendense del  ejemplo~\ref{Ej:MP:GeneCaracUniformeEsfera} que
%  la generadora caracter\'istica toma la forma
%  %
%  \[
%  \varphi_X\left(  w^2  \right)  =  2^{\frac{d}{2}-1}  \Gamma\left(  \frac{d}{2}
%  \right) \, w^{1-\frac{d}{2}} \, J_{\frac{d}{2}-1}\left( w \right)
%  \]
%  %
%  depende explicitamente de  $d$. M\'as all\'a, para $d'  < d$, por transformada
%  inversa de Hankel y~\cite[Ec.~6.575-1]{GraRyz15}, se obtiene
%  %
%  \[
%  d_{\widetilde{X}}\left(   r^2   \right)   =   \frac{\Gamma\left(   \frac{d}{2}
%    \right)}{\pi^{\frac{d'}{2}} \Gamma\left( \frac{d-d'}{2}  \right)} \left( 1 -
%    r^2 \right)^{\frac{d-2-d'}{2}} \un_{(0 \; 1)}(r)
%  \]
%  %
%  y no existe para  $d' > d$.  Claramente lar marginales depende  de ambas $d$ y
%  $d'$;  no son  uniforma, como  lo vimos  sin  calculos y  no se  puede ver  la
%  uniforma sobre la  esfera como marginal de un  vector aleatorio de dimensi\'on
%  m\'as  alta.  De  hecho, se  puede notar  que las  marginales de  \ $U$  \ son
%  Student-r con  \ $\nu = d-2$  \ grados de  libertad, a condici\'on que  $\nu >
%  d'-2$, es decir sol\'o cuando $d'  < d$ (ver~\cite{titi, toto, Zoz}). Cuando \
%  $d' = d-1$, la distribuci\'on diverge en los bordes de. Notar que si no cambia
%  el grado de libertad para cualquier marginales, depende de la dimensi\'on $d$:
%  la generadora de densidad no depende solamente de $d'$.
\end{ejemplo}

\begin{ejemplo}[Distribuci\'on uniforme sobre la esfera - continuaci\'on]
  Claramente, $U \sim  \U(\Sset_d)$ (se supone no es consistente: las  marginales de $U$ no
  pueden ser uniformes sobre $\Sset_{d'}$;  sin calculo, se queda claro que para
  $d' =  d-1$, el  vector es  definido en la  bola $\Bset_{d-1}(\Rset)$,  y, por
  inducci\'on es lo mismo para cualquier dimensi\'on m\'as baja.

  En  calculos, recuendense del  ejemplo~\ref{Ej:MP:GeneCaracUniformeEsfera} que
  la generadora caracter\'istica toma la forma
  %
  \[
  \varphi_X\left(  w^2  \right)  =  2^{\frac{d}{2}-1}  \Gamma\left(  \frac{d}{2}
  \right) \, w^{1-\frac{d}{2}} \, J_{\frac{d}{2}-1}\left( w \right)
  \]
  %
  depende explicitamente de  $d$. M\'as all\'a, para $d'  < d$, por transformada
  inversa de Hankel y~\cite[Ec.~6.575-1]{GraRyz15}, se obtiene
  %
  \[
  d_{\widetilde{X}}\left(   r^2   \right)   =   \frac{\Gamma\left(   \frac{d}{2}
    \right)}{\pi^{\frac{d'}{2}} \Gamma\left( \frac{d-d'}{2}  \right)} \left( 1 -
    r^2 \right)^{\frac{d-2-d'}{2}} \un_{(0 \; 1)}(r)
  \]
  %
  y no existe para  $d' > d$.  Claramente lar marginales depende  de ambas $d$ y
  $d'$;  no son  uniforma, como  lo vimos  sin  calculos y  no se  puede ver  la
  uniforma sobre la  esfera como marginal de un  vector aleatorio de dimensi\'on
  m\'as  alta.  De  hecho, se  puede notar  que las  marginales de  \ $U$  \ son
  Student-r con  \ $\nu = d-2$  \ grados de  libertad, a condici\'on que  $\nu >
  d'-2$, es decir sol\'o cuando $d'  < d$ (ver~\cite{titi, toto, Zoz}). Cuando \
  $d' = d-1$, la distribuci\'on diverge en los bordes de. Notar que si no cambia
  el grado de libertad para cualquier marginales, depende de la dimensi\'on $d$:
  la generadora de densidad no depende solamente de $d'$.
\end{ejemplo}

\SZ{
\begin{itemize}

\item Volver a los cumulantes $2 k$: se puede decir m\'as?

\item Maxwell-Hershel
%\item Ver Kano, Rao

\item GSM (y consistante) %
  Esta \'ultima  aserci\'on es precisamente una caracterizaci\'on  posible de la
  GSM~\cite{Yao94}.


\item  Hablar de  nuevo de   de Student-t como  GSM~\cite{toto, titi,  FanKot90,
    KotNad04} y la Student-r con $r$ pero que no es GSM (nota con casi GSM X/sqrt(G+||X||)).

\end{itemize}

Citar mi HDR


Ver BilBre def 13.3


Ver 1.5 de KotNad04 entre otros, Mui82, m\'as lis ref.

}

\SZ{Caso complejo, con matriz unitaria

Ver Shiryayev}