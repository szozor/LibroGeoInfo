\subsubseccion{Distribuci\'on uniforme sobre un intervalo}
\label{Sssec:MP:UniformeContinua}

Esta distribuci\'on es  la m\'as natural que se usa  cuando queremos modelar una
falta de  informaci\'on sobre una variable,  sabiendo que vive en  un espacio de
volumen  finito: sin  a  priori  m\'as, una  tendencia  natural/intuitiva es  de
asignar la  ``misma probabilidad''  a cada punto  del conjunto.   En particular,
aparece as\'i  naturalmente en  la inferencia Bayesiana  que consiste  a modelar
como aleatorio  un par\'ametro  que se quierre  inferir~\cite{Rob07} (la  ley es
dicha  ley  {\em a  priori};  ver  tambi\'en~\cite{Bay63} o~\cite{Lap12,  Lap14,
  Lap20}; tal a priori es conocido como a a priori de Laplace).

Se denota $X \, \sim \, \U([a \; b])$. Las caracter\'isticas de \ $X$ \ son las
siguientes:

\begin{caracteristicas}
%
Dominio de definici\'on & $\X = [a \; b]$\\[2mm]
\hline
%
Par\'ametros & $(a,b) \in \Rset, \: b > a$\\[2mm]
\hline
%
Densidad de probabilidad & $p_X(x) = \frac{1}{b-a}$\\[2mm]
\hline
%
Promedio & $\displaystyle m_X = \frac{a+b}{2}$\\[2mm]
\hline
%
Varianza & $\displaystyle \sigma_X^2 = \frac{(b-a)^2}{12}$\\[2mm]
\hline
%
\modif{Sesgo} & $\gamma_X = 0$\\[2mm]
\hline
%
Curtosis por exceso & $\displaystyle \widebar{\kappa}_X = -\frac65$\\[2mm]
\hline
%
Generadora de momentos & $\displaystyle M_X(u) = \frac{ e^{b u} - e^{a u}}{u}$ \
para~\footnote{En el caso l\'imite \ $u \to  0$, \ $\lim_{u \to 0} \frac{ e^{b u}
- e^{a u}}{u} = b-a$, y similarmente para la funci\'on caracter\'istica}  \ $u \in \Cset^d$\\[2mm]
\hline
%
Funci\'on caracter\'istica & $\displaystyle  \Phi_X(\omega) = \frac{ e^{\imath a
\omega} - e^{\imath b \omega}}{\imath \, \omega}$
\end{caracteristicas}

% Momentos & $ \Esp\left[ X^k \right] = p^k$\\[2mm]
% Momento factorial & $\Esp\left[ (X)_k \right] = ?$\\[2mm]
% Generadora de probabilidad & $G_X(z) = e^{\lambda (z-1)}$ \ para \ $z \in \Cset$\\[2mm]
% modo 0
% Mediana \ln(2)/\lambda
% CDF 1-e^{-\lambda x}

Obviamente, se puede escribir \ $X \, \egald  \, a + (b-a) U$ \ donde \ $\egald$
\ significa que la equalidad es en distribuci\'on (las variables tienen la misma
distribuci\'on de probabilidad), con \ \ $U \, \sim \, \U \left( [ 0 \; 1 ]
\right)$ \ llamada {\em uniforme estandar}.

La densidad de probabilidad y funci\'on de repartici\'on de la variable estandar
son representadas en la figura Fig.~\ref{Fig:MP:Uniformecontinua}.
%
\begin{figure}[h!]
\begin{center} \input{TIKZ_MP/UniformeContinua} \end{center}
% 
\leyenda{Ilustraci\'on  de  una densidad  de  probabilidad  uniforme  (a), y  la
funci\'on de repartici\'on asociada (b).}
\label{Fig:MP:Uniformecontinua}
\end{figure}

Una nota  importante es que cada ley  continua es v\'inculada a  la ley uniforme
sobre $(0 \; 1)$ de la manera siguiente:
%
\begin{lema}[Inversi\'on]\label{Lem:MP:InversionUniforme}
Sea $X$, continua sobre $\X \subset \Rset$, de funci\'on de repartici\'on $F_X$. Entonces
%
\[
U \equiv F_X(X) \sim \U(0 \; 1)
\]
%
Reciprocamente, definiendo la funci\'on de repartici\'on inversa (o quantile)
%
\[
F_X^{-1}(u) = \inf \{ x \tq F(x) \ge u \}
\]
%
si $V \sim \U( 0 \; 1 )$,
%
\[
Y = F_X^{-1}(V) \quad \Rightarrow \quad F_Y(y) = F_X(y)
\]
\end{lema}
%
Cuando  $F_X$ se  inversa  sencillamente eso  da  una manera  sencille de  tirar
sampleos de funci\'on de repartici\'on $F_X$ a partir de sampleos tirados seg\'un
una ley uniforme.
%
\begin{proof}
Inmediatamente, $F_X$ siendo creciente,
%
\begin{eqnarray*}
P(U \le u) & = &  P( F_X(X) \le u)\\[2mm]
%
& = & P(X \le F_X^{-1}(u))\\[2mm]
%
& = & F_X\left( F_X^{-1} (u) \right)
\end{eqnarray*}
%
Similarmente
%
\begin{eqnarray*}
P(Y \le y) & = &  P( F_X^{-1}(V) \le y)\\[2mm]
%
& = & P(V \le F_X(y))\\[2mm]
%
& = & F_X(y)
\end{eqnarray*}
%
\end{proof}

De manera  general, para  cualquier ensemble $\D  \subset \Rset^d$ de  volumen \
$|\D|$ \,  la variable uniforma sobre $\D$  tiene la densidad con  respecto a la
medida  ``natural'' sobre  $\D$  (Lebesque, discreta,\ldots)  constante sobre  \
$\D$,
%
\[
p_X(x) = \frac{1}{|\D|} \un_{\D}(x)
\]
%
La media va a ser el centro de gravedad de $\D$.

Vamos  a  ver  el  el   cap\'itulo  siguiente  que  esta  distribuci\'on  es  la
distribuci\'on  definida sobre  un conjunto  de volumen  finito que  maximiza la
entrop\'ia, \ie  que es la  ``menos informativa''. Por  ejemplo, si se  busca un
par\'ametro  modelizado como  aleatorio (enfoque  Bayesiano), definido  sobre un
conjunto de volumen finito, sin  a priori m\'as, una tendencia natural/intuitiva
es de asignar la ``misma probabilidad'' a cada punto del conjunto. Aparece as\'i
naturalmente en la inferencia Bayesiana~\cite{Rob07}.
 
Notar que  cuando $b \to a$,  la variable tiende a  una variable cierta  $X = a$
(ver principio de esta secci\'on).
