\subsubseccion{Distribuci\'on Student-$r$ multivariada}
\label{Sssec:MP:StudentR}

Estas distribuciones  aparecieron esencialmente a  trav\'es el sistema  dicho de
Pearson en el fin  del siglo 19~\cite{Pea95, JohKot95:v1, JohKot95:v1, KotBal00,
  FanKot90}.   M\'as   especialmente  son  conicidos  como   {\em  Pearson  tipo
  IIIa$\alpha$}.   A veces,  se  encuentra en  f\'isica  la denominaci\'on  {\em
  Student-$r$}; aparecen como maximizantes de  le entrop\'ia de R\'enyi, o la de
Tsalis  de la  misma manera  que las  Student-$t$ usual,  pero cuando  el indice
entropico  es mayor  que la  unidad (ver  capitulo~\ref{Cap:SZ:Informacion} para
tener m\'as detalles)~\cite{JohVig07, CosHer03, VigHer04, Tsa88, Tsa99}.

Se denota con \ $X \sim \R_\nu(m,\Sigma)$ \ con \ $m \in \Rset^d$, \ $\Sigma \in
P_d^+(\Rset)$. $m$ \ es llamado  {\em par\'ametro de posici\'on}, \ $\Sigma$
  \ es  llamada {\em matriz  caracter\'istica} y \  $\nu > d-2$ \  llamado {\em
  grados  de  libertad}.   Las  caracter\'isticas  de una  Student-$r$  son  las
siguientes:
%
\begin{caracteristicas}
%
Dominio de definici\'on & $\begin{array}{lll} \X & = & m + \Sigma^{\frac12} \,
\Bset_d\left( 0 , \sqrt{\nu+2} \right)\\[1mm] & = & \left\{ x \in \Rset^d \tq
\Sigma^{-\frac12} (x-m) \in \Bset\left( 0 , \sqrt{\nu+2} \right)
\right\} \end{array}\vspace{1mm}$\\[2mm]
\hline
%
Par\'ametro & $\nu > d-2$ \ (grados de libertad), \ $m \in \Rset^d$ \
(posici\'on), \ $\Sigma \in P_d^+(\Rset)$ \ (matriz caracer\'istica)\\[2mm]
\hline
%
Densidad de probabilidad & $\displaystyle p_X(x) = \frac{\Gamma\left(
\frac{\nu}{2} + 1 \right)}{\pi^{\frac{d}{2}} (\nu+2)^{\frac{d}{2}} \Gamma\left(
\frac{\nu-d}{2} + 1 \right) \, \left| \Sigma \right|^{\frac12}} \, \left( 1 -
\frac{(x-m)^t \Sigma^{-1} (x-m)}{\nu+2} \right)_+^{\!\frac{\nu-d}{2}}$\\[2mm]
\hline
%
Promedio & $\displaystyle m_X = m$.\\[2.5mm]
\hline
%
Covarianza & $\displaystyle \Sigma_X = \Sigma$.\\[2.5mm]
\hline
%
\modif{Asimetr\'ia} & $\displaystyle \gamma_X = 0$.\\[2mm]
\hline
%
Curtosis por exceso & $\displaystyle \widebar{\kappa}_X = \frac{- 2}{\nu+4}
\sum_{i,j=1}^d \Big( \! \left(
    \un_i \un_i^t \right) \otimes \left(  \un_j \un_j^t \right) +  \left( \un_i
    \un_j^t \right) \otimes \left( \un_i  \un_j^t \right) + \left( \un_i \un_j^t
  \right) \otimes \left( \un_j \un_i^t \right) \! \Big)$.\\[2mm]
\hline
%
Funci\'on caracter\'istica & $\displaystyle
\Phi_X(\omega) = \frac{2^{\frac{\nu}{2}} \Gamma\left(
\frac{\nu}{2} +1 \right)}{(\nu+2)^{\frac{\nu}{4}}} \, e^{\imath \omega^t m} \, \left( \omega^t \Sigma \omega
\right)^{- \frac{\nu}{4}} J_{\frac{\nu}{2}}\left( \sqrt{(\nu+2) \, \omega^t \Sigma
\omega} \right)$
\end{caracteristicas}

Nota: nuevamente se puede escribir $X \, \egald \, \Sigma^{\frac12} R + m$ \ con
\ $R \, \sim \, \R_\nu(0,I)$ \ donde \ $R$ \ es dicha {\em Student-$r$ estandar}
y  las caracter\'isticas  de \  $X$  \ son  v\'inculadas a  las  de \  $R$ \  (y
vice-versa) por transformaci\'on lineal (ver secciones anteriores).

La densidad de probabilidad Student-$r$ estandar y la funci\'on de repartici\'on
en el caso escalar  son representadas en la figura Fig.~\ref{Fig:MP:StudentR}-(a)
y    (b)   y    una   densidad    en   un    contexto    bi-dimensional   figura
Fig.~\ref{Fig:MP:StudentR}(c).
%%
\begin{figure}[h!]
\begin{center} \input{TIKZ_MP/StudentR} \end{center}
% 
\leyenda{Ilustraci\'on  de  una  densidad  de probabilidad  Student-$r$  escalar
  estandar (a),  y la funci\'on  de repartici\'on asociada  (b) con \ $\nu  = 0$
  (linea mixta), \ $\nu = 1$ (linea guionada), \ $\nu = 3$ (linea llena), \ $\nu
  = 11$ (linea  punteada) \ y \  $\nu \to +\infty$ (linea llena  fina; ver m\'as
  adelante)  grados  de  libertad,   as\'i  que  una  densidad  de  probabilidad
  Student-$r$ bi-dimensional con \ $\nu = 3$ \ grado de libertad, centrada, y de
  matriz caracter\'istica \ $\Sigma = R(\theta) \Delta^2 R(\theta)^t$ \ con
  \  $R(\theta)  =  \protect\begin{bmatrix}  \cos\theta  &  -  \sin\theta\\[2mm]
    \sin\theta &  \cos\theta \protect\end{bmatrix}$ \  matriz de rotaci\'on  y \
  $\Delta   =  \diag\left(\protect\begin{bmatrix}  1   &  a\protect\end{bmatrix}
  \right)$ \  matriz de cambio  de escala,  y sus marginales  \ $X_1 \,  \sim \,
  \R_\nu\left(0,\cos^2\theta + a^2  \sin^2\theta \right)$ \ y \  $X_2 \, \sim \,
  \R_\nu\left(0,\sin^2\theta   +  a^2   \cos^2\theta  \right)$   \   (ver  m\'as
  adelante). En la figura, $a = \frac13$ \ y \ $\theta = \frac{\pi}{6}$.}
\label{Fig:MP:StudentR}
\end{figure}

Nota:  en el  caso \  $\nu =  d$ \  la ley  es uniforme  adentro del  dominio de
definici\'on  $X  \sim  \U\left(  m  + \Sigma^{\frac12}  \,  \Bset_d\left(  0  ,
    \sqrt{d+2} \right) \right)$. Para \ $d-2 < \nu < d$ \ la densidad diverge
en los bordes del dominio de definici\'on (divergencia integrable).

Contrariamente al caso gaussiano, de la forma de la densidad de probabilidad, es
claro que si la matriz \ $\Sigma$ \ es diagonal, la densidad no factoriza, as\'i
que  las componentes  del vector  no son  independientes.  Este  ejemplo muestra
claramente y nuevamente  que la reciproca del lema~\ref{Lem:MP:IndependenciaCov}
es falsa en general.

Sin embargo, las distribuciones Student-$r$ tienen varias propiedades notables.

\begin{lema}[Stabilidad por transformaci\'on lineal]
\label{Lem:MP:StabilidadLinealStudentR}
%
  Sea \ $X \, \sim \,  \R_\nu(m,\Sigma)$, \ $A$ \ matriz de \ $\M_{d',d}(\Rset))$
  \ con \ $d' \le d$, y de rango lleno y \ $b \in \Rset^{d'}$. Entonces
  %
  \[
  A X + b\, \sim \, \R_\nu( A m + b , A \Sigma A^t)
  \]
  %
  En particular los componentes de \ $X$ \ son student-$r$,
  %
  \[
  X_i \, \sim \, \R_\nu(m_i , \Sigma_{i,i} )
  \]
\end{lema}
\begin{proof}
  La prueba es inmediata usando  la funci\'on caracter\'istica y sus propiedades
  por  transformaci\'on lineal.  La condici\'on  sobre \  $A$ \  es  necesaria y
  suficiente para que \ $A \Sigma A^t \in P_{d'}^+(\Rset)$.
\end{proof}

\begin{lema}[L\'imite Gausiana]
\label{Lem:MP:LimiteStudentRGaussiana}
%
  Sea \  $X_\nu \, \sim  \, \R_\nu(m,\Sigma)$ \ vector  Student-$r$ parametizado
  por \ $\nu$ \ sus grados de libertad. Entonces
  %
  \[
  X_\nu \, \limitd{\nu \to \infty} \, = \, X \, \sim \, \N(m,\Sigma)
  \]
  %
  con \ $\displaystyle \limitd{}$ \ l\'imite es en distribuci\'on.
\end{lema}
\begin{proof}
  La prueba  es inmediata tomando el  logaritmo de la  densidad de probabilidad,
  usando      la     formula      de     Stirling~\footnote{Ver      nota     de
    pie~\footref{Foot:MP:Stirling}} para  \ $\log\Gamma(z) = \left(  z - \frac12
  \right)  \log  z  -  z  +  \frac12   \log(2  \pi)  +  o(1)$  \  en  \  $z  \to
  +\infty$~\cite{Sti30, AbrSte70, GraRyz15} \  y \ $\frac{\nu-d}{2} \log\left( 1
    - \frac{(x-m)^t  \Sigma^{-1} (x-m)}{\nu} \right) =  - \frac{\nu-d}{2} \left(
    \frac{(x-m)^t \Sigma^{-1} (x-m)}{\nu+2} + o\left( \nu^{-1} \right) \right) =
  - \frac{(x-m)^t \Sigma^{-1}  (x-m)}{2} + o(1)$. Adem\'as, se  nota que $\X \to
  \Rset^d$.
\end{proof}

%Las   variables   Student-t   tienen   varias   representaciones   estocasticas,
%relacionadas a la gausiana~\cite{FanKot90, And03, KotNad04, AndKau65}:
%% ej. KotNad p. 7 para la secunda
%
\begin{lema}[Relaci\'on con la distribuci\'on Gamma]\label{Lem:MP:StudentRGamma}
%
  Sea \ $V \sim \G\left( \frac{\nu-d}{2}+1 \,  , \, \frac12 \right)$ \ y \ $G \,
  \sim \,  \N(0,I)$ \  $d$-dimensional e independientes  de $V$.  Entonces, para
  $\Sigma \in P_d^+(\Rset)$ y $m \in \Rset^d$,
  %
  \[
  \frac{\sqrt{\nu+2} \:  \Sigma^{\frac12} \, G}{\sqrt{V  + \|G\|^2}} \,  \sim \,
  \R_\nu( m , \Sigma )
  \]
  %
\end{lema}
\begin{proof}
  Sea \ $X = \frac{\sqrt{\nu+2} \,  G}{\sqrt{V + \|G\|}}$.  De la nota siguiendo
  la tabla  de caracter\'isticas  es necesario y  suficiente probar que  $X \sim
  \R_\nu(0,I)$.   Veremos en  la secci\'on~\ref{Ssec:MP:FamiliaEliptica}  que $G
  \egald R U$ \ con $R >  0$ de densidad de probabilidad $p_R(r) \propto r^{d-1}
  e^{-\frac{r^2}{2}}$, independiente de \ $U$, vector de distribuci\'on uniforme
  sobre la  esfera $\Sset_d$.  Veremos tambi\'en  que $Y \sim  \R_\nu(0,I)$ \ se
  escribe de  la misma manera  \ $Y  \egald S U$  \ con $S  > 0$ de  densidad de
  probabilidad   $p_S(s)   \propto   s^{d-1}   \left(  1   -   \frac{s^2}{\nu+2}
  \right)_+^{\frac{\nu-d}{2}}$.   Ahora, seg\'un~\cite{FanKot90, Zol86},  si dos
  vectores aleatorios  \ $A$  \ y \  $B$ \  son iguales en  distribuci\'on, para
  cualquier  funci\'one \  $f$, $f(A)  \egald f(B)$.  Entonces, de  la escritura
  estocastica de $G$ tenemos
  %
  \[
  X \egald \frac{\sqrt{d+2} \, R}{\sqrt{V + R^2}} \: U
  \]
  %
  Sea
  %
  \[
  S = \frac{\sqrt{d+2} \, R}{\sqrt{V + R^2}}
  \]
  %
  Claramente,  $R,  V$  siendo  independientes   de  $U$,  la  variable  $S$  es
  independiente de  $U$ en esta  escritura estocastica. Entonces,  sufice probar
  que    $p_S(s)    \propto     s^{d-1}    \left(    1    -    \frac{s^2}{\nu+2}
  \right)_+^{\frac{\nu-d}{2}}$. Por eso, sea
  %
  \[
  T = \sqrt{\frac{V+R^2}{\nu+2}} \qquad \mbox{y} \qquad g: (r,v) \mapsto (s,t)
  \]
  %
  con ambas  \ $(r,v) \in  \Rset_+^2$ \ y  \ $(s,t) \in \Rset_+^2$.   Se calcula
  sencillamente  la  jacobiana  de  $g^{-1}:  (s,t)  \mapsto  \left(  s t  ,  t^2
    (\nu+2-s^2) \right)$ y a continuaci\'on
  %
  \[
  \left| \Jac_{g^{-1}} \right| = 2 \, (\nu+2) \, t^2
  \]
  %
  Del teorema de transformaci\'on~\ref{Teo:MP:TransformacionInyectivaDensidad} y
  de la independencia de $R$ y $V$ tenemos
  %
  \begin{eqnarray*}
  p_{S,T}(s,t) & = & 2 \, (\nu+2) \, t^2 \, p_R(st) \, p_V\left( t^2 (\nu+2-s^2)
  \right)\\[2mm]
  %
  & \propto & t^2 \, (s t)^{d-1} \, e^{-\frac{s^2 t^2}{2}} \, t^{\nu-d} \,
  \left( \nu+2-s^2 \right)_+^{\frac{\nu-d}{2}} \, e^{-\frac{t^2 (\nu+2-s^2)}{2}}
  \end{eqnarray*}
  %
  es decir
  %
  \[
  p_{S,T}(s,t)     \propto    s^{d-1}     \left(    1     -    \frac{s^2}{\nu+2}
  \right)_+^{\frac{\nu-d}{2}} \, t^{\nu+1} \, e^{-\frac12 t^2}
    \]
  %
    Por marginalisaci\'on en $t$, se  obtiene el resultado esperado. Pasando, de
    la forma separable de \ $p_{S,T}$,  vemos que $S$ y $T$ son independientes y
    que $T^2 \sim \G\left( \frac{\nu}{2} , \frac12 \right)$.
\end{proof}

M\'as propiedades de esta distribuci\'on se encuentran en libros especializados,
por ejemplo~\cite{FanKot90, KotBal00} o en~\cite[Sec.~3.2.1]{Zoz12}.

%\

% \SZ{  Como  en el  contexto  Student-$t$,  se  puede imaginar  generalizar  la
%   Student-$r$ al caso matriz-variada  $X$ definido sobre $M_{d,d'}(\Rset)$; se
%   denotar\'a  \  $X \,  \sim  \, \R_\nu(M,\Sigma,\Omega)$  \  donde  \ $M  \in
%   M_{d,d'}(\Rset), \: \Sigma \in  P_d^+(\Rset), \: \Omega \in P_{d'}^+(\Rset)$
%   y  la  densidad  dada   por  $\displaystyle  p_X(x)  =  \frac{\Gamma_d\left(
%       \frac{\nu+d+d'-1}{2}\right)}{\pi^{\frac{\nu     d}{2}}    \Gamma_d\left(
%       \frac{\nu+d-1}{2}\right) \,  \left| \Sigma \right|^{\frac{d'}{2}} \left|
%       \Omega  \right|^{\frac{d}{2}}}  \:  \left|  I  +  \Sigma^{-1}  (x-M)  \,
%     \Omega^{-1}  \,  (x-M)^t  \right|^{-  \frac{\nu+d+d'-1}{2}}$.  Se  refiera
%   a~\cite[Cap.~4]{GupNag99} para tener m\'as detalles.
%}
