\subsubseccion{Distribuci\'on Student-$r$ multivariada}
\label{Sssec:MP:StudentR}

Estas distribuciones  aparecieron esencialmente a  trav\'es el sistema  dicho de
Pearson en el fin del siglo XIX~\cite{Pea95, JohKot95:v1, JohKot95:v1, KotBal00,
  FanKot90}.   M\'as   especialmente  son  conocidos  como   {\em  Pearson  tipo
  IIIa$\alpha$}.   A veces,  se  encuentra en  f\'isica  la denominaci\'on  {\em
  Student-$r$}; aparecen como maximizantes de  la entrop\'ia de R\'enyi, o de la
de Tsalis  de la misma manera que  las Student-$t$ usual, pero  cuando el indice
entr\'opico es  mayor que la unidad  (ver capitulo~\ref{Cap:SZ:Informacion} para
tener m\'as detalles)~\cite{JohVig07, CosHer03, VigHer04, Tsa88, Tsa99}.

Se denota con \ $X \sim \R_\nu(m,\Sigma)$ \ con \ $m \in \Rset^d$, \ $\Sigma \in
\Pos_d^+(\Rset)$. $m$ \ es llamado  {\em par\'ametro de posici\'on}, \ $\Sigma$
  \ es  llamada {\em matriz  caracter\'istica} y \  $\nu > d-2$ \  llamado {\em
  grado  de  libertad}.   Las  caracter\'isticas  de una  Student-$r$  son  las
siguientes:
%
\begin{caracteristicas}
%
Dominio de definici\'on & $\begin{array}{lll} \X & = & m + \Sigma^{\frac12} \,
\Bset_d\left( 0 , \sqrt{\nu+2} \right)\\[1mm] & = & \left\{ x \in \Rset^d \tq
\Sigma^{-\frac12} (x-m) \in \Bset_d\left( 0 , \sqrt{\nu+2} \right)
\right\} \end{array}\vspace{1mm}$\\[2mm]
\hline
%
Par\'ametro & $\nu > d-2$ \ (grado de libertad),\newline $m \in \Rset^d$ \
(posici\'on), \ $\Sigma \in \Pos_d^+(\Rset)$ \ (matriz caracer\'istica)\\[2mm]
\hline
%
Densidad de probabilidad & $\displaystyle p_X(x) = \frac{\Gamma\left(
\frac{\nu}{2} + 1 \right)}{\pi^{\frac{d}{2}} (\nu+2)^{\frac{d}{2}} \Gamma\left(
\frac{\nu-d}{2} + 1 \right) \, \left| \Sigma \right|^{\frac12}} \, \left( 1 -
\frac{(x-m)^t \Sigma^{-1} (x-m)}{\nu+2} \right)_+^{\!\frac{\nu-d}{2}}$\\[2mm]
\hline
%
Promedio & $\displaystyle m_X = m$\\[2.5mm]
\hline
%
Covarianza & $\displaystyle \Sigma_X = \Sigma$\\[2.5mm]
\hline
%
\modif{Asimetr\'ia} & $\displaystyle \gamma_X = 0$\\[2mm]
\hline
%
Curtosis por exceso & $\displaystyle \widebar{\kappa}_X = - \frac{2}{\nu+4} \Big( I \otimes I + \tau_{(2,3)}\big[ I \otimes I \big] + \tau_{(2,4)}\big[ I
\otimes I \big] \Big)$\\[2mm]
%\sum_{i,j=1}^d \Big( \! \left(
%    \un_i \un_i^t \right) \otimes \left(  \un_j \un_j^t \right) +  \left( \un_i
%    \un_j^t \right) \otimes \left( \un_i  \un_j^t \right) + \left( \un_i \un_j^t
%  \right) \otimes \left( \un_j \un_i^t \right) \! \Big)$\\[2mm]
\hline
%
Funci\'on caracter\'istica & $\displaystyle
\Phi_X(\omega) = \frac{2^{\frac{\nu}{2}} \Gamma\left(
\frac{\nu}{2} +1 \right)}{(\nu+2)^{\frac{\nu}{4}}} \, e^{\imath \omega^t m} \, \left( \omega^t \Sigma \omega
\right)^{- \frac{\nu}{4}} J_{\frac{\nu}{2}}\left( \sqrt{(\nu+2) \, \omega^t \Sigma
\omega} \right)$
\end{caracteristicas}

Nota: nuevamente se puede escribir $X \, \egald \, \Sigma^{\frac12} R + m$ \ con
\ $R \, \sim \, \R_\nu(0,I)$ \ donde \ $R$ \ es dicha {\em Student-$r$ estandar}
y  las caracter\'isticas  de \  $X$  \ son  v\'inculadas a  las  de \  $R$ \  (y
vice-versa) por transformaci\'on lineal (ver secciones anteriores).

Unas  densidades  de probabilidad  Student-$r$  estandares  y  las funciones  de
repartici\'on  asociadas en  el  caso  escalar son  representadas  en la  figura
Fig.~\ref{Fig:MP:StudentR}-(a) y  (b) para varios  grado de libertad, y
una densidad en un contexto bi-dimensional figura Fig.~\ref{Fig:MP:StudentR}(c).
%%
\begin{figure}[h!]
\begin{center} \input{TIKZ_MP/StudentR} \end{center}
% 
\leyenda{Ilustraci\'on  de  una  densidad  de probabilidad  Student-$r$  escalar
  estandar (a),  y la funci\'on  de repartici\'on asociada  (b) con \ $\nu  = 0$
  (linea mixta), \ $\nu = 1$ (linea guionada), \ $\nu = 3$ (linea llena), \ $\nu
  = 11$ (linea  punteada) \ y \  $\nu \to +\infty$ (linea llena  fina; ver m\'as
  adelante)  grado   de  libertad,  as\'i  que  una   densidad  de  probabilidad
  Student-$r$ bi-dimensional con \ $\nu = 3$ \ grado de libertad, centrada, y de
  matriz caracter\'istica \ $\Sigma = R(\theta) \Delta^2 R(\theta)^t$ \ con
  \  $R(\theta)  =  \protect\begin{bmatrix}  \cos\theta  &  -  \sin\theta\\[2mm]
    \sin\theta &  \cos\theta \protect\end{bmatrix}$ \  matriz de rotaci\'on  y \
  $\Delta  =  \Diag\left(\protect\begin{bmatrix}  1  &  a\protect\end{bmatrix}^t
  \right)$ \  matriz de cambio  de escala,  y sus marginales  \ $X_1 \,  \sim \,
  \R_\nu\left(0,\cos^2\theta + a^2  \sin^2\theta \right)$ \ y \  $X_2 \, \sim \,
  \R_\nu\left(0,\sin^2\theta   +  a^2   \cos^2\theta  \right)$   \   (ver  m\'as
  adelante). En la figura, $a = \frac13$ \ y \ $\theta = \frac{\pi}{6}$.}
\label{Fig:MP:StudentR}
\end{figure}

Nota:  en el  caso \  $\nu =  d$ \  la ley  es uniforme  adentro del  dominio de
definici\'on  $X  \sim  \U\left(  m  + \Sigma^{\frac12}  \,  \Bset_d\left(  0  ,
    \sqrt{d+2} \right) \right)$. Para \ $d-2 < \nu < d$ \ la densidad diverge
en los bordes del dominio de definici\'on (divergencia integrable).

Contrariamente al caso gaussiano, de la forma de la densidad de probabilidad, es
claro que a\'un si la matriz \ $\Sigma$ \ es diagonal, la densidad no factoriza,
as\'i  que las  componentes  del  vector no  son  independientes.  Este  ejemplo
muestra     claramente     y     nuevamente     que     la     reciproca     del
lema~\ref{Lem:MP:IndependenciaCov} es falsa en general.

Sin embargo, las distribuciones Student-$r$ tienen varias propiedades notables.

\begin{lema}[Stabilidad por transformaci\'on lineal]
\label{Lem:MP:StabilidadLinealStudentR}
%
  Sean \ $X \, \sim \,  \R_\nu(m,\Sigma)$, \ $A$ \ matriz de \ $\M_{d',d}(\Rset))$
  \ con \ $d' \le d$, y de rango lleno y \ $b \in \Rset^{d'}$. Entonces
  %
  \[
  A X + b\, \sim \, \R_\nu( A m + b , A \Sigma A^t)
  \]
  %
  En particular los componentes de \ $X$ \ son student-$r$,
  %
  \[
  X_i \, \sim \, \R_\nu(m_i , \Sigma_{i,i} )
  \]
\end{lema}
\begin{proof}
  La prueba es inmediata usando  la funci\'on caracter\'istica y sus propiedades
  por  transformaci\'on lineal.  La condici\'on  sobre \  $A$ \  es  necesaria y
  suficiente para que \ $A \Sigma A^t \in \Pos_{d'}^+(\Rset)$.
\end{proof}

\begin{lema}[L\'imite gaussiana]
\label{Lem:MP:LimiteStudentRGaussiana}
%
  Sea \  $X_\nu \, \sim  \, \R_\nu(m,\Sigma)$ \ vector  Student-$r$ parametizado
  por \ $\nu$ \ su grado de libertad. Entonces
  %
  \[
  X_\nu \, \limitd{\nu \to \infty} \, = \, X \, \sim \, \N(m,\Sigma)
  \]
  %
  con \ $\displaystyle \limitd{}$ \ l\'imite es en distribuci\'on.
\end{lema}
\begin{proof}
  La prueba  es inmediata tomando el  logaritmo de la  densidad de probabilidad,
  usando la  formula de Stirling \  $\log\Gamma(z) = \left( z  - \frac12 \right)
  \log z - z  + \frac12 \log(2 \pi) + o(1)$ \  en \ $z \to +\infty$~\cite{Sti30,
    AbrSte70,  GraRyz15} \  y \  $\frac{\nu-d}{2} \log\left(  1  - \frac{(x-m)^t
      \Sigma^{-1} (x-m)}{\nu}  \right) = -  \frac{\nu-d}{2} \left( \frac{(x-m)^t
      \Sigma^{-1}  (x-m)}{\nu+2}   +  o\left(  \nu^{-1}  \right)   \right)  =  -
  \frac{(x-m)^t \Sigma^{-1}  (x-m)}{2} +  o(1)$. Adem\'as, se  nota que  $\X \to
  \Rset^d$.
\end{proof}

%Las   variables   Student-t   tienen   varias   representaciones   estocasticas,
%relacionadas a la gaussiana~\cite{FanKot90, And03, KotNad04, AndKau65}:
%% ej. KotNad p. 7 para la secunda
%
\begin{lema}[Relaci\'on con la distribuci\'on gamma y la ley gaussiana]\label{Lem:MP:StudentRGamma}
%
  Sea \ $V \sim \G\left( \frac{\nu-d}{2}+1 \,  , \, \frac12 \right)$ \ y \ $G \,
  \sim \,  \N(0,I)$ \  $d$-dimensional e independientes  de $V$.  Entonces, para
  $\Sigma \in \Pos_d^+(\Rset)$ y $m \in \Rset^d$,
  %
  \[
  \frac{\sqrt{\nu+2} \:  \Sigma^{\frac12} \, G}{\sqrt{V  + \|G\|^2}} + m \,  \sim \,
  \R_\nu( m , \Sigma )
  \]
  %
\end{lema}
\begin{proof}
  Sea \ $X = \frac{\sqrt{\nu+2} \,  G}{\sqrt{V + \|G\|}}$.  De la nota siguiendo
  la tabla  de caracter\'isticas  es necesario y  suficiente probar que  $X \sim
  \R_\nu(0,I)$.  Probaremos en la secci\'on~\ref{Ssec:MP:FamiliaEliptica} que $G
  \egald R U$  \ con \ $R >  0$ \ de densidad de probabilidad  \ $p_R(r) \propto
  r^{d-1} e^{-\frac{r^2}{2}}$, independiente de  \ $U$, vector de distribuci\'on
  uniforme  sobre la esfera  \ $\Sset_d$.   Probaremos tambi\'en  que \  $Y \sim
  \R_\nu(0,I)$ \ se escribe de la misma manera \ $Y \egald S U$ \ ahora con \ $S
  >  0$ \  de densidad  de probabilidad  \ $p_S(s)  \propto s^{d-1}  \left(  1 -
    \frac{s^2}{\nu+2}       \right)_+^{\frac{\nu-d}{2}}$.        Ahora,      del
  teorema~\ref{Teo:MP:IgualdadDistribucionFuncionVA},   y    de   la   escritura
  estoc\'astica de $G$ tenemos
  %
  \[
  X \egald \frac{\sqrt{\nu+2} \, R}{\sqrt{V + R^2}} \: U
  \]
  %
  Sea
  %
  \[
  S = \frac{\sqrt{\nu+2} \, R}{\sqrt{V + R^2}}
  \]
  %
  Claramente,  $R,  V$  siendo  independientes   de  $U$,  la  variable  $S$  es
  independiente de  $U$ en esta  escritura estocastica. Entonces,  sufice probar
  que    $p_S(s)    \propto     s^{d-1}    \left(    1    -    \frac{s^2}{\nu+2}
  \right)_+^{\frac{\nu-d}{2}}$. Por eso, sea
  %
  \[
  T = \sqrt{\frac{V+R^2}{\nu+2}} \qquad \mbox{y} \qquad g: (r,v) \mapsto (s,t)
  \]
  %
  con ambas  \ $(r,v) \in  \Rset_+^2$ \ y  \ $(s,t) \in \Rset_+^2$.   Se calcula
  sencillamente  la  jacobiana  de $g^{-1}:  (s,t)  \mapsto  \left(  s t  ,  t^2
    (\nu+2-s^2) \right)$ y a continuaci\'on el valor absoluto de su determinente
  que vale
  %
  \[
  \left| \Jac_{g^{-1}} \right| = 2 \, (\nu+2) \, t^2
  \]
  %
  Del teorema de transformaci\'on~\ref{Teo:MP:TransformacionInyectivaDensidad} y
  de la independencia de $R$ y $V$ tenemos
  %
  \begin{eqnarray*}
  p_{S,T}(s,t) & = & 2 \, (\nu+2) \, t^2 \, p_R(st) \, p_V\left( t^2 (\nu+2-s^2)
  \right)\\[2mm]
  %
  & \propto & t^2 \, (s t)^{d-1} \, e^{-\frac{s^2 t^2}{2}} \, t^{\nu-d} \,
  \left( \nu+2-s^2 \right)_+^{\frac{\nu-d}{2}} \, e^{-\frac{t^2 (\nu+2-s^2)}{2}}
  \end{eqnarray*}
  %
  es decir
  %
  \[
  p_{S,T}(s,t)     \propto    s^{d-1}     \left(    1     -    \frac{s^2}{\nu+2}
  \right)_+^{\frac{\nu-d}{2}} \, t^{\nu+1} \, e^{-\frac12 t^2}
    \]
  %
    Inmediatamente, de  la forma separable de  \ $p_{S,T}$, vemos que  $S$ y $T$
    son independientes, y sobre todo se recononce en el primer factor que la ley
    de  $S$ es dada  por $p_S(s)  \propto s^{d-1}  \left( 1  - \frac{s^2}{\nu+2}
    \right)_+^{\frac{\nu-d}{2}}$, lo que cierra la prueba. Pasando, de la ley de
    $T$ se notar\'a que $T^2 \sim \G\left( \frac{\nu}{2} + 1 , \frac12 \right)$,
    como suma  de dos variables  gamma independientes respectivamente \  $V \sim
    \G\left(  \frac{\nu-d}{2}+1 , \frac12  \right)$ \  y \  $R^2 =  \|G\|^2 \sim
    \G\left(        \frac{d}{2}       ,       \frac12        \right)$       (ver
    lemma~\ref{Lem:MP:StabilidadGamma}). $T$ es de distribuci\'on raiz-gamma.
 %   Por marginalisaci\'on en $t$, se  obtiene el resultado esperado. Pasando, de
 %   la forma separable de \ $p_{S,T}$,  vemos que $S$ y $T$ son independientes y
 %   que $T^2 \sim \G\left( \frac{\nu}{2} , \frac12 \right)$.

    Una prueba alternativa  que no usa resultados de  secciones siguientes sigue
    los pasos del lema~\ref{Lem:MP:StudentWishart}.
\end{proof}


\begin{lema}[Relaci\'on con la distribuci\'on de Wishart]\label{Lem:MP:StudentWishart}

%
  Sea \ $W \, \sim \, \W( I \, ,  \, \nu+1)$ \ $d \times d$ \ Wishart, \ $Y \,
  \sim  \, \N(0, (\nu+2)  I)$  \ con  $\nu  >  0$ \  e  \ $Y$  \  independiente de  \
  $W$. Entonces, para \ $m \in \Rset^d$, \ $\Sigma \in \Pos_d^+(\Rset)$,
  %
  \[
  \Sigma^{\frac12}  \left(  W +  Y  Y^t  \right)^{-\frac12} Y  +  m  \, \sim  \,
  \R_\nu\left( m , \Sigma \right)
  \]
\end{lema}
\begin{proof}
  Sea \ $X  = \left( W + Y  Y^t \right)^{-\frac12} Y$.  De la  nota siguiendo la
  tabla  de caracter\'isticas  es  necesario  y suficiente  probar  que $X  \sim
  \R_\nu(0,I)$.  Por independencia, la ley conjunta de $(W,Y)$ tiene la forma
  %
  \[
  p_{W,Y}(w,y)  =  \frac{|w|^{\frac{\nu-d}{2}}  \,  e^{-\frac12  \Tr\left(  w  +
        \frac{y      y^t}{\nu+2}\right)}}{2^{\frac{d       (\nu+1)}{2}}      (2
    \pi)^{\frac{d}{2}}   (\nu+2)^{\frac{d}{2}}   \Gamma_d\left(  \frac{\nu+1}{2}
    \right)} \quad \mbox{sobre} \quad \Pos_d^+(\Rset) \times \Rset^d
  \]
  %
  Sea  el cambio  de variables  $g: (W,Y)  \mapsto (V,Y)  = \left(  W  + \frac{Y
      Y^t}{\nu+2} , Y \right)$, con $\Jac_g = 1$, dando
  %
  \[
  p_{V,Y}(v,y) = \frac{\left|  v - \frac{y y^t}{\nu+2} \right|^{\frac{\nu-d}{2}}
    \,   e^{-\frac12   \Tr\left(    v   \right)}}{2^{\frac{d   (\nu+1)}{2}}   (2
    \pi)^{\frac{d}{2}}   (\nu+2)^{\frac{d}{2}}   \Gamma_d\left(  \frac{\nu+1}{2}
    \right)}  \quad  \mbox{sobre} \quad  \{  (v,y)  \in \Pos_d^+(\Rset)  \times
  \Rset^d \tq v - \frac{y y^t}{\nu+2} > 0 \}
  \]
  %
  Por fin,  con el  cambio de  variables $h: (V,Y)  \mapsto (V,X)  = \left(  V ,
    V^{-\frac12} X \right)$, con $\Jac_h = |v|^{-\frac12}$, dando
  %
 \[
  p_{V,X}(v,x) = \left|  I - \frac{x x^t}{\nu+2} \right|^{\frac{\nu-d}{2}} \frac{|v|^{\frac{\nu-d}{2}}
    \,   e^{-\frac12   \Tr\left(    v   \right)}}{2^{\frac{d   (\nu+1)}{2}}   (2
    \pi)^{\frac{d}{2}}   (\nu+2)^{\frac{d}{2}}   \Gamma_d\left(  \frac{\nu+1}{2}
    \right)} \quad \mbox{sobre}  \quad \Pos_d^+(\Rset)  \times \{  x \in 
  \Rset^d \tq I - \frac{x x^t}{\nu+2} > 0 \}
  \]
  %
  El resultado sigue por marginalizaci\'on con  respeto a \ $v$ \ y la identidad
  de Sylvester~\cite{Syl51} o~\cite[\S~18.1]{Har08} \  $\left| I + a b^t \right|
  = 1  + b^t a$ ($I  - \frac{x x^t}{\nu+2} >  0$ impone entonces  $1 - \frac{x^t
    x}{\nu+2} > 0$).

  Se nota pasando, de  la forma separable de la densidad, que \  $W+Y Y^t$ \ y \
  $(W+Y Y^t)^{-\frac12} Y$ \ son independientes.
\end{proof}

M\'as propiedades de esta distribuci\'on se encuentran en libros especializados,
por ejemplo~\cite{FanKot90, KotBal00} o en~\cite[Sec.~3.2.1]{Zoz12}.

\

\

La distribuci\'on  Student-$r$ se generaliza al  caso complejo \  $Z$ \ definido
sobre $\Cset^d$; se denota  \ $Z \, \sim \, \CR_\nu(m,\Sigma)$ \  donde \ $m \in
\Cset^d$, \ $\Sigma \in \Pos_d^+(\Cset)$, \ $\nu > 2 d - 2$ \ y la densidad es dada
por \
%
\[
p_Z(z) = \frac{\Gamma\left( \frac{\nu}{2} + 1 \right)}{\pi^d (\nu+2)^d \Gamma\left(
    \frac{\nu}{2} - d + 1   \right)  \,   \left|   \Sigma  \right|}   \:   \left(  1   -
  \frac{(z-m)^\dag \, \Sigma^{-1} \, (z-m)}{\nu+2} \right)_+^{\frac{\nu}{2}-d}
\]

\

Como en  el contexto  Student-$t$, se puede  generalizar la Student-$r$  al caso
matriz-variada $X$  definido sobre $\Mat_{d,d'}(\Rset)$;  se denotar\'a \  $X \,
\sim \, \R_\nu(m,\Sigma,\Sigma')$ \ donde \ $m \in \Mat_{d,d'}(\Rset), \: \Sigma
\in \Pos_d^+(\Rset), \:  \Sigma' \in \Pos_{d'}^+(\Rset)$ y la  densidad dada por
$\displaystyle      p_X(x)      =      \frac{\Gamma_d\left(      \frac{\nu}{2}+1
  \right)}{\pi^{\frac{d   d'}{2}}    (\nu+2)^{\frac{d   d'}{2}}   \Gamma_d\left(
    \frac{\nu-d'}{2} +  1\right) \, \left|  \Sigma \right|^{\frac{d'}{2}} \left|
    \Sigma' \right|^{\frac{d}{2}}}  \: \left| I - \frac{1}{\nu+2}  \, (x-m)^t \,
  \Sigma^{-1} (x-m) \,  \Sigma'^{-1} \right|^{\frac{\nu-d-d'+1}{2}}$ \ sobre $\X
= \{  x \in  \Mat_{d,d'}(\Rset) \tq  I - \frac{(x-m)^t  \, \Sigma^{-1}  (x-m) \,
  \Sigma'^{-1}}{\nu+2} > 0 \}$.  Se refiera a~\cite[Cap.~4]{GupNag99} para tener
m\'as detalles. En particular, se puede  probar con los mismos pasos que para la
ley Student-$t$  que se generaliza  el lema\ref{Lem:MP:StabilidadLinealStudentR}
(ver              secci\'on~\ref{Ssec:MP:FamiliaElipticaMatriz}),             el
lema~\ref{Lem:MP:LimiteStudentTGaussiana}                  y                  el
lema~\ref{Lem:MP:StudentWishart}~\cite[Teo.~4.2.1]{GupNag99}.
% (las formas son un poco diferentes, pero completamente
%equivalente  a   la  de   este  libro).