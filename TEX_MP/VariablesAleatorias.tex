\seccion{Variables aleatorias y distribuciones de probabilidad}
\label{s:variablealeatoria}

\emph{En  un  experimento  o  un  dado  proceso,  los  posibles  resultados  son
  t\'ipicamente  n\'umeros reales, siendo  cada n\'umero  un evento.   Luego los
  resultados  son mutuamente  excluyentes. Se  considera a  esos  n\'umeros como
  valores de una  \emph{variable aleatoria} $X$ a valores  reales, que puede ser
  discreta o continua.}

%  (cuando  el espacio  muestral  es  finito  o infinito  numerable)  o
%  continua.  La ley  de la variable aleatoria $X$ es  una medida de probabilidad
%  definida por  \ $P_X(x) =  \Pr(X=x)$ o, en  general, por $P_X(A)  = \Pr(X=x\in
%  A)$.  Para indicar  que la variable~$X$ sigue la ley  de distribuci\'on $p$ se
%  escribe  \  $X\sim p  $.   Puede  ser  \'util tambi\'en  considerar  variables
%  aleatorias  complejas  $Z=X+iY$, donde  $X$  e  $Y$  son variables  aleatorias
%  reales. }


\modif{  Formalmente,  la noci\'on  de  variable  aleatoria  se apoya  sobre  la
  noci\'on de funci\'on medible~\cite{KolFom61, AthLah06, Bog07:v1, Coh13}:
%
\begin{definicion}[Funci\'on medible]
  Sean  \ $(\Omega,\A)$  \ y  \ $(\Upsilon,\B)$  \ dos  espacios  medibles.  Una
  funci\'on $f: \Omega \mapsto \Upsilon$ es dicha {\it $(\A,\B)$-medible} si
  %
  \[
  \forall \,  B \in  \B, \quad  A \equiv f^{-1}(B)  = \left\{  \omega \in  A: \,
    f(\omega) \in B \right\} \: \in \: \A
  \]
  %
  Dicho de  otra manera,  la pre-imagen  de un elemento  dada de  $\B$ (elemento
  medible)  partenece  a  $\A$  (elemento  medible).  A  veces,  se  dice  m\'as
  simplemente de que $f: (\Omega,\A) \mapsto (\Upsilon,\B)$ es medible por abuso
  de escritura.
\end{definicion}

Adem\'as, saliendo de un espacio de medida y una funci\'on $f$ medible, se puede
definir una medida imagen  sobre el espacio de llegada~\cite{AthLah06, Bog07:v1,
  Coh13}:
%
\begin{teorema}[Teorema de la medida imagen]
  Sean  \ $(\Omega,\A,\mu)$  \  un espacio  de  medida, \  $(\Upsilon,\B)$ \  un
  espacios  medibles  y una  funci\'on  $f:  (\Omega,\A) \mapsto  (\Upsilon,\B)$
  medible. Sea $\mu_f$ tal que
  %
  \[
  \forall \,  B \in  \B, \quad  \mu_f(B) = \mu\left( f^{-1}(B) \right)
  \]
  %
  Entonces, $\mu_f$ es una medida sobre el espacio medible $(\Upsilon,\B)$ \ \ie
  \ $(\Upsilon,\B,\mu_f)$ \ define un espacio de medida.  Adem\'as, $\mu(\Omega)
  = \mu_f(\Upsilon)$ (posiblemente infinitas).
\end{teorema}
%
\begin{proof}
  Por  definici\'on,  claramente $\mu_f  \ge  0$ \  y  por  definici\'on de  una
  funci\'on,  $f^{-1}(\emptyset)  =   \emptyset$  \  dando  $\mu_f(\emptyset)  =
  \mu(\emptyset) =  0$.  Luego,  si para  un conjunto numerable  $\{ B_i  \}$ de
  elementos  de $\B$  disjuntos entre  s\'i, las  preimagenes de  los  $B_i$ son
  disjuntos tambi\'en entre  s\'i (para $i \ne j$ no se  puede tener $\omega \in
  f^{-1}(B_i) \cap f^{-1}(B_j)$ si no $\omega$ tendr\'ia dos imagenes distinctas
  por  $f$).   Entonces  $\displaystyle  f^{-1}\left( \bigcup_i  B_i  \right)  =
  \bigcup_i  f^{-1}(B_i)$.   Eso   implica  de  que  $\displaystyle  \mu_f\left(
    \bigcup_i B_i \right) = \mu\left( f^{-1}\left( \bigcup_i B_i \right) \right)
  =  \bigcup_i  \mu\left( f^{-1}(B_i)  \right)  =  \sum_i \mu\left(  f^{-1}(B_i)
  \right) = \sum_i  \mu_f(B_i)$.  Finalmente, necesariamente $f^{-1}(\Upsilon) =
  \Omega$  (es incluida y  $f(\Omega)$ siendo  en $\Upsilon$  son necesariamente
  iguales) lo  que cierra la  prueba~\footnote{De hecho, se  puede sencillamente
    probar que la  preimagen de una uni\'on numerable (que  sean disjuntos o no)
    es la uni\'on  de las preimagenes; lo mismo occure  para la intersecci\'on y
    adem\'as la preimagen del complemento es el complemento de la preimagen. Eso
    es conocido  como {\it leyes de de  Morgan}~\cite{AthLah06, Coh13, HogMck13}
    (ver tambi\'en~\cite[Cap.~1]{KolFom57} y~\cite[Caps.~5~\&~6]{KolFom61}).}.
\end{proof}

Un espacio  jugando un  rol particular es  $\Rset$, a  lo cual se  puede asociar
$\B(\Rset)$ la  $\sigma$-\'algebra m\'as  peque\~na generada por  los intervalos
$(-\infty  \,  ;  \, b]$  (equivalentemente,  por  los  abiertos de  $\Rset$,  o
tambi\'en  por  los  intervalos  $(a  \,  ; \,  b]$),  \ie  uniones  numerables,
intersecciones  numerables,  complementos  de  estos  intervalos~\cite{AthLah06,
  Bog07:v1,  Bog07:v2,  Coh13}.   $\B(\Rset)$  es  llamada  {\it  Borelianos  de
  $\Rset$} o {\it $\sigma$-\'algebra de Borel de $\Rset$}.

Con  estas   definiciones,  tenemos  todo   lo  necesario  para   introducir  la
definici\'on de una variable aleatoria real~\cite{AthLah06, Coh13, Bre88}:
%
\begin{definicion}[Variable aleatoria real]
  Una variable aleatoria real es una funci\'on medible
  %
  \[
  X: (\Omega,\A,P) \mapsto (\Rset,\B(\Rset),P_X)
  \]
  %
  donde la medida  $P_X$ sobre $\B(\Rset)$ es la medida imagen  de $P$.  \ $P_X$
  es frecuentemente llamada {\it distribuci\'on  de probabilidad} o {\it ley} de
  la variable aleatoria $X$. En lo que sigue, escribiremos los eventos
  %
  \[
  (X \in B) \equiv X^{-1}(B) = \{ \omega \in \Omega: \: X(\omega) \in B \}
  \]
  %
  as\'i que, por definici\'on,
  %
  \[
  P_X(B) = P(X \in B)
  \]
\end{definicion}
%
Para  ilustrar esta definici\'on,  tomando el  ejemplo de  un dado,  $\Omega$ es
discreto y representa  las caras, mientras de que los  numeros ser\'an la imagen
de $\Omega$ por $X$ (ej. $X(\omega_i) = i, \quad i = 1, \ldots , 6$).

Fijense de que,  por la propiedades de una  medida sobre una $\sigma$-\'algebra,
para caracterizar completamente la  distribuci\'on $P_X$ es suficiente conocerla
sobre  los intervalos de  la forma  $(-\infty \,  ; \,  b]$. Eso  da lugar  a la
definici\'on  de  la funci\'on  de  repartici\'on~\cite{AthLah06, Coh13,  Bre88,
  HogMck13}:
%
\begin{definicion}[Funci\'on de repartici\'on]
  Por  definici\'on,  la  funci\'on  de  repartici\'on  $F_X$  de  una  variable
  aleatoria es definida por
  %
  \[
  F_X(x) = P_X((-\infty \, ; \, x]) = P(X \le x)
  \]
  %
  A veces, por abuso de terminologia,  se denomina $F_X$ como ley de la variable
  aleatoria. Se  encuentra tambi\'en  el la literatura  la terminologia  de {\it
    funci\'on cumulativa}.
\end{definicion}
%
Naturalmente, de las propiedades de una medida de probabilidad,
%
\begin{itemize}
\item $0 \le F_X(x) \le 1$;
%
\item $\displaystyle \, \lim_{x \to -\infty} F_X(x) = 0$ \ y \ $\displaystyle \,
  \lim_{x \to +\infty} F_X(x) = 1$  (viene de $P_X(\emptyset) = 0$ y $P_X(\Rset)
  = 1$);
%
\item $F_X$ es creciente (viene de que $x_1 \le x_2 \Rightarrow (-\infty \, ; \,
  x_1] \subseteq (-\infty \, ; \, x_2]$);
%
\item $F_X$ no es necesariamente continua  (lo vamos a ver m\'as adelante), pero
  en cada punto $x$ es continua a su derecha (ver punto anterior).
\end{itemize}
}

Cuando se trabaja  con $d\geq 2$ variables aleatorias  es conveniente definir un
{\it vector aleatorio}  de dimensi\'on $d$, y apelar para  su estudio a nociones
del \'algebra  lineal y  a notaci\'on matricial.   Se tiene el  vector aleatorio
$d$-dimensional  \ $X  = \begin{bmatrix}  X_1  & \cdots  & X_d  \end{bmatrix}^t$
\modif{donde $\cdot^t$  denota la  transpuesta,} caracterizado por  $d$-uplas de
variables aleatorias reales.  Como en  el caso univariado, se define este vector
de la manera siguiente\modif{:~\cite{AthLah06, Coh13, Bre88}
%
\begin{definicion}[Vector aleatorio real]
  Un variable aleatorio real es una funci\'on medible
  %
  \[
  X: (\Omega,\A,P) \mapsto (\Rset^d,\B(\Rset^d),P_X)
  \]
  %
  donde  $\B(\Rset^d)$  son  los  borelianos  de  $\Rset^d$,  $\sigma$-\'algebra
  generada por  los productos cartesianos $(-\infty  \, ; \,  b_1] \times \cdots
  \times (-\infty \,  ; \, b_d]$ y donde la medida  $P_X$ sobre $\B(\Rset^d)$ es
  la  medida imagen  de $P$  llamada  {\it distribuci\'on  de probabilidad}  del
  vector aleatorio $X$. como el el caso escalar,
  %
 \[
 (X \in B) \equiv X^{-1}(B) = \{ \omega \in \Omega: \: X(\omega) \in B \} \qquad
 \mbox{y} \qquad P_X(B) = P(X \in B)
 \]
\end{definicion}
%
De la propiedades de una  medida sobre una $\sigma$-\'algebra, para caracterizar
completamente la distribuci\'on $P_X$ de nuevo es suficiente conocerla sobre los
elementos de la forma $(-\infty \, ;  \, b_1] \times \cdots \times (-\infty \, ;
\, b_d]$, \ie la  funci\'on de repartici\'on multivariada~\cite{AthLah06, Coh13,
  Bre88, HogMck13}:
%
\begin{definicion}[Funci\'on de repartici\'on multivariada]
  Por  definici\'on,  la  funci\'on  de  repartici\'on  $F_X$  de  un vector
  aleatorio es definida en $x = (x_1 , \ldots , x_d)$ por
  %
  \[
  F_X(x) = P_X((-\infty \, ; \, x_1] \times \cdots \times (-\infty \, ; \, x_d])
  = P\left( \bigcap_{i=1}^d (X_i \le x_i) \right)
  \]
\end{definicion}
%
De nuevo, de las propiedades de una medida de probabilidad,
%
\begin{itemize}
\item $0 \le F_X(x) \le 1$;
%
\item $\displaystyle  \, \lim_{\forall  i, x_i \to  -\infty} F_X(x)  = 0$ \  y \
  $\displaystyle \, \lim_{\forall i, x_ \to +\infty} F_X(x) = 1$;
%
\item $F_X$ es creciente con respecto a cada variable $x_i$.
\end{itemize}
%
Al  final, para  un subconjunto  $I_k =  (i_1,\ldots,i_k)$ de  $1 \le  k  \le d$
elementos de  $\{ 1  , \ldots ,  d \}^k$,  $X_{I_k} = \begin{bmatrix}  X_{i_1} &
  \cdots   &   X_{i_k}\end{bmatrix}^t$  es   obviamente   un  vector   aleatorio
$k$-dimensional. Es entonces sencillo ver de que
%
\[
F_{X_{I_k}}(x_{I_k}) = \lim_{\forall i \not\in I_k, x_i \to +\infty} F_X(x)
\]
%
(viene de  que $\bigcap_{j=1}^k (X_{i_j}  \le x_{i_j}) =  \left( \bigcap_{j=1}^k
  (X_{i_j} \le x_{i_j}) \right) \bigcap  \left( \bigcap_{i \not\in I_k} (X_i \in
  \Rset)  \right)$). Esta  funci\'on es  dicha {\it  funci\'on  de repartici\'on
  marginale} de $F_X$. 

Cerramos estas generalidades con el caso de variables independientes:
%
\begin{definicion}[Independencia]
  Sean       $d$        variables       aleatorias       $X_i$        y       $X
  = \begin{bmatrix}  \end{bmatrix}^t$. Los $X_i$  son mutualmente independientes
  si y  solamente si, para cualiquier  ensemble de conjuntos  $B_i$, los eventos
  $(X_i \in \B_i)$ son mutualmente inependientes, \ie
  %
  \[
  P_X(\times_{i=1}^d B_i) = \prod_{i=1}^d P_{X_i}(B_i)
  \]
  %
  donde $\times$ denota el producto cartesiano entre elementos de $\B(\Rset)$.
  %
  Es equivalente a
  %
  \[
  F_X(x) = \prod_{i=1}^d F_{X_i}(x_i)
  \]
  %
  La ley del vector aleatorio se factoriza.
\end{definicion}
%
Es importante notar de que no es equivalente a tener la independencia por pares,
como ilustrado en el fin de la seci\'on precediente.

\

M\'as  all\'a de  este  enfoque  general, dos  casos  particulares de  variables
aleatorias son  de inter\'es:  las variables discretas  y las continuas.   En el
primer  caso $\Omega$  es discreto,  finito  o no.  La meta  de las  susecciones
siguientes es estudiar las particularidades de cada caso.

Par fijar unas notaciones, en todo lo que sigue, escribiremos
%
\[
\X = X(\Omega)
\]
%
conjuntos de llegada  de $X$, o conjunto de valores que  puede tomar la variable
aleatoria.  A veces,  por razones  de simplificaciones,  se considera  $\X$ como
siendo el  espacio muestral  y se olvida  de que  $X$ sea una  funci\'on medibel
entre espacios de probabilidades,  \ie se trabaja en $(\Rset^d,\B(\Rset^d),P_X)$
como es el espacio preimagen.

}



% ================================= Discreta

\subseccion{Variable aleatoria discreta}
\label{sec:MP:VADiscreta}

\modif{
\begin{definicion}[Variable aleatoria discreta]
  Una  variable aleatoria es  dicha {\it  discreta} cuando  $\X =  X(\Omega)$ es
  discreto, finito o infinito numerable.  En lo que sigue, denotaremos por $|X|$
  el cardinal de $\X$, posiblemente infinito.
\end{definicion}
%
\noindent En  otras palabras,  l}os posibles valores  de una  variable aleatoria
discreta $X$ consisten en un  conjunto contable (finito o infinito numerable) de
n\'umeros  reales:  \  $\modif{\X  = \{  x_i  \}_i}$~\cite{AthLah06,  HogMck13}.
\modif{En este caso, las probabilidades $P_X(\{ x_i \}) = P(X = x_i), \: x_i \in
  \X$   caracterisan   completamente   la   variable   aleatoria~\cite{AthLah06,
    HogMck13}:
%
\begin{definicion}[Funci\'on de masa de probabilidad]
  Por  definici\'on, la  funci\'on  de  masa de  probabilidad  de $X$,  variable
  aleatoria discreta tomando sus valores sobre $\X$ es dada por
  %
  \[
  p_X(x) \equiv P(X = x) = P_X( \{ x\} ) \quad x \in \X
  \]
  %
  Por   abuso  de   denominaci\'on,  llamaremos   en  este   libro   $p_X$  {\it
    distribuci\'on de probabilidad}. Adem\'as, usaremos tambi\'en la notaci\'on
  %
  \[
  p_X = \begin{bmatrix} \cdots & p_X(x_i) & \cdots \end{bmatrix}^t
  \]
  %
  dicho {\it vector de probabilidad}, de tama\~no $|\X|$, posiblemente infinito.
\end{definicion}
%
En  la  Fig.~\ref{fig:MP:ProbaDiscreta}-(a)   se  muestra  una  representaci\'on
gr\'afica de una distribuci\'on de probabilidad discreta.
%
En particular,
%
\[
\forall \, B \in \B(\Rset), \quad P_X(B) = \sum_{x \in \X \cap B} p_X(x)
\]
%
lo que da, tratando de la funci\'on de repartici\'on,
%
\[
F_X(x) = \sum_{x_i \le x} p_X(x_i)
\]
%
De   esta  forma,  se   justifica  la   denominaci\'on  {\it   cumulativa}  para
$F_X$.  Tambi\'en,  se  puede ver  inmediato  de  que  $F_X$} es  una  funci\'on
discontinua,   con   saltos   finitos   \modif{(en  $x_i$,   salto   de   altura
  $p_X(x_i)$)}. Eso es ilustrado figura Fig.~\ref{fig:MP:ProbaDiscreta}-(b).
%, y no decreciente. 

\modif{
\begin{figure}[h!]
\begin{center} \input{TIKZ_MP/DistribucionReparticionDiscreta} \end{center}
%
\leyenda{\modif{Ilustraci\'on  de u}na  distribuci\'on de  probabilidad discreta
  \modif{ (a), y  la funci\'on de repartici\'on asociada (b),  con $\X = \big\{
      \, 1 \,  , \, \sqrt3 \,  , \, \sqrt5 \, ,  \, \sqrt7 \, ,  \, \sqrt{11} \,
    \big\}$ \  y \  $p_X =  \left[ \frac18 \quad  \frac14 \quad  \frac16 \quad
      \frac18 \quad \frac13 \right]^t$.  }}
\label{fig:MP:ProbaDiscreta}
\end{figure}
}
%   A   cada  uno   de  los   valores  $x_n$
%($n=1,2,\ldots$) se puede asociar una  probabilidad $p_n=p(x_n)$, de modo que se
%satisface la condici\'on de normalizaci\'on:
%%
%$$\sum_n p_n = 1 . $$ 
%
%La \emph{funci\'on (de masa) de probabilidad} es  de la forma: 
%
%$$
%p(x) = \left\{
%\begin{array}{cl}
%\Pr(X=x) & \mbox{si} \ x=x_1, x_2, \ldots \\ 0 &
%\mbox{en~todo~otro~punto}
%\end{array} \right.
%$$
%%
%En  la   Fig.~\ref{fig:distribprobdiscreta}  se  muestra   una  representaci\'on
%gr\'afica de una distribuci\'on de probabilidad discreta.
%
%\begin{figure}[h!] %%ojo numeracion de figs !
%\centerline{\includegraphics[width=3cm]{distribprobdiscreta.jpg}} %%rehacer
%
%\leyenda{Una distribuci\'on de probabilidad discreta.}
%\label{fig:distribprobdiscreta}
%\end{figure}

%Tambi\'en, se puede caracterizar la ley de la variable discreta $X$ por medio de
%su \emph{funci\'on de repartici\'on}:
%
%$$
%F_X(x)= \Pr(X\in(-\infty,x]) = \Pr (X\leq x) = \sum_{\forall
%  n \,:\, x_n\leq x} p(x_n)
%$$
%
%que es una funci\'on discontinua, con saltos finitos, y no decreciente. 

%Sin  p\'erdida de  generalidad, el  conjunto de  valores que  toma  una variable
%aleatoria discreta $X$ puede considerarse como $\{0,1,2,\ldots,N\}$ para alg\'un
%$N$ natural, o todo $\Nset$. Entonces la ley de una variable aleatoria a valores
%naturales est\'a dada por  \ $\{p_n = \Pr(X=n), \ n\in \Nset  \}$.  Luego \ $\Pr
%(X\in  A)=\sum_{n\in A\cap  \Nset}  p_n$,  y la  funci\'on  de repartici\'on  se
%calcula como  \ $\Pr(X\leq x) = \sum_{n  \leq x} \Pr(X=n)$ que  es una funci\'on
%que presenta un  salto finito en cada n\'umero natural.  En  general un salto de
%la funci\'on  de repartici\'on corresponde a  la presencia de  una \emph{masa de
%  Dirac} en el entorno del salto. %%

Un caso especial se tiene cuando un  valor $x_j$ es cierto o seguro, y no ocurre
ninguno de  los otros valores $x_i \  (i\neq j)$. La forma  de la distribuci\'on
es: \ \modif{$p_X(x) = \un_{\{ x_i \}}(x)$ \ o \ $p_X = \un_i$}, donde
%
\[
\un_A(x) = \left\{
\begin{array}{clr}
1 & \mbox{si} \quad x \in A\\
0 & \mbox{si no}
% \ i\neq j 
\end{array} \right.
\]
%
\modif{es  la  funci\'on indicator  y  $\un_i$  es  el vector  (posiblemente  de
  dimensi\'on infinita) de componentes $j$-esima $\delta_{ij} = \un_{\{i\}}(j)$}
s\'imbolo \emph{delta de Kronecker},
%
\[
\delta_{ij} = 
\left\{
\begin{array}{clr}
1 & \mbox{si} \: i=j \\
0 & \mbox{si no}
\end{array} \right.
\]
%. Cuando el espacio muestral es finito
%de dimensi\'on $N$, la ley de  distribuci\'on se puede representar por medio del
%siguiente vector columna:
%%
%$$
%p = \begin{pmatrix}
%% \left(  
%%\begin{array}{c}
%0 \\ \vdots \\ 0 \\ 1  \\ 0 \\ \vdots \\ 0
%\end{pmatrix}
%%\end{array} \right)
%$$
%
%con  un  1  en  el  lugar  $j$-\'esimo,  que tambi\'en  se  escribe  como  \  $p
%= \begin{pmatrix} 0  & \cdots & 0 &  1 & 0 & \cdots &  0 \end{pmatrix}^t$, donde
%$t$ indica transposici\'on.  La funci\'on de repartici\'on resulta una funci\'on
%escal\'on o de Heaviside: \ $F(x)=\Theta(x-x_j)$.

Otra   situaci\'on  particular   es  la   de  {\it   equiprobabilidad}   o  {\it
  distribuci\'on uniforme}  \modif{cuando $|\X| = \alpha <  +\infty$}.  La forma
de la distribuci\'on es: \ \modif{$p_X(x_i)  = \frac1\alpha \quad \forall \, i =
  1  , \ldots  , \alpha$,  \ie $p_X  = \begin{bmatrix}  \frac1\alpha &  \cdots &
    \frac1\alpha \end{bmatrix}^t$.}
%, donde  $N$ señala el tamaño del espacio muestral.
%La ley  de distribuci\'on  se puede representar  por medio del  siguiente vector
%columna:
%
%$$
%p = \begin{pmatrix}
%% \left(  
%%\begin{array}{c}
%1/N \\ 1/N  \\ \vdots \\ 1/N
%\end{pmatrix}
%%array} \right) , 
%$$
%
%que tambi\'en se escribe como \  $p = \begin{pmatrix} \frac1N & \frac1N & \cdots
%  &  \frac1N  \end{pmatrix}^t$.
La funci\'on  de repartici\'on resulta  una funci\'on escalonada, con  saltos de
altura \modif{$\frac1\alpha$ en cada $x_i, \quad 1 \le i \le \alpha$}.

\
%hfill 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\SZ{Reordenamiento y relaci\'on de mayorizaci\'on  : a ver como trasladar lo que
  ya estaba en en cap. 2 mas los ejemplos. Todo comentado por ahora}

% Para comparar dos  distribuciones es \'util reordenar el  vector de probabilidad
% permutando  sus  elementos  hasta  listarlos  de forma  descendente.   Se  anota
% $p^\downarrow$, de  modo que \  $p^\downarrow_1 \geq p^\downarrow_2  \geq \ldots
% \geq  p^\downarrow_N$.   En  el  ejemplo   del  caso  con  certeza  se  tiene  \
% $p^\downarrow =  \begin{pmatrix} 1 & 0  & \cdots &  0 \end{pmatrix}^t$, mientras
% que la distribuci\'on uniforme no var\'ia.

% Se  define  \emph{mayorizaci\'on} del  siguiente  modo,  para distribuciones  de
% dimensi\'on  $N$ (con  sus elementos  acomodados  en forma  decreciente): \  una
% distribuci\'on $p$  es mayorizada por otra $q$,  y se denota $p\prec  q$, si las
% primeras $N-1$  sumas parciales de $p^\downarrow$ y  $q^\downarrow$ satisfacen \
% $\sum_{i=1}^n  p^\downarrow_i   \leq  \sum_{i=1}^n  q^\downarrow_i$   para  todo
% $n=1,\ldots,N-1$, con \ $\sum_{i=1}^N p_i = 1 = \sum_{i=1}^N q_i$.

% Por    ejemplo,   $\begin{pmatrix}    \frac12    &   \frac14    &   \frac18    &
%   \frac18 \end{pmatrix}^t  \prec \begin{pmatrix} \frac12  & \frac14 &  \frac14 &
%   0 \end{pmatrix}^t$.  Es posible  comparar por mayorizaci\'on distribuciones de
% distinta  dimensionalidad, completando con  ceros el  vector de  probabilidad de
% menor  dimensi\'on.  Es  importante  resaltar que  la  mayorizaci\'on provee  un
% \emph{orden  parcial}  (no  total)  entre distribuciones,  existiendo  pares  de
% distribuciones   tales  que   ninguna  mayoriza   a  la   otra.    Por  ejemplo,
% $\begin{pmatrix} 0.50 &  0.40 & 0.10 \end{pmatrix}^t$ y  $\begin{pmatrix} 0.70 &
%   0.15 & 0.15 \end{pmatrix}^t$ no se comparan por mayorizaci\'on.

% Es  interesante  notar  que  la   siguiente  propiedad  es  v\'alida  para  toda
% distribuci\'on $p$ de tamaño~$N$:
% %
% $$
% \begin{pmatrix} \frac1N & \frac1N & \cdots & \frac1N \end{pmatrix}^t \ \prec \ p
% \ \prec \ \begin{pmatrix} 1 & 0 & \cdots & 0 \end{pmatrix}^t.
% $$
% %
% En este  sentido, los  casos particulares de  equiprobabilidad y de  certeza, se
% dice  que  son  distribuciones  extremas.  Notamos que  uno  implica  ignorancia
% m\'axima  en el  resultado de  la variable  mientras que  el otro  corresponde a
% conocimiento completo.
% %% graficamente 
% %
% \begin{figure}[h!] %%ojo numeracion de figs !
% %\centerline{\includegraphics[width=3cm]{majorizationplot.pdf}} %%rehacer
% %
% \leyenda{Orden parcial por mayorizaci\'on}
% \label{fig:majorizationplot}
% \end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



% ================================= Discreta

\subseccion{Variable aleatoria continua}
\label{sec:MP:VAContinua}

\modif{En varios contextos, puede tomar valores en un conjunto no numerable, por
  ejemplo}  cualesquiera de  los  n\'umeros en  un  dado intervalo  de la  recta
real\modif{.  No son  variables discretas  m\'as. En  las variables  que  no son
  discretas,   el   caso   particular   de   inter\'es  es   el   de   variables
  continuas~\cite{AthLah06, HogMck13}:
%
\begin{definicion}[Variable aleatoria continua]
  Una  variable $X$ es  dicha {\it  continua} si  su funci\'on  de repartici\'on
  $F_X$ es continua sobre $\Rset$ (on respeto a la medida de Lebesgue).
\end{definicion}
%
}
%Los posibles valores de una  variable aleatoria continua $X$ son cualesquiera de
%los n\'umeros en un dado  intervalo de la recta real: \ $x\in\Omega\subset\Rset$
%que  puede ser  un intervalo  $[x_m,x_M]$  o un  subconjunto (semi)infinito.  
\modif{Cuando se puede, es}
conveniente asociar una  \emph{funci\'on densidad de probabilidad} (com\'unmente
anotada por su  sigla en ingl\'es: pdf por  \emph{probability density function})\modif{:
%
\begin{definicion}[Variable aleatoria continua admitiendo una densidad de probabilidad]
  Sea $X$  variable aleatoria continua  y \ $P_X$  su medida de probabiidad  y \
  $F_X$ \ su  funci\'on de repartici\'on. Si existe una  funci\'on no negativa \
  $p_X$ \ sobre $\Rset$ tal que
  %
  \[
  \forall \, B \in \B(\Rset), \quad P_X(B) = \int_B p_X(x) \, dx
  \]
  %
  (la    integral    debe   ser    entendido    como    en    el   sentido    de
  Lebesgue~\footnote{\SZ{Decir  un  poquito  sobre   la  medida  de  Lebesgue  y
      ref.~\cite{Leb04, Leb18, KolFom61, AthLah06, Bog07:v1, Coh13}}}), entonces
  $X$ es dicha {\it admitiendo una densidad} y $p_X$ es llamada {\it densidad de
    probabilidad} de $X$. En particular,
  %
  \[
  F_X(x) = \int_{-\infty}^x p_X(u) \, du
  \]
  %
  Dicho de  otra manera, si $F_X$ es  derivable sobre $\Rset$ (con  respeto a la
  medida  de Lebesgue),  por lo  menos por  partes, $X$  admite una  densidad de
  probabilidad y
  %
  \[
  p_X(x) = \frac{d F_X(x)}{dx}
  \]
  %
  Por abuso  de terminologia,  en lo que  sigue llamaremos $p_X$  tambi\'en {\it
    distribuci\'on de  probabilidad}, a pesar de  que no tiene  el mismo sentido
  que la masa de probabilidad del caso discreto.
\end{definicion}
%
La  escritura  integral de  $F_X$  justifica  de  nuevo la  denominaci\'on  {\it
  cumulativa} para  $F_X$. Adem\'as, se puede  ver por ejemplo que  en este caso
$\displaystyle P(a < x \le b) = \int_a^b p_X(x) \, dx = F_X(b) - F_X(a)$,}
%
%$p(x)$ que tiene el  sentido de que la probabilidad de que  $X$ tome valor entre
%$a$ y $b$ est\'a dada por:
%%
%$$
%\Pr(a\leq X\leq b) = \int_a^b p(x) \, dx ,
%$$
%
siendo   $\modif{p_X(x)}  \,   dx$  \modif{esquematicamente}   la   densidad  de
probabilidad de hallar a la variable con valores en el ``intervalo infinitesimal
entre $x$ y $x+dx$''.  La condici\'on de normalizaci\'on se escribe
%
\[
\int_\X p_X(x) \, dx = \int_\Rset p_X(x) \, dx = 1. 
\] 
%
En   la  \modif{figure   Fig.~\ref{fig:MP:ProbaContinua}-(a)}  se   muestra  una
representaci\'on gr\'afica  de una funci\'on  densidad de probabilidad  para una
variable continua  \modif{y en Fig.~\ref{fig:MP:ProbaContinua}-(b)  la funci\'on
  cumulativa correspondiente.
%
\begin{figure}[h!]
\begin{center} \input{TIKZ_MP/DistribucionReparticionContinua} \end{center}
%
  \leyenda{\modif{Ilustraci\'on de  una distribuci\'on de  probabilidad continua
      (a), y la funci\'on de repartici\'on asociada  (b), con \ $\X = [0 \, ; \,
      1) \cup [2  \, ; \, 3)$ \ y  \ $p_X(x) = \frac12 \un_{[0 \,  ; \, 1)}(x) +
      \frac1{4 \sqrt{x-2}} \un_{[2 \, ; \,  3)}(x)$, \ \ie \ $F_X(x) = \frac{x}{2}
      \,  \un_{[0 \, ;  \, 1)}(x)  + \frac{\sqrt{x-2}}{2}  \un_{[2 \,  ; \,
        3)}(x) + \frac12 \un_{[1 \, ; \, +\infty)}(x)$.  }}
\label{fig:ProbaContinua}
\end{figure}
}

%Tambi\'en, se puede caracterizar la ley de la variable continua $X$ por medio de
%su  \emph{funci\'on  de   repartici\'on}  o  \emph{funci\'on  de  distribuci\'on
%  cumulativa} (CDF por \emph{cumulative distribution function}):
%%
%$$
%F_X(x) = \Pr(X\leq x) = \int_{x_m}^x p(t) \, dt
%$$
%%
%que da la  probabilidad de que $X$ sea  menor o igual que cierto  valor $x$ dado
%(dentro del conjunto~$\Omega$ de todos  los valores posibles de la variable). En
%forma an\'aloga,  \ $\Pr(X\in  A) = \int_A  p(x) \,  dx$ acumula la  densidad de
%probabilidad en un subconjunto $A$ del espacio muestral.  Por la propiedad de la
%inclusi\'on,  se  tiene \  $\Pr(X\leq  x_1)  \leq  \Pr(X\leq x_2)$  siempre  que
%$x_1\leq x_2$; luego $F_X(x)$ es una funci\'on creciente
%%no decreciente ?? SI, LO DIRIA ASI
%de   $x$,  acotada   por  la   unidad,  con   valores  extremos   dados   por  \
%$\lim_{x\rightarrow -\infty} F_X(x)=0$  y $\lim_{x\rightarrow \infty} F_X(x)=1$,
%tomando $\Omega=\Rset$.  Adem\'as la derivada respecto de $x$ es la pdf:
%%
%$$
%\frac{dF_X(x)}{dx}=p(x) . 
%$$ 
%
\modif{Fijense de que una variable aleatoria puede ser ni continua, ni discreta:
%
\begin{itemize}
\item Sean $U$  \ y \ $V$ \ variables continuas,  independientes, de densidad de
  probabilidad $p_U  = p_V = \un_{[0 \,  ; \, 1)}$ ($U$  \ y \ $V$  \ son dichas
  uniformes sobre $[0  \, ; \, 1)$)  \ y sea \ $X  = V \un_{U <  \frac12}$, \ es
  decir \ $X(\omega)  = V(\omega)$ \ si \  $U(\omega) < \frac12$ \ y \  $0$ \ si
  no.  Entonces de la formula de  probabilidades totales, \ $F_X(x) = P(X \le x)
  = P\left(  (X \le  x) \left| \left(  U <  \frac12 \right) \right.   \right) \,
  P\left( U  < \frac12 \right)  \, + \,  P\left( (X \le  x) \left| \left(  U \ge
        \frac12 \right)  \right.  \right) \, P\left(  U \ge \frac12  \right) $ \
  \ie \ $F_X(x)  = \frac12 P\left( (V  \le x) \left| \left( U  < \frac12 \right)
    \right.   \right) \, +  \, P\left(  (0 \le  x) \left|  \left( U  \ge \frac12
      \right)\right. \right)$. \ Ahora, de la  independencia de \ $U$ \ y \ $V$,
  \ tenemos \ $F_X(x) =  \frac12 F_V(x) + \frac12 \un_{\Rset_+}(x) = \frac{x}{2}
  \un_{[0 \, ; \, 1)}(x) + \un_{\Rset_+}(x)$. Esta funci\'on de repartici\'on es
  representada figura Fig.~\ref{fig:MP:}: es ni discreta, ni continua. Entonces,
  a pesar  de que $\X  = [0  \, ; \,  1)$, un intervalo,  $X$ no es  continua (y
  tampoco no puede ser discreta).
  %
  \begin{figure}[h!]
  \begin{center} \input{TIKZ_MP/ReparticionMixta} \end{center}
  %
  \leyenda{\modif{Funci\'on de repartici\'on $F_X(x)  = \frac{x}{2} \un_{[0 \, ;
        \, 1)}(x) +  \un_{\Rset_+}(x)$ asociada a \ $X = V  \un_{U < \frac12}$ \
      con \ $U$ \ y \ $V$ \ variables continuas uniformes sobre $\X = [0 \, ; \,
      1)$. Noes tipo escalon, as\'i que $X$ no es discreta. A pesar de que $\X =
      [0 \,  ; \, 1)$  es un intervalo,  de la presencia del  salto en $x  = 0$,
      tampoco $X$ no es continua.}}
  \label{fig:ProbaMixta}
  \end{figure}
%
\item Sea  $U$ \ variable  continua uniforme sobre $[0  \, ; \,  1)$ \ y \  $X =
  \un_{U \not\in \Qset}$. Claramente  $X$ no es continua, pero $\X =  [0 \, ; \,
  1)   \backslash    \Qset$   \   siendo   no   numerable,    $X$   tampoco   es
  discreta~\footnote{\SZ{$X = 1$ casi siempre\ldots}}.
\end{itemize}
}

\modif{De  hecho, en el  caso continu,  discreto, o  cualquiera, se  conserva la
  forma integral  de la  medida de probabilidad  en una  forma tipo \  $P_X(B) =
  \int_B  dP_X(x)$   \  basado   sobre  la   teoria  de  la   medida  y   de  la
  integraci\'on~\cite{Leb04, KolFom61, AthLah06,  Bog07:v1, Bog07:v2, Coh13}. En
  el caso  discreto cierto  $X =  x_0$, la distribuci\'on  discreta es  dada por
  $p_X(x) = \un_{\{  x_0 \}}(x) = \un_{\{ 0 \}}(x-x_0)$. En  este caso, $P_X$ es
  dicha {\it medida de Dirac} y  $dP_X(x)$ es denotado \ $\delta_{x_0}(x)$ \ o \
  $\delta(x-x_0)$ \  tambi\'en llamado {\it delta  de Dirac}. Se  puede ver este
  Dirac como una}
%De aqu\'i  se observa que  la 
densidad de  probabilidad $p_X(x)$ \modif{pero} no es
% puede no  ser 
una funci\'on ``ordinaria'' pero  una funci\'on generalizada o distribuci\'on de
Schwarz~\footnote{\modif{El  Dirac,  visto  como  distribuci\'on de  Schwarz,  o
    funci\'on   generalizada,   tiene   una  ``representaci\'on   integral''   \
    $\displaystyle  \delta(x) =  \frac{1}{2\pi}  \int_{-\infty}^{\infty} e^{itx}
    dt$ \ o  m\'as rigurosamente transformada de Fourier de $x  \mapsto 1$ en el
    sentido  de  las  funciones  generalizadas o  distribuciones.   Eso  muestra
    claramente su  caracter no  ordinario (la integral  siendo divergente  en el
    sentido usual). Eso va m\'as all\'a de la meta del cap\'itulo y el lector se
    podr\'a  referir  a~\cite{Sch66,  GelShi64,  GelShi68} por  ejemplo.}}.   En
particular,   $F_X(x)  =   \un_{\Rset_+}(x-x_0)$  y   en  el   sentido   de  las
distribuciones, $\frac{d F_X}{dx} =  \delta_{x_0}$. Adem\'as, se usan en general
las propiedades, para cualquier function $f$,
%
\[
f(x) \delta(x-x_0) = f(x_0) \delta(x-x_0) \qquad \mbox{y} \qquad \int_\Rset f(x)
\delta(x-x_0) \, dx = f(x_0)
% \mbox{y} \qquad \int_{x_0}^{+\infty} f(x)  \delta(x-x_0) \, dx =
%\frac12 f(x_0)
\]
%
pero  hay que  entender la  integraci\'on a  trav\'es de  la medida  Dirac (esta
notaci\'on es un abuso de escritura, ej.~\cite{GelShi64}).
%  cuando $\Pr(X\leq x)$  es discontinua, pero  como mucho
%tiene  la  singularidad  de   una  distribuci\'on  \emph{delta  de  Dirac}  cuya
%representaci\'on integral es:
%
%$$
%\delta (x) = \frac{1}{2\pi} \int_{-\infty}^{\infty} e^{itx} dt . 
%$$
% SZ: LA  VERDAD ES  QUE NO ME  GUSTA MUCHO  escribir una distribucion  como una
% fuccion porque no viven en el  mismo espacio. Pero no importa. Para mi, cuando
% hay  una  discontinuidad  X no  admite  une  pdf  por  definicion del  'f'  de
% pdf\sum_{}

%Un caso especial  se tiene cuando la variable aleatoria $X$  toma el valor $x_0$
%con certeza.  La forma  de la pdf  es: \ $p(x)=\delta(x-x_0)$.  Otra situaci\'on
%particular es la distribuci\'on uniforme en  un intervalo; la pdf es de la forma
%\  $p(x)=\frac{1}{b-a} \  \forall  \  x\in[a,b]$, donde  $[a,b]$  es el  espacio
%muestral.
Usando las  \modif{medidas de  Dirac}, se puede  unificar el tratamiento  de las
variables aleatorias  discretas con las continuas \modif{(entre  otros)}: si una
variable aleatoria discreta toma los valores $x_i$ con probabilidades $p_X(x_i)$
respectivamente, entonces  formalmente se puede describir  mediante una variable
aleatoria   continua  $X$   con   ``funci\'on  densidad   de  probabilidad''   \
\modif{$p_X(x) = \sum_i p_i \, \delta(x-x_i)$ donde $p_i = P(X = x_i)$.}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subseccion{Vector aleatorio}


Cuando se trabaja  con $d\geq 2$ variables aleatorias  es conveniente definir un
\emph{vector aleatorio} de dimensi\'on $d$,  y apelar para su estudio a nociones
del \'algebra  lineal y  a notaci\'on matricial.   Se tiene el  vector aleatorio
$d$-dimensional  \  $\mathbf{X} =  \{X^1,  \ldots,  X^d  \}$, o  simplemente  $X
=  \begin{pmatrix}  X^1  &  \cdots  & X^d  \end{pmatrix}^t$,  caracterizado  por
$d$-uplas de variables aleatorias reales, con funci\'on densidad de probabilidad
conjunta~$p(x^1, \ldots, x^d)$. La ley  del vector $\mathbf{X}$ es una medida de
probabilidad sobre $\Rset^d$, con
%
$$
P_{\mathbf{X}}(\mathbf{A})  =   \Pr(\mathbf{X}\in\mathbf{A})  =  \int_{\mathbf{A}}
p(x^1, \ldots, x^d)\ dx^1\ldots dx^d
$$
%
para  $\mathbf{A}  \subset \mathbf{\Omega}$,  siendo  la  pdf  conjunta $p$  una
funci\'on positiva, definida sobre $\mathbf{\Omega}\subset\Rset^d$, y tal que se
satisface la condici\'on de normalizaci\'on:
%
$$
\int_{\mathbf{\Omega}} p(x^1, \ldots, x^d)\ dx^1\ldots dx^d  = 1 .
$$

La  \emph{funci\'on densidad  de  probabilidad marginal}  que  caracteriza a  la
variable aleatoria  $X^i$ es la  ley que se  obtiene integrando la  pdf conjunta
sobre todas las variables excepto la $i$-\'esima:
%
$$
p_{X^i}(x^i)  =  \int_{\mathbf{\Omega}^{(i)}}  p(x^1, \ldots,  x^d)\  dx^1\ldots
dx^{i-1} dx^{i+1} \ldots dx^d
$$
%
donde $\mathbf{\Omega}^{(i)}\subset\Rset^{d-1}$  barre el espacio  muestral para
$X^1, \ldots, X^{i-1}, X^{i+1}, \ldots, X^d$.

Las  $d$  variables  aleatorias  $X^1,  \ldots,  X^d$  de  un  vector  aleatorio
$\mathbf{X}$ se dicen \emph{independientes} si corresponden a eventos mutuamente
independientes. Esto se  da si y s\'olo  si la pdf conjunta se  factoriza en las
$d$ pdf marginales:
%
$$
p(x^1, \ldots, x^d) = p_{X^1}(x^1) \cdots p_{X^d}(x^d) . 
$$

\

\SZ{Reordenamiento y relaci\'on de mayorizaci\'on  : a ver como trasladar lo que
  ya estaba en en cap. 2 mas los ejemplos. Todo comentado por ahora}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subseccion{Transformaci\'on de variables aleatorias}


Sea $X$ una  variable aleatoria (continua, en general)  definida en el intervalo
$[x_m, x_M]$ con funci\'on densidad  de probabilidad $p(x)$. Sea $Y=\Psi(X)$ una
funci\'on real  de $X$, luego $Y$  toma los valores $y=\Psi(x)$  en el intervalo
$[y_m,y_M]$.  La funci\'on  densidad  de probabilidad  $q(y)$  para la  variable
aleatoria transformada $Y$ se obtiene  de la siguiente manera, dependiendo de la
forma de la transformaci\'on:

\begin{itemize}
\item Si  $\Psi$ es inversible, con  inversa (\'unica), se  tiene \ $x=\Phi(y)$,
  con  $\Phi=\Psi^{-1}$.  A partir  de  la  propiedad  de conservaci\'on  de  la
  probabilidad
  %
  $$
  |q(y)\, dy| = |p(x) \, dx|
  $$ 
  %
  para  una correspondencia  biun\'ivoca  entre $x$  e  $y$, se  obtiene la  pdf
  transformada
  %
  $$
  q(y)  = p(x)  \left| \frac{dx}{dy}  \right| =  p\left(\Phi(y)\right)  \ \left|
    \Phi'(y)   \right|   =  \frac{p\left(\Phi(y)\right)}{\left|   \Psi'(\Phi(y))
    \right|} .
  $$
  %
  Una forma alternativa  de derivar este resultado es partir  de la funci\'on de
  repartici\'on:
  %
  $$
  F_Y(y)  =  P(Y\leq  y)  =  P(\Psi(X)  \leq  y)  =  P(X\leq  \Psi^{-1}  (y))  =
  F_X(\Phi(y))
  $$
  %
  y  calcular las  derivadas del  primer y  \'ultimo t\'erminos  respecto  de la
  variable transformada~$y$.
%
\item Si la inversa de $\Psi$  es multivaluada, cada valor de $y$ se corresponde
  con  un conjunto de  valores de  $x$, digamos  $\{x_k =  \Phi_k(y), \  k=1, 2,
  \ldots\}$.  Debido a  que  estas soluciones  son  mutuamente excluyentes,  las
  probabilidades se suman, de modo que
  %
  $$
  q(y)   =    \sum_k   p(x_k)   \left|   \frac{dx_k}{dy}    \right|   =   \sum_k
  \frac{p\left(\Phi_k(y)\right)}{\left| \Psi'(\Phi_k(y)) \right|} ,
  $$
  %
  que   formalmente  se   puede  expresar   como  \   $q(y)  =   \int   p(x)  \,
  \delta(y-\Psi(x)\,) \ dx$ , donde se  usa la expansi\'on de la funci\'on delta
  en  t\'erminos de sus  ceros: \  $\delta(y-\Psi(x)\,)= \sum_k  \delta(x-x_k) /
  |\Psi'(x_k)| $.\newline  Por ejemplo, para la transformaci\'on  de variables \
  $Y=X^2$ se tiene \  $Y=\Psi(X)=X^2$ cuyas inversas son \ $X_1=\Phi_1(Y)=+\sqrt
  Y$  y   $X_2=\Phi_2(Y)=-\sqrt  Y$;  luego   \  $q(y)=\frac{p(\sqrt  y)}{2\sqrt
    y}+\frac{p(-\sqrt y)}{|-2\sqrt y|}$ , para $y>0$.
\end{itemize}

\hfill

Consideramos ahora el  caso de un vector aleatorio  $\mathbf{X} = \{X^1, \ldots,
X^d\}$  con  funci\'on  densidad  de  probabilidad conjunta  \  $p(x^1,  \ldots,
x^d)$. Se  define otro vector aleatorio  \ $\mathbf{Y} =  \{Y^1, \ldots, Y^d\}$,
por   medio   de   las   transformaciones  \   $Y^j=\Psi^j(X^1,\ldots,X^d)$,   \
$j=1,\ldots,d$. Suponiendo que las  funciones $\Psi^j$ tienen inversa (\'unica),
se  puede escribir \  $X^j=\Phi^j(Y^1,\ldots,Y^d)$ para  cada $j$.  La funci\'on
densidad de probabilidad conjunta $q(y^1,\ldots,y^d)$ para $\mathbf{Y}$ se puede
obtener a partir de la propiedad de conservaci\'on de la probabilidad
%
$$
|q(y^1,\ldots,y^d)\ dy^1\cdots dy^d| = |p(x^1,\ldots,x^d) \ dx^1\cdots dx^d| .
$$ 
%
Para  una  correspondencia biun\'ivoca  entre  $\mathbf{x}$  e $\mathbf{y}$,  se
obtiene la pdf transformada
%
$$
q(y^1,\ldots,y^d) = \left| \Jac_\Phi \right| \, p(x^1,\ldots, x^d) 
%%= \int  p(x^1,\ldots, x^d) \delta(y^1-\Psi^1) .......  dx^1 .....
$$
%
donde  $\Jac_\Phi =  \frac{\partial(\Phi^1  , \ldots  , \Phi^d)}{\partial(y^1  ,
  \ldots , y^d)}$ es el Jacobiano de la transformaci\'on.

%% Ejercicio: Estudiar el caso multivaluado / Resolver un ej. 

\hfill

Una  \emph{variable  aleatoria  compleja}   $Z=X+i  Y$  puede  interpretarse  en
t\'erminos de las  dos variables aleatorias reales $X$ e $Y$.  La pdf asociada \
$P(z)=p(x,y)$ est\'a dada por la  funci\'on densidad de probabilidad conjunta de
las variables reales. La condici\'on de normalizaci\'on se escribe
%
$$
\int P(z) \, d^2 z = 1
$$
%
donde $d^2 z=dx\,dy$.