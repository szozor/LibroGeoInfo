\seccion{Variables aleatorias y distribuciones de probabilidad}
\label{s:variablealeatoria}

{\it  En  un  experimento  o  un  dado  proceso,  los  posibles  resultados  son
  t\'ipicamente  n\'umeros reales, siendo  cada n\'umero  un evento.   Luego los
  resultados  son mutuamente  excluyentes. Se  considera a  esos  n\'umeros como
  valores de una  \emph{variable aleatoria} $X$ a valores  reales, que puede ser
  discreta o continua.}

Formalmente, la noci\'on de variable aleatoria  se var a apoya sobre la noci\'on
de funci\'on medible. M\'as adelante, vamos a necesitar definir la integraci\'on
de manera general, m\'as all\'a del enfoque de Riemann (``a la Lebesgue'') as\'i
que la  noci\'on de derivada de  una medida con  respeto a una otra  para defnir
densidades de  probabilidades al imagen de  densidad de masas  en mec\'anica por
ejemplo~\cite{Leb04, Leb18, KolFom61, AthLah06, Bog07:v1, Coh13}.


% ================================= Medida, integral, densidades

\subseccion{Consideraciones preliminarias}
\label{sec:MP:VAPreliminaria}

La  primera noci\'on  que subtiende  a la  definici\'on formal  de  una variable
aleatoria es la de funci\'on medible:

\begin{definicion}[Funci\'on medible]
  Sean  \ $(\Omega,\A)$  \ y  \ $(\Upsilon,\B)$  \ dos  espacios  medibles.  Una
  funci\'on $f: \Omega \mapsto \Upsilon$ es dicha {\it $(\A,\B)$-medible} si
  %
  \[
  \forall \,  B \in  \B, \quad  A \equiv f^{-1}(B)  = \left\{  \omega \in  A: \,
    f(\omega) \in B \right\} \: \in \: \A
  \]
  %
  Dicho de  otra manera,  la pre-imagen  de un elemento  dada de  $\B$ (elemento
  medible)  partenece  a  $\A$  (elemento  medible).  A  veces,  se  dice  m\'as
  simplemente de que $f: (\Omega,\A) \mapsto (\Upsilon,\B)$ es medible por abuso
  de escritura.
\end{definicion}

Adem\'as, saliendo de un espacio de medida y una funci\'on $f$ medible, se puede
definir una medida imagen  sobre el espacio de llegada~\cite{AthLah06, Bog07:v1,
  Coh13}:
%
\begin{teorema}[Teorema de la medida imagen]\label{th:MP:MedidaImagen}
  Sean  \ $(\Omega,\A,\mu)$  \  un espacio  de  medida, \  $(\Upsilon,\B)$ \  un
  espacio  medible  y  una  funci\'on  $f:  (\Omega,\A)  \mapsto  (\Upsilon,\B)$
  medible. Sea $\mu_f$ tal que
  %
  \[
  \forall \,  B \in  \B, \quad  \mu_f(B) = \mu\left( f^{-1}(B) \right)
  \]
  %
  Entonces, $\mu_f$ es una medida sobre el espacio medible $(\Upsilon,\B)$ \ \ie
  \ $(\Upsilon,\B,\mu_f)$ \ define un espacio de medida.  Adem\'as, $\mu(\Omega)
  =  \mu_f(\Upsilon)$ (posiblemente  infinitas).  $\mu_f$ es  dicha {\it  medida
    imagen de $\mu$ por $f$}.
\end{teorema}
%
\begin{proof}
  Por  definici\'on,  claramente $\mu_f  \ge  0$ \  y  por  definici\'on de  una
  funci\'on,  $f^{-1}(\emptyset)  =   \emptyset$  \  dando  $\mu_f(\emptyset)  =
  \mu(\emptyset) =  0$.  Luego,  si para  un conjunto numerable  $\{ B_j  \}$ de
  elementos  de $\B$  disjuntos entre  s\'i, las  preimagenes de  los  $B_j$ son
  disjuntos tambi\'en entre  s\'i (para $k \ne j$ no se  puede tener $\omega \in
  f^{-1}(B_j) \cap f^{-1}(B_k)$ si no $\omega$ tendr\'ia dos imagenes distinctas
  por  $f$).   Entonces  $\displaystyle  f^{-1}\left( \bigcup_j  B_j  \right)  =
  \bigcup_j  f^{-1}(B_j)$.   Eso   implica  de  que  $\displaystyle  \mu_f\left(
    \bigcup_j B_j \right) = \mu\left( f^{-1}\left( \bigcup_j B_j \right) \right)
  =  \bigcup_j  \mu\left( f^{-1}(B_j)  \right)  =  \sum_j \mu\left(  f^{-1}(B_j)
  \right) = \sum_j  \mu_f(B_j)$.  Finalmente, necesariamente $f^{-1}(\Upsilon) =
  \Omega$  (es incluida y  $f(\Omega)$ siendo  en $\Upsilon$  son necesariamente
  iguales) lo  que cierra la  prueba~\footnote{De hecho, se  puede sencillamente
    probar que la  preimagen de una uni\'on numerable (que  sean disjuntos o no)
    es la uni\'on  de las preimagenes; lo mismo occure  para la intersecci\'on y
    adem\'as la  preimagen del  complemento es el  complemento de  la preimagen.
    Eso  es  conocido  como  {\it  leyes de  de  Morgan}~\cite{AthLah06,  Coh13,
      HogMck13}              (ver              tambi\'en~\cite[Cap.~1]{KolFom57}
    y~\cite[Caps.~5~\&~6]{KolFom61}).}
\end{proof}

\

Un espacio  jugando un rol particular es  $\Rset^d$, a lo cual  se puede asociar
una $\sigma$-\'algebra particular~\cite{AthLah06, Bog07:v1, Bog07:v2, Coh13}:
%
\begin{definicion}[$\Rset^d$ y Borelianos]
  Para  cualquier  $d  \ge  1$  entero,  llamamos  Borelianos  $\B(\Rset^d)$  de
  $\Rset^d$  la $\sigma$-\'algebra  m\'as peque\~na  generada por  los productos
  cartesianos   $\displaystyle   \optimes_{i=1}^d  (-\infty   \,   ;  \,   b_i]$
  \big(equivalentemente,  por los  abiertos de  $\Rset^d$, o  tambi\'en  por los
  productos cartesianos de intervalos  $\displaystyle \optimes_{i=1}^d (a_i \, ;
  \, b_i]$\big), \ie uniones numerables, intersecciones numerables, complementos
  de   estos   intervalos.    $\B(\Rset^d)$   es  tambi\'en   llamado   o   {\it
    $\sigma$-\'algebra de Borel de $\Rset^d$}.
\end{definicion}

\

Se necesita ahora definir la  noci\'on de integraci\'on de una funci\'on medible
con respeto a una medida:
%
\begin{definicion}[Medida e intrgraci\'on]
  Para una medida  cualquiera, sobre un espacio de  medida $(\Omega,\A,\mu)$, se
  define la integraci\'on a partir de
  %
  \[
  \forall \, A \in \A,  \quad \int_A d\mu(\omega) = \int_\Omega \un_A(\omega) \,
  d\mu(\omega) = \mu(A)
  \]
  %
  donde
  %
  \[
  \un_A(\omega) = \left\{
  \begin{array}{clr}
  1 & \mbox{si} \quad \omega \in A\\
  0 & \mbox{si no}
  \end{array} \right.
  \]
  %
  es  la funci\'on  indicadora del  conjunto $A$.   $d\mu(\omega)$ se  escribe a
  veces  tambi\'en $\mu(d\omega)$, medida  de un  ``infinitesimo''.  Claramente,
  por  propiedades  de una  medida,  para $  A_i,  A_j$  disjuntos $\un_{A_i}  +
  \un_{A_j}  =  \un_{A_i \cup  A_i}$,  dando  $\displaystyle \int_\Omega  \left(
    \un_{A_i} + \un_{A_j} \right) d\mu(\omega) = \mu(A_i \cup A_j) = \int_\Omega
  \un_{A_i} d\mu(\omega)  + \int_\Omega \un_{A_j} d\mu(\omega)$  y entonces, sin
  perdida  de  generalidad~\footnote{Si  $A_i,  A_j$ no  son  disjuntos,  sufice
    considerar $A_i\backslash A_j, \: A_j\backslash  A_j, A_i \cap A_j$ \ con $A
    \backslash B = \{ \omega: \omega \in  A \: \mbox{y} \: \omega \not\in B\}$ \
    y respectivamente los coefficientes \  $\alpha_i, \: \alpha_j, \: \alpha_i +
    \alpha_j$.}   para  un  conjunto  $\{  A_j  \}$  numerable,  con  los  $A_j$
  disjuntos, y $\{ \alpha_j \}$ reales no negativos, la integral de la funci\'on
  escalonada \ $\displaystyle \sum_j \alpha_j \un_{A_j}$ \ es dada por
  %
  \[
  \int_\Omega \left( \sum_j \alpha_j \un_{A_j}(\omega) \right) \, d\mu(\omega) =
  \sum_j \alpha_j \int_\Omega \un_{A_j}(\omega) \, d\mu(\omega)
  \]
  %
\end{definicion}


Antes de definir la integraci\'on de una funci\'on real, medible, cualquiera, el
\'ultimo paso que falta es el siguiente:
%
\begin{teorema}[Funci\'on medible como limite]
  Sea $g: (\Omega,\A) \mapsto  (\Rset,\B(\Rset))$, no negativa y medible, existe
  una serie  $\{ g_n  \}_{n \in \Nset}$  creciente de funciones  escalonadas que
  converge simplemente (punto a punto) hacia $g$.
\end{teorema}
%
\begin{proof}
  La  serie   $\displaystyle  g_n   =  \sum_{k=0}^{n  2^n-1}   \frac{k}{2^n}  \,
  \un_{g^{-1}\left(  \left[  \frac{k}{2^n}   \,  ;  \,  \frac{k+1}{2^n}  \right)
    \right)} + n \, \un_{g^{-1}\left( \left[ n \, ; \, +\infty \right) \right)}$
  es  escalonada, creciente  y  converge hacia  $g$  \ (fijense  que esta  serie
  comparte la idea subtendido a la integraci\'on de Riemann).
\end{proof}

De  este resultado, se  puede generalizar  la noci\'on  de integraci\'on  de una
funci\'on real:
%
\begin{definicion}[Integraci\'on de una funci\'on real]
  Sea $g: (\Omega,\A)  \mapsto (\Rset,\B(\Rset))$, no negativa y  medible, y $\{
  g_n  \}_{n  \in  \Nset}$  creciente  de  funciones  escalonadas  que  converge
  simplemente hacia $g$. Por definici\'on,
  %
  \[
  \int_{\Omega}  g(\omega) \,  d\mu(\omega)  = \lim_{n  \to \infty}  \int_\Omega
  g_n(\omega) \, d\mu(\omega)
  \]
  %
  Fijense de que el limite puede ser infinita.\newline Sea ahora $g: (\Omega,\A)
  \mapsto  (\Rset,\B(\Rset))$ medible cualquiera.  Se verifica  sencillamente de
  que tambi\'en $|g|$ es medible y,  por definici\'on, $g$ es dicha integrable a
  $\mu$ si la integral de $|g|$ es finita,
  %
  \[
  g\: \mbox{ integrable} \quad  \Leftrightarrow \quad \int_\Omega |g(\omega)| \,
  d\mu(\omega) < +\infty
  \]
  %
  Por  fin,  se escribe  $g  =  g_+  + g_-$  con  $g_+  =  \max(g,0)$ y  $g_-  =
  \min(g,0)$. Es  sencillo ver de que  si $g_+$ y  $g_-$ son medible. Si  $g$ es
  integrable, necesariamente $g_+$ y $g_-$ son integrables, y, por definici\'on
  %
  \[
  \int_\Omega   g(\omega)   \,  d\mu(\omega)   =   \int_\Omega  g_+(\omega)   \,
  d\mu(\omega) - \int_\Omega \left( - g_-(\omega) \right) \, d\mu(\omega)
  \]
\end{definicion}

\

Seguimos esta secci\'on con la noci\'on  de derivada de una medida con respeto a
una otra, dando una definici\'on muy general de una densidad:
%
\begin{definicion}[Densidad de una medida]\label{def:MP:DensidadMedida}
  Sean  $\mu$  y  $\nu$  dos  medidas  cualquieras  sobre  une  espacio  medible
  $(\Omega,\A)$.  Si  existe una funci\'on  real no negativa $p:  \Omega \mapsto
  \Rset_+$ medible tal que
  %
  \[
  \forall \, A \in \A, \quad \nu(A) = \int_A p(\omega) d\mu(\omega)
  \]
  %
  $p$ es llamado densidad de $\nu$ con respeto a $\mu$ y es a veces notado
  %
  \[
  p = \frac{d\nu}{d\mu}
  \]
  %
  tambi\'en llamada derivada de Radon-Nikod\'ym.
\end{definicion}
%
Es sencillo ver  de que si $\mu(A)  = 0$, necesariamente $\nu(B) =  0$: $\nu$ es
dicha  {\it  absolutamente continua}  con  respeto  a  $\mu$. Reciprocamente  se
muestra de que  si una medida $\nu$ es absolutamente continua  con respeto a una
medida  $\mu$, \  $\nu$ admite  una densidad  (derivada de  Radon-Nikod\'ym) con
respeto a  $\mu$~\cite{Nyk30, AthLah06, Bog07:v1,  Coh13}.  Se muestra  que esta
derivada  es \'unica  en un  sentido patrticular,  basado sobre  la  noci\'on de
igualdad casi siempre:

\begin{definicion}[Igualidad $\mu$-casi siempre]
  Dos funciones  medibles \ $p_1$  \ y \  $p_2$ \ son dichas  iguales $\mu$-casi
  siempre,
  %
  \[
  p_1 = p_2 \quad (\mu-c.s.)
  \]
  %
  si y solamente son iguales excepto sobre un conjunto de medida nula,
  %
  \[
  \mu\left( \left\{ \omega: \: p_1(\omega) \ne p_2(\omega) \right\} \right) = 0
  \]
\end{definicion}
%
\noindent Ahora, si  dos funciones \ $p_1  = p_2 \quad (\mu-c.s.)$, y  $C$ es el
conjunto donde no son iguales, notando \ $A \backslash B = \{ \omega: \omega \in
A \:  \mbox{y} \:  \omega \not\in B\}$,  de \ $\displaystyle  \int_A p_1(\omega)
d\mu(\omega) = \int_{A\backslash C} p_1(\omega) d\mu(\omega) = \int_{A\backslash
  C} p_2(\omega) d\mu(\omega)  = \int_A p_2(\omega) d\mu(\omega)$ se  ve que dos
funciones iguales casi  siempre pueden ser densidad de una  medida con respeto a
una otra.   En todo lo que sigue,  hablaremos de ``la'' densidad  de una medida,
salvo si se encesita explicitamente tener en cuenta esta sutileza.

\

En todo lo que sigue, una medida que juega un rol particular es la medida de Lebesgue,
%
\begin{definicion}
  La medida de  Lebesgue $\mu_L$ sobre $(\Rset^d,\B(\Rset^d))$ la,  tal que para
  cualquier porducto cartesiano de intervalos,
  %
  \[
  \mu_L\left(  \optimes_{i=1}^d  (a_i  \,  ;  \, b_i)  \right)  =  \prod_{i=1}^d
  (b_i-a_i)
  \]
  %
\end{definicion}

En lo que sigue, tratando  de igualdad $\mu_L$-casi siempre, diremos simplemente
``casi  siempre''  $(c.s.)$, subentiendo  que  es con  respeto  a  la medida  de
Lebesgue.

\

Con estas series  de definiciones, tenemos todo lo  necesario para introducir la
definici\'on de variables/vectores aleatoria(o)s reales y sus caracterizaciones.


% ================================= VA y distribuci\'on de probabilidad

\subseccion{Variables aleatorias, vectores aleatorios y distribuci\'on de probabilidad}
\label{sec:MP:VAGeneral}

Empezamos con la  noci\'on de variable aleatoria real, que  queremos var como el
resultado de un experimento o de un evento dado~\cite{AthLah06, Coh13, Bre88}:
%
\begin{definicion}[Variable aleatoria real]
  Una variable aleatoria real es una funci\'on medible
  %
  \[
  X: (\Omega,\A,P) \mapsto (\Rset,\B(\Rset),P_X)
  \]
  %
  donde la medida  $P_X$ sobre $\B(\Rset)$ es la medida imagen  de $P$.  \ $P_X$
  es frecuentemente llamada {\it distribuci\'on  de probabilidad} o {\it ley} de
  la variable aleatoria $X$. En lo que sigue, escribiremos los eventos
  %
  \[
  (X \in B) \equiv X^{-1}(B) = \{ \omega \in \Omega: \: X(\omega) \in B \}
  \]
  %
  as\'i que, por definici\'on,
  %
  \[
  P_X(B) = P(X \in B)
  \]
\end{definicion}
%
Para  ilustrar esta definici\'on,  tomando el  ejemplo de  un dado,  $\Omega$ es
discreto y representa  las caras, mientras de que los  numeros ser\'an la imagen
de $\Omega$ por $X$ (ej. $X(\omega_j) = j, \quad j = 1, \ldots , 6$).

Fijense de que, por las  propiedades de una medida sobre una $\sigma$-\'algebra,
para caracterizar completamente la  distribuci\'on $P_X$ es suficiente conocerla
sobre  los intervalos de  la forma  $(-\infty \,  ; \,  b]$. Eso  da lugar  a la
definici\'on  de  la funci\'on  de  repartici\'on~\cite{AthLah06, Coh13,  Bre88,
  HogMck13}:
%
\begin{definicion}[Funci\'on de repartici\'on]
  Por  definici\'on,  la  funci\'on  de  repartici\'on  $F_X$  de  una  variable
  aleatoria es definida por
  %
  \[
  F_X(x) = P_X((-\infty \, ; \, x]) = P(X \le x)
  \]
  %
  A veces, por abuso de terminologia,  se denomina $F_X$ como ley de la variable
  aleatoria. Se  encuentra tambi\'en  en la literatura  la terminologia  de {\it
    funci\'on cumulativa} (cdf por cumulative density function en ingl\'es).
\end{definicion}
%
Naturalmente, de las propiedades de una medida de probabilidad,
%
\begin{itemize}
\item $0 \le F_X(x) \le 1$;
%
\item $\displaystyle \, \lim_{x \to -\infty} F_X(x) = 0$ \ y \ $\displaystyle \,
  \lim_{x \to +\infty} F_X(x) = 1$  (viene de $P_X(\emptyset) = 0$ y $P_X(\Rset)
  = 1$);
%
\item  $F_X$ es creciente  \big(viene de  que \  $x_1 \le  x_2 \:  \Leftrightarrow \:
  (-\infty \, ; \, x_1] \subseteq (-\infty \, ; \, x_2]$\big);
%
\item $F_X$ no es necesariamente continua  (lo vamos a ver m\'as adelante), pero
  en cada punto $x$ es continua a su derecha (ver punto anterior).
\end{itemize}


Cuando se trabaja  con $d\geq 2$ variables aleatorias  es conveniente definir un
{\it vector aleatorio}  de dimensi\'on $d$, y apelar para  su estudio a nociones
del \'algebra  lineal y  a notaci\'on matricial.   Se tiene el  vector aleatorio
$d$-dimensional \ $X = \begin{bmatrix} X_1 & \cdots & X_d \end{bmatrix}^t$ donde
$\cdot^t$  denota  la  transpuesta,  caracterizado por  $d$-uplas  de  variables
aleatorias reales.   Como en  el caso  univariado, se define  este vector  de la
manera siguiente~\cite{AthLah06, Coh13, Bre88}:
%
\begin{definicion}[Vector aleatorio real]
  Un vector real es una funci\'on medible
  %
  \[
  X: (\Omega,\A,P) \mapsto (\Rset^d,\B(\Rset^d),P_X)
  \]
  %
  donde  $\B(\Rset^d)$  son  los  borelianos  de  $\Rset^d$,  $\sigma$-\'algebra
  generada por  los productos cartesianos $(-\infty  \, ; \,  b_1] \times \cdots
  \times (-\infty \,  ; \, b_d]$ y donde la medida  $P_X$ sobre $\B(\Rset^d)$ es
  la medida  imagen de  $P$ llamada {\it  distribuci\'on de probabilidad}  de la
  variable aleatoria (o vector aleatorio) \ $X$. Como en el caso escalar,
  %
 \[
 (X \in B) \equiv X^{-1}(B) = \{ \omega \in \Omega: \: X(\omega) \in B \} \qquad
 \mbox{y} \qquad P_X(B) = P(X \in B)
 \]
\end{definicion}
%
De las propiedades de una medida sobre una $\sigma$-\'algebra, para caracterizar
completamente la distribuci\'on $P_X$ de nuevo es suficiente conocerla sobre los
elementos de  la forma $\displaystyle  \optimes_{i=1}^d (-\infty \, ;  \, b_i]$,
\ie  la funci\'on  de repartici\'on  multivariada~\cite{AthLah06,  Coh13, Bre88,
  HogMck13}:
%
\begin{definicion}[Funci\'on de repartici\'on multivariada]
  Por  definici\'on,  la  funci\'on  de  repartici\'on  $F_X$  de  un vector
  aleatorio es definida en $x = (x_1 , \ldots , x_d)$ por
  %
  \[
  F_X(x) =  P_X\left( \optimes_{i=1}^d (-\infty \,  ; \, x_i]  \right) = P\left(
    \bigcap_{i=1}^d (X_i \le x_i) \right)
  \]
\end{definicion}
%
De nuevo, de las propiedades de una medida de probabilidad,
%
\begin{itemize}
\item $0 \le F_X(x) \le 1$;
%
\item $\displaystyle  \, \lim_{\forall  i, x_i \to  -\infty} F_X(x)  = 0$ \  y \
  $\displaystyle \, \lim_{\forall i, x_ \to +\infty} F_X(x) = 1$;
%
\item $F_X$ es creciente con respecto a cada variable $x_i$.
\end{itemize}
%
Al  final, para  un subconjunto  $I_k =  (i_1,\ldots,i_k)$ de  $1 \le  k  \le d$
elementos de  $\{ 1  , \ldots ,  d \}^k$,  $X_{I_k} = \begin{bmatrix}  X_{i_1} &
  \cdots   &   X_{i_k}\end{bmatrix}^t$  es   obviamente   un  vector   aleatorio
$k$-dimensional. Es entonces sencillo ver de que
%
\[
F_{X_{I_k}}(x_{I_k}) = \lim_{\forall i \not\in I_k, x_i \to +\infty} F_X(x)
\label{pagina:MP:MarginalesF}
\]
%
(viene de  que $\bigcap_{j=1}^k (X_{i_j}  \le x_{i_j}) =  \left( \bigcap_{j=1}^k
  (X_{i_j} \le x_{i_j}) \right) \bigcap  \left( \bigcap_{i \not\in I_k} (X_i \in
  \Rset)  \right)$). Esta  funci\'on es  dicha {\it  funci\'on  de repartici\'on
  marginale} de $F_X$.

Cerramos estas generalidades con el caso de variables independientes:
%
\begin{definicion}[Independencia]
  Sean $d$  variables aleatorias  $X_i$ y  $X = \begin{bmatrix}  X_1 &  \cdots &
    X_d  \end{bmatrix}^t$.   Los  $X_i$  son  mutualmente  independientes  si  y
  solamente si, para  cualiquier ensemble de conjuntos $B_i$,  los eventos $(X_i
  \in \B_i)$ son mutualmente independientes, \ie
  %
  \[
  P_X\left( \optimes_{i=1}^d B_i \right) = \prod_{i=1}^d P_{X_i}(B_i)
  \]
  %
  Es equivalente a
  %
  \[
  F_X(x) = \prod_{i=1}^d F_{X_i}(x_i)
  \]
  %
  La ley del vector aleatorio se factoriza.
\end{definicion}
%
Es importante notar de que no es equivalente a tener la independencia por pares,
como ilustrado en el fin de la seci\'on precediente.

\

M\'as  all\'a de  este  enfoque  general, dos  casos  particulares de  variables
aleatorias son  de inter\'es:  las variables discretas  y las continuas.   En el
primer caso  $X(\Omega)$ es discreto, finito  o no.  La meta  de las susecciones
siguientes es estudiar las particularidades de cada caso.

Par fijar unas notaciones, en todo lo que sigue, escribiremos
%
\[
\X = X(\Omega)
\]
%
conjunto de  llegada de $X$, o conjunto  de valores que puede  tomar la variable
aleatoria.  A  veces, por  razones de simplificaciones,  se considera  $\X$ como
siendo el  espacio muestral  y se olvida  de que  $X$ sea una  funci\'on medible
entre espacios de probabilidades,  \ie se trabaja en $(\Rset^d,\B(\Rset^d),P_X)$
como en el espacio preimagen.



% ================================= Discreta

\subseccion{Variable aleatoria discreta}
\label{sec:MP:VADiscreta}

\begin{definicion}[Variable aleatoria discreta]
  Una  variable aleatoria es  dicha {\it  discreta} cuando  $\X =  X(\Omega)$ es
  discreto,  finito o  infinito numerable.   En  lo que  sigue, denotaremos  por
  $|\X|$  el cardinal  de $\X$,  posiblemente infinito.  En otras  palabras, los
  posibles  valores de  una  variable  aleatoria discreta  $X$  consisten en  un
  conjunto contable (finito  o infinito numerable) de n\'umeros  reales, \ $\X =
  \{ x_j \}$ \ y se puede escribir \ $X$ \ como una {\it variable escalonadas},
  %
  \[
  X = \sum_j x_j \un_{A_j} \quad \mbox{con} \quad A_j = X^{-1}(\{ x_j \})
  \]
\end{definicion}
%
\noindent (ver ej.  ~\cite{AthLah06, HogMck13}).  Fijense de que  $\Omega$ no es
necesariamente discreto.  Por ejemplo, si  $\omega$ es la posici\'on de un punto
sobre una linea, y \ $X(\omega) = 0$ si $\omega$ es a la izquierda de un umbral, y
$X(\omega) = 1$ si $\omega$  es a su derecha, $\X = \{ 0 \,  ; \, 1 \}$ mientras
de que $\Omega$ no es discreto.

En el  caso de una variable  aleatoria discreta $X$,  las probabilidades $P_X(\{
x_j \})  = P(X = x_j), \:  x_j \in \X$ caracterisan  completamente esta variable
aleatoria~\cite{AthLah06, HogMck13}:
%
\begin{definicion}[Funci\'on de masa de probabilidad]
  Por  definici\'on, la  funci\'on  de  masa de  probabilidad  de $X$,  variable
  aleatoria discreta tomando sus valores sobre $\X$ es dada por
  %
  \[
  p_X(x) \equiv P(X = x) = P_X( \{ x\} ) \quad x \in \X
  \]
  %
  Por   abuso  de   denominaci\'on,  llamaremos   en  este   libro   $p_X$  {\it
    distribuci\'on de probabilidad}. Adem\'as, usaremos tambi\'en la notaci\'on
  %
  \[
  p_X = \begin{bmatrix} \cdots & p_X(x_j) & \cdots \end{bmatrix}^t
  \]
  %
  dicho {\it vector de probabilidad}, de tama\~no $|\X|$, posiblemente infinito.
\end{definicion}
%
Fijense de  que, $P_X$ siendo  una medida  de probabilidad, $p_X  \ge 0$ \  y es
obviamente normalizada en el sentido de que
%
\[
\sum_{x_j \in \X} p_X(x_j) = 1
\]
%
En  la  Fig.~\ref{fig:MP:ProbaDiscreta}-(a)   se  muestra  una  representaci\'on
gr\'afica de una distribuci\'on de probabilidad discreta.
%
En particular,
%
\[
\forall \,  B \in  \B(\Rset), \quad  P_X(B) = \sum_{x  \in \X  \cap B}  p_X(x) =
\int_B dP_X(x)
\]
%
lo que da, tratando de la funci\'on de repartici\'on,
%
\[
F_X(x) = \sum_{x_j \le x} p_X(x_j)
\]
%
De  esta forma,  se justifica  la  denominaci\'on {\it  cumulativa} para  $F_X$.
Tambi\'en, se puede ver inmediato de que $F_X$ es una funci\'on discontinua, con
saltos finitos (en  $x_j$, salto de altura $p_X(x_j)$).  Eso es ilustrado figura
Fig.~\ref{fig:MP:ProbaDiscreta}-(b).

\begin{figure}[h!]
\begin{center} \input{TIKZ_MP/DistribucionReparticionDiscreta} \end{center}
%
\leyenda{Ilustraci\'on de una distribuci\'on  de probabilidad discreta (a), y la
  funci\'on de repartici\'on asociada (b), con $\X  = \big\{ \, 1 \, , \, \sqrt3
  \, ,  \, \sqrt5  \, , \,  \sqrt7 \,  , \, \sqrt{11}  \, \big\}$ \  y \  $p_X =
  \protect\begin{bmatrix}  \frac18  & \frac14  &  \frac16  &  \frac18 &  \frac13
    \protect\end{bmatrix}^t$.}
\label{fig:MP:ProbaDiscreta}
\end{figure}

Un caso especial se tiene cuando un  valor $x_k$ es cierto o seguro, y no ocurre
ninguno de los  otros valores $x_j \  (j \ne k)$. La forma  de la distribuci\'on
es: \ $p_X(x) = \un_{\{ x_k \}}(x)$ \ o el vector de probabilidad de escribir\'a
\  $p_X  =  \un_k$  donde  $\un_k$  denotar\'a es  el  vector  (posiblemente  de
dimensi\'on  infinita) de componentes  $k$-esima $\delta_{jk}  = \un_{\{k\}}(j)$
s\'imbolo \emph{delta de Kronecker},
%
\[
\delta_{jk} = 
\left\{
\begin{array}{clr}
1 & \mbox{si} \: j = k \\
0 & \mbox{si no}
\end{array} \right.
\]
%
En este  caso, $P_X$ es  conocida como  {\it medida de  Dirac} centrada en  $x =
x_k$, a veces  denotada $\delta_{x_k}(x) = \delta(x-x_k)$. Vamos  a volver m\'as
adelante sobre esta medida particular.

Otra   situaci\'on  particular   es  la   de  {\it   equiprobabilidad}   o  {\it
  distribuci\'on uniforme}  cuando $|\X|  = \alpha <  +\infty$.  La forma  de la
distribuci\'on es: \ $p_X(x_j) = \frac1\alpha \quad  \forall \, j = 1 , \ldots ,
\alpha$,    \ie   $p_X    =    \begin{bmatrix}   \frac1\alpha    &   \cdots    &
  \frac1\alpha \end{bmatrix}^t$ \  o, en termino de medida,  $P_X = \frac1\alpha
\sum_{j=1}^\alpha  \delta_{x_j}$.   La funci\'on  de  repartici\'on resulta  una
funci\'on escalonada, con saltos de  altura \ $\frac1\alpha$ en cada $x_j, \quad
1 \le j \le \alpha$.

De manera general, la medida de probabilidad de una variable discreta se escribe
como combinaci\'on convexa de medida de Dirac,
%
\[
P_X = \sum_j p_j \delta_{x_j} \quad p_j = P(X=x_j) \ge 0, \: \sum_j p_j = 1, 
\]

\

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\SZ{Reordenamiento y relaci\'on de mayorizaci\'on  : a ver como trasladar lo que
  ya estaba en en cap.  2 mas los ejemplos, pagina~\pageref{def:SZ:Mayorizacion}
  (cf  pagina~\pageref{prop:SZ:permutacion}).  Todo  tal  cual por  ahora,  pero
  ser\'ia la parte azul a cambiar.}

\aver{
Para comparar dos  distribuciones es \'util reordenar el  vector de probabilidad
permutando  sus  elementos  hasta  listarlos  de forma  descendente.   Se  anota
$p^\downarrow$, de  modo que \  $p^\downarrow_1 \geq p^\downarrow_2  \geq \ldots
\geq  p^\downarrow_N$.   En  el  ejemplo   del  caso  con  certeza  se  tiene  \
$p^\downarrow =  \begin{pmatrix} 1 & 0  & \cdots &  0 \end{pmatrix}^t$, mientras
que la distribuci\'on uniforme no var\'ia.

Se  define  \emph{mayorizaci\'on} del  siguiente  modo,  para distribuciones  de
dimensi\'on  $N$ (con  sus elementos  acomodados  en forma  decreciente): \  una
distribuci\'on $p$  es mayorizada por otra $q$,  y se denota $p\prec  q$, si las
primeras $N-1$  sumas parciales de $p^\downarrow$ y  $q^\downarrow$ satisfacen \
$\sum_{i=1}^n  p^\downarrow_i   \leq  \sum_{i=1}^n  q^\downarrow_i$   para  todo
$n=1,\ldots,N-1$, con \ $\sum_{i=1}^N p_i = 1 = \sum_{i=1}^N q_i$.

Por    ejemplo,   $\begin{pmatrix}    \frac12    &   \frac14    &   \frac18    &
  \frac18 \end{pmatrix}^t  \prec \begin{pmatrix} \frac12  & \frac14 &  \frac14 &
  0 \end{pmatrix}^t$.  Es posible  comparar por mayorizaci\'on distribuciones de
distinta  dimensionalidad, completando con  ceros el  vector de  probabilidad de
menor  dimensi\'on.  Es  importante  resaltar que  la  mayorizaci\'on provee  un
\emph{orden  parcial}  (no  total)  entre distribuciones,  existiendo  pares  de
distribuciones   tales  que   ninguna  mayoriza   a  la   otra.    Por  ejemplo,
$\begin{pmatrix} 0.50 &  0.40 & 0.10 \end{pmatrix}^t$ y  $\begin{pmatrix} 0.70 &
  0.15 & 0.15 \end{pmatrix}^t$ no se comparan por mayorizaci\'on.

Es  interesante  notar  que  la   siguiente  propiedad  es  v\'alida  para  toda
distribuci\'on $p$ de tama\~no~$N$:
%
$$
\begin{pmatrix} \frac1N & \frac1N & \cdots & \frac1N \end{pmatrix}^t \ \prec \ p
\ \prec \ \begin{pmatrix} 1 & 0 & \cdots & 0 \end{pmatrix}^t.
$$
%
En este  sentido, los  casos particulares de  equiprobabilidad y de  certeza, se
dice  que  son  distribuciones  extremas.  Notamos que  uno  implica  ignorancia
m\'axima  en el  resultado de  la variable  mientras que  el otro  corresponde a
conocimiento completo.
%% graficamente 
%
\begin{figure}[h!] %%ojo numeracion de figs !
%\centerline{\includegraphics[width=3cm]{majorizationplot.pdf}} %%rehacer
%
\leyenda{Orden parcial por mayorizaci\'on}
\label{fig:majorizationplot}
\end{figure}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



% ================================= Continua

\subseccion{Variable aleatoria continua}
\label{sec:MP:VAContinua}

En  varios contextos,  puede  tomar valores  en  un conjunto  no numerable,  por
ejemplo cualesquiera de los n\'umeros en un dado intervalo de la recta real.  No
son variables  discretas m\'as. En las  variables que no son  discretas, el caso
particular de inter\'es es el de variables continuas~\cite{AthLah06, HogMck13}:
%
\begin{definicion}[Variable aleatoria continua]
  Una variable  aleatoria \  $X$ \ es  dicha {\it  continua} si su  funci\'on de
  repartici\'on  $F_X$ es  continua sobre  $\Rset$.
\end{definicion}

Cuando  se  puede,  es  conveniente  asociar  una  {\it  funci\'on  densidad  de
  probabilidad} (com\'unmente  anotada por  su sigla en  ingl\'es: pdf  por {\it
  probability   density   function}).   Por   eso,   nos   apoyamos   sobre   la
definici\'on~\ref{def:MP:DensidadMedida}  aplicada a  la medida  de probabilidad
$P_X$:
%
\begin{definicion}[Variable aleatoria admitiendo una densidad de probabilidad]
  Sea $X$ variable  aleatoria continua y \ $P_X$ su  medida de probabilidad. Por
  definici\'on, se dice que $X$  admite una densidad de probabilidad con respeto
  a  una medida  $\mu$  sobre $\Rset$  si  $P_X$ es  absolutamente continua  con
  respeto  a  $\mu$ seg\'un  la  definici\'on~\ref{def:MP:DensidadMedida} (y  la
  reciproca  evocaca al  seguir).\newline  En general,  nos  enfocamos sobre  la
  medida (dicha de referencia) $\mu  = \mu_L$ de Lebesgue y denotando $d\mu_L(x)
  \equiv dx$, la definici\'on se reduce a: Si existe una funci\'on no negativa \
  $p_X$ \ medible sobre $\Rset$ tal que
  %
  \[
  \forall \, B \in \B(\Rset), \quad P_X(B) = \int_B p_X(x) \, dx
  \]
  %
  entonces $X$  es dicha {\it  admitiendo una densidad}  y \ $p_X$ \  es llamada
  {\it densidad de probabilidad} de  $X$ (subentendido ``con respeto a la medida
  de Lebesgue'').  Notando de que $P_X(B) = P_X(B \cap \X)$, el soporte de $p_X$
  es necesariamente $\X = X(\Omega)$ (\ie $p_X(\widebar{\X}) = 0$ \ y \ $p_X(\X)
  \ne 0$), y
  %
  \[
  \forall \, B \in \B(\Rset), \quad P_X(B) = \int_{B \cap \X} p_X(x) \, dx
  \]
  %
  Tratando de la funci\'on de repartici\'on \ $F_X$, tenemos entonces
  %
  \[
  F_X(x) = \int_{-\infty}^x p_X(u) \, du
  \]
  %
  (queda valid con cualquier medida $\mu$, densidad con respeto a esta medida de
  referencia,  e integraci\'on  sobre $(-\infty;  x]$ con  la  ``diferencial'' \
  $d\mu(x)$).  Dicho  de otra manera, si  $F_X$ es (continua  y) derivable sobre
  $\Rset$, por lo menos por partes, $X$ admite una densidad de probabilidad (con
  respeto a  la medida de Lebesgue)  y~\footnote{Recuendense que, rigurosamente,
    la igualdad debe ser entendido ``casi siempre''.}
  %
  \[
  p_X(x) = \frac{d F_X(x)}{dx}
  \]
  %
  Por abuso  de terminologia,  en lo que  sigue llamaremos $p_X$  tambi\'en {\it
    distribuci\'on de  probabilidad}, a pesar de  que no tiene  el mismo sentido
  que la masa de probabilidad del  caso discreto y denotaremos $|\X|$ el volumen
  (o medida de Lebesgue) de $\X$, posiblemente infinito.
\end{definicion}
%
La  escritura  integral de  $F_X$  justifica  de  nuevo la  denominaci\'on  {\it
  cumulativa} para  $F_X$. Adem\'as, se puede  ver por ejemplo que  en este caso
$\displaystyle P(a < X \le b) = \int_a^b p_X(x) \, dx = F_X(b) - F_X(a)$ \ y que
claramente
%
\[
\forall x \in \Rset, \quad P_X(\{x\}) = P(X = x) = 0
\]
%
$\{ x \}$ es dicho de medida $P_X$ nula (es el caso de todos conjuntos numerable
de $\Rset$).

Fijense de  que si  $0 \le  F_X \le  1$, \ $p_X$  puede ser  mayor que  uno. Por
ejemplo, para \ $F_X(x) = 2 \, x  \, \un_{\left[ 0 \, ; \, \frac12 \right)}(x) +
\un_{\left[ \frac12 \,  ; \, +\infty \right)}(x)$, que  define correctamente una
funci\'on  de  repartici\'on,  \  $p_X(x)  =  2  \un_{\left[  \frac12  \,  ;  \,
    +\infty\right)}(x)$. No es  contradictorio en el sentido de  que $p_X$ no es
una probabilidad, sino  que $p_X(x) \, dx$ puede ser  visto como la probabilidad
de hallar a la variable con  valores en el ``intervalo infinitesimal entre $x$ y
$x+dx$''.  Al final, la condici\'on de normalizaci\'on se escribe
%
\[
\int_\X p_X(x) \, dx = \int_\Rset p_X(x) \, dx = 1. 
\] 
%

En la figura Fig.~\ref{fig:MP:ProbaContinua}-(a) se muestra una representaci\'on
gr\'afica de una  funci\'on densidad de probabilidad para  una variable continua
admitiendo una  densidad, y en  Fig.~\ref{fig:MP:ProbaContinua}-(b) la funci\'on
cumulativa correspondiente.
%
\begin{figure}[h!]
\begin{center} \input{TIKZ_MP/DistribucionReparticionContinua} \end{center}
%
\leyenda{Ilustraci\'on de una distribuci\'on  de probabilidad continua (a), y la
  funci\'on de repartici\'on asociada (b), con \ $\X  = [0 \, ; \, 1) \cup [2 \,
  ;  \,  3)$  \  y \  $p_X(x)  =  \frac12  \un_{[0  \,  ; \,  1)}(x)  +  \frac{3
    \sqrt{x-2}}{4} \un_{[2  \, ; \,  3)}(x)$, \ \ie  \ $F_X(x) =  \frac{x}{2} \,
  \un_{[0   \,   ;  \,   1)}(x)   +   \frac12  \un_{[1   \,   ;   \,  2)}(x)   +
  \frac{(x-2)^{\frac32}}{2}  \un_{[2  \,   ;  \,  3)}(x)  +  \un_{[3   \,  ;  \,
    +\infty)}(x)$.  }
\label{fig:MP:ProbaContinua}
\end{figure}

Fijense de que una variable aleatoria puede ser ni continua, ni discreta:
%
\begin{itemize}
\item Sean $U$  \ y \ $V$ \ variables continuas,  independientes, de densidad de
  probabilidad $p_U  = p_V = \un_{[0 \,  ; \, 1)}$ ($U$  \ y \ $V$  \ son dichas
  uniformes sobre $[0  \, ; \, 1)$)  \ y sea \ $X  = V \un_{U <  \frac12}$, \ es
  decir \ $X(\omega)  = V(\omega)$ \ si \  $U(\omega) < \frac12$ \ y \  $0$ \ si
  no.  Entonces de la formula de  probabilidades totales, \ $F_X(x) = P(X \le x)
  = P\left(  (X \le  x) \left| \left(  U <  \frac12 \right) \right.   \right) \,
  P\left( U  < \frac12 \right)  \, + \,  P\left( (X \le  x) \left| \left(  U \ge
        \frac12 \right)  \right.  \right) \, P\left(  U \ge \frac12  \right) $ \
  \ie \ $F_X(x)  = \frac12 P\left( (V  \le x) \left| \left( U  < \frac12 \right)
    \right.   \right) \, +  \, P\left(  (0 \le  x) \left|  \left( U  \ge \frac12
      \right)\right. \right)$. \ Ahora, de la  independencia de \ $U$ \ y \ $V$,
  \  tenemos   \  $F_X(x)  =   \frac12  F_V(x)  +  \frac12   \un_{\Rset_+}(x)  =
  \frac{x+1}{2} \un_{[0  \, ; \,  1)}(x) + \un_{[1  \, ; \,  +\infty)}(x)$. Esta
  funci\'on       de       repartici\'on       es      representada       figura
  Fig.~\ref{fig:MP:ProbaMixta}: es ni discreta,  ni continua.  Entonces, a pesar
  de que $\X = [0 \, ; \, 1)$  \ sea un intervalo, $X$ no es continua (y tampoco
  no puede ser discreta).
  %
  \begin{figure}[h!]
  \begin{center} \input{TIKZ_MP/ReparticionMixta} \end{center}
  %
  \leyenda{Funci\'on  de repartici\'on  $F_X(x) =  \frac{x}{2} \un_{[0  \,  ; \,
      1)}(x) + \un_{\Rset_+}(x)$ asociada a \ $X  = V \un_{U < \frac12}$ \ con \
    $U$ \ y \ $V$ \ variables continuas uniformes sobre $\X = [0 \, ; \, 1)$. No
    es tipo escalon, as\'i que $X$ no es  discreta. A pesar de que $\X = [0 \, ;
    \, 1)$ \ sea un intervalo, de la presencia del salto en $x = 0$, tampoco $X$
    no es continua.}
  \label{fig:MP:ProbaMixta}
  \end{figure}
%
\item Sea  $U$ \ variable  continua uniforme sobre $[0  \, ; \,  1)$ \ y \  $X =
  \un_{U \not\in \Qset}$. Claramente  $X$ no es continua, pero $\X =  [0 \, ; \,
  1)   \backslash    \Qset$   \   siendo   no   numerable,    $X$   tampoco   es
  discreta~\footnote{\SZ{$X = 1$ casi siempre\ldots quizas m\'as adelante}}.
\end{itemize}


Recordamonos de  que cualquier  medida de probabilidad  (caso continuo o  no) se
escribe tambi\'en con una integral \ $\displaystyle P_X(B) = \int_B dP_X(x)$ \ y
que en el caso discreto cierto \ $X = x_k$, \ la medida de probabilidad $P_X$ es
la medida de  Dirac. A veces, por  abuso de escritura \ $dP_X(x)$  es denotado \
$\delta_{x_k}(x) \,  dx$ \ o \ $\delta(x-x_k)  \, dx$ \ donde  ahora $\delta$ es
llamada {\it distribuci\'on (delta) de Dirac}.  Se puede ver este Dirac como una
densidad de probabilidad  $p_X(x)$ pero no es una  funci\'on ``ordinaria'' dando
de que  $P_X$ no es  diferenciable con  respeto a la  medida de Lebesgue.  Se la
llama    {\it    funci\'on    generalizada}    o    {\it    distribuci\'on    de
  Schwartz}~\footnote{La teor\'ia de la distribuciones vali\'o a Laurent Schwarz
  la medalla Field  en 1950.  Entre otros en el trabajo  de Schwartz, se prob\'o
  que el Dirac, visto como distribuci\'on de Schwartz, o funci\'on generalizada,
  tiene   una  ``representaci\'on  integral''   \  $\displaystyle   \delta(x)  =
  \frac{1}{2\pi}  \int_{-\infty}^{\infty}   e^{\imath  t   x}  dt$  \   o  m\'as
  rigurosamente transformada  de Fourier de $x  \mapsto 1$ en el  sentido de las
  funciones generalizadas o distribuciones.   Eso muestra claramente su caracter
  no  ordinario (la integral  siendo divergente  en el  sentido usual).   Eso va
  m\'as  all\'a  de la  meta  del  cap\'itulo y  el  lector  se podr\'a  referir
  a~\cite{Sch66, GelShi64,  GelShi68} por  ejemplo.}.  En particular,  $F_X(x) =
\un_{\Rset_+}(x-x_k)$ y en el sentido de las distribuciones, $\frac{d F_X}{dx} =
\delta_{x_k}$.   Adem\'as, se usan  en general  las propiedades,  para cualquier
function \ $f$ \ y real \ $x_0$,
%
\[
f(x) \delta(x-x_0) = f(x_0) \delta(x-x_0) \qquad \mbox{y} \qquad \int_\Rset f(x)
\delta(x-x_0) \, dx = f(x_0)
\]
%
pero hay que entender la integraci\'on a trav\'es de la medida Dirac (insistamos
en   el   hecho   de  que   esta   notaci\'on   es   un  abuso   de   escritura,
ej.~\cite{GelShi64}).  Usando las distribuciones  de Dirac, se puede unificar el
tratamiento de las  variables aleatorias discretas con las  continuas en termino
de densidad: si  una variable aleatoria discreta toma los valores  \ $x_j$ \ con
probabilidades \ $p_j  = P(X = x_j)$ \  respectivamente, entonces formalmente se
puede describir mediante una variable aleatoria continua \ $X$ \ con ``funci\'on
densidad de probabilidad'' \ $p_X(x) = \sum_j p_j \, \delta(x-x_j)$.


% ================================= Vector discreto

\subseccion{Vector aleatorio discreto}
\label{sec:MP:VecDiscreto}

Un ejemplo de vector aleatorio discreto puede verse a trav\'es de un conjunto de
dados (que podr\'ian  ser dependientes si son ligados por  un hilo por ejemplo).

\begin{definicion}[Vector aleatorio discreto]
  Un  vector aleatorio $d$-dimensional  \ $X  = \begin{bmatrix}  X_1 &  \cdots &
    X_d \end{bmatrix}^t$ \ y \  $\displaystyle \X = X(\Omega) = \optimes_{i=1}^d
  \X_i$ \ donde \  $\X_i = X_i(\Omega)$. \ $X$ \ es  dicho {\it discreto} cuando
  $\X \subseteq \Nset^d$, \ es discreto, finito o infinito numerable.  En lo que
  sigue,  denotaremos tambi\'en  por $|\X|$  el cardinal  de  $\X$, posiblemente
  infinito.
\end{definicion}

Obviamente, la  medida de probabilidad  en los $\displaystyle  x = (x_1 \,  , \,
\ldots \, , \, x_d)  \in \optimes_{i=1}^d \X_i$ \ caracterisa completamente este
vector aleatorio:
%
\begin{definicion}[Funci\'on de masa de probabilidad conjunta]
  Por  definici\'on,  la  funci\'on  de  masa de  probabilidad  de  $X$,  vector
  aleatorio discreto tomando  sus valores sobre $\X =  \X_1 \times \cdots \times
  \X_d$ \ es dada por
  %
  \[
  p_X(x) \equiv  P(X =  x) =  P\left( \bigcap_{i=1}^d \left(  X_i =  x_i \right)
  \right) \quad \forall \, x_i \in \X_i, \: 1 \le i \le d
  \]
  %
  Se la llama  tambi\'en {\it funci\'on de masa de  probabilidad conjunta de los
    $X_i$}, o, por  abuso de denominaci\'on, la llamaremos  todav\'ia $p_X$ {\it
    distribuci\'on  de probabilidad  (conjunta)}.  En  el caso  multivariado, la
  notaci\'on vectorial  es m\'as  delicada a usar:  $p_X$ ser\'ia  un ``tensor''
  $d$-dimensional (una matriz para $d = 2$,\ldots).  Pero queda posible usar una
  notaci\'on vectorial,  recordandose de que $\Nset^d$ puede  ser en biyecci\'on
  con $\Nset$ y  una biyecci\'on elegida, usarla para  etiquetar los componentes
  de  $p_X$  puesto  en  vector.   En  el  caso finito  \  $\X_i  =  \{  x_{j_i}
  \}_{j=1}^{\alpha_i}$  \  con \  $\alpha_i  = |\X_i|  <  +\infty$,  \ se  puede
  organizar  los  componentes tales  que  $p_X(x_{j_1}\, ,  \,  \ldots  \, ,  \,
  x_{j_d})$  sea   la  $\displaystyle  j   =  \sum_{i=1}^{d-1}  (j_i  -   1)  \,
  \prod_{k=i+1}^d \alpha_k \, + \, j_d$-esima componente del vector $p_X$.
%   \  con  \   $\displaystyle  \prod_{k=0}^1  \equiv  1$   \  por
%  convenci\'on.
\end{definicion}

Como en  el caso escalar, la  funci\'on de repartici\'on de  un vector aleatorio
discreto $d$-dimensional es echo de hyperplanos $d$-dimensionales constantes.
% , \ie  $F_X$ es constante sobre  $[x_{(j-1)_1} \, , \,  x_{j_1}) \times \cdots
% \times [x_{(j-1)_d} \, , \, x_{j_d})$
Adem\'as, las  componentes son mutualmente  independientes si y solamente  si la
funci\'on de  r\'epartici\'on se factoriza,  o equivalentemente la  funci\'on de
masa se factoriza, \ie
%
\[
X_i  \:  \mbox{mutualmente independientes}  \quad  \Leftrightarrow  \quad p_X  =
p_{X_1} \ldots  p_{X_d}
\]
%
En notaciones tensoriales, $p_X =  p_{X_1} \otimes \cdots \otimes p_{X_d}$ donde
$\otimes$  denota  el  producto  tensorial  o  externo  entre  los  vectores  de
probabilidades~\footnote{``Tensor''      $d$-dimensional      de     componentes
  $(j_1,\ldots,j_d)$  el  producto $\prod_i  p_{X_i}  (x_{j_i})$.}.  Cuando  los
$\alpha_i$ son finito y la  notaci\'on vectorial de la definici\'on es adoptada,
esta  expresi\'on  queda  valide  donde  $\otimes$  representa  el  producto  de
Kronecker~\footnote{Para   \    $p   =   \begin{bmatrix}   p_1    &   \cdots   &
    p_n  \end{bmatrix}^t$   \  y  \  $q   =  \begin{bmatrix}  q_1   &  \cdots  &
    q_m \end{bmatrix}^t$ \ el producto de  Kronecker es dado por \ $p \otimes q$
  \ vector de tama\~no $n m$ de componente \ $(j-1) m + k$-esima \ el producto \
  $p_j  q_k, \quad 1  \le j  \le n,  \: 1  \le k  \le m$.   Fijense de  que este
  producto es asociativo pero no es comutativo.\label{foot:MP:Kronecker}}.

Al  final, de la  formula de  calculo de  funci\'on de  repartici\'on marginales
visto  pagina~\pageref{pagina:MP:MarginalesF},   para  un  subconjunto   $I_k  =
(i_1,\ldots,i_k)$ de  $1 \le k  \le d$ elementos  de $\{ 1  , \ldots ,  d \}^k$,
$X_{I_k}  =  \begin{bmatrix}  X_{i_1}  &  \cdots  &  X_{i_k}\end{bmatrix}^t$  la
probabilidad marginal o distribuci\'on marginale de $X_{I_k}$ es dada por
%
\[
p_{X_{I_k}}(x_{I_k}) = \sum_{\forall i \not\in I_k, x_i \in \X_i} p_X(x)
\]



% ================================= Vector continuo

\subseccion{Vector aleatorio continuo}
\label{sec:MP:VecContinuo}

Como para  el caso  de una  variable, se puede  considerar cualquiera  medida de
referencia  $\mu$  sobre  $\Rset^d$   para  definir  una  noci\'on  de  densidad
($d$-variada),  pero  en general  nos  enfocamos  en el  caso  de  la medida  de
Lebesgue.

\begin{definicion}[Vector aleatorio continuo y densidad de probabilidad multivariada]
  Un  vector aleatorio  \  $X$ \  es dicho  {\it  continuo} si  su funci\'on  de
  repartici\'on  $F_X$ es  continua sobre  $\Rset^d$.  Como  en el  caso escalar
  tambi\'en,   por  definici\'on~\ref{def:MP:DensidadMedida}  (y   la  reciproca
  evocaca al  seguir), se dice que  $X$ admite una densidad  de probabilidad con
  respeto a una medida $\mu$  sobre $\Rset^d$ si $P_X$ es absolutamente continua
  con  respeto a  $\mu$.  De  nuevo,  nos enfocamos  sobre la  medida (dicha  de
  referencia) $\mu  = \mu_L$ de  Lebesgue as\'i que  si existe una  funci\'on no
  negativa y medible \ $p_X: \Rset^d \mapsto \Rset$ \ tal que
  %
  \[
  \forall \,  B \in \B(\Rset^d),  \quad P_X(B) =  \int_B p_X(x) \, dx  = \int_{B
    \cap \X} p_X(x) \, dx
  \]
  %
  con $\X  = X(\Omega)$ soporte  de \ $p_X$  \ y \  $d\mu_L(x) \equiv dx  = dx_1
  \cdots dx_d$, entonces  $X$ es dicha {\it admitiendo una  densidad} y $p_X$ es
  llamada {\it densidad de probabilidad} de \ $X$ (`subentendido ``con respeto a
  la medida de Lebesgue''), o  tambi\'en {\it densidad de probabilidad conjunta}
  de los \ $X_i$. En particular,
  %
  \[
  F_X(x) =  \int_{\optimes_{i=1}^d (-\infty \, ;  \, x_i]} p_X(u) \, du
  \]
  %
  o, equivalentemente, para $F_X$ es (continua y) derivable sobre $\Rset^d$ (con
  respeto a la medida de Lebesgue), por lo menos por partes,
  %
  \[
  p_X(x) = \frac{\partial^d F_X(x)}{\partial x_1 \cdots \partial x_d}
  \]
  %
  Usaremos  todav\'ia la terminolog\'ia  (por abuso)  de {\it  distribuci\'on de
    probabilidad} y  denotaremos todav\'ia  \ $|\X|$ \  el volumen (o  medida de
  Lebesgue) de \ $\X$, posiblemente infinito.
\end{definicion}

Como en el caso  escalar, $p_X \ge 0$ \ no es necesario  menor que 1 y satisface
la condici\'on de normalizaci\'on
%
\[
\int_\X p_X(x) \, dx = \int_{\Rset^d} p_X(x) \ dx  = 1
\]

Mencionamos de que las $d$  variables aleatorias $X_1, \ldots, X_d$, componentes
de un vector aleatorio $X$ son  independientes si y solamente si se factoriza la
funci\'on de repartici\'on, lo que da derivando esta,
%
\[
X_i \:  \mbox{ mutualmente independientes} \quad \Leftrightarrow  \quad p_X(x) =
p_{X_1}(x_1) \ldots p_{X_d}(x_d)
\]


Terminamos esta secci\'on mencionando que, de la formula de calculo de funci\'on
de  repartici\'on marginales visto  pagina~\pageref{pagina:MP:MarginalesF}, para
un subconjunto $I_k = (i_1,\ldots,i_k)$ de $1  \le k \le d$ elementos de $\{ 1 ,
\ldots   ,  d   \}^k$,   $X_{I_k}   =  \begin{bmatrix}   X_{i_1}   &  \cdots   &
  X_{i_k}\end{bmatrix}^t$  la   {\it  densidad  de   probabilidad  marginal}  de
$X_{I_k}$ es dada por
%
\[
p_{X_{I_k}}(x_{I_k})  = \int_{\times_{i  \not\in  I_k} \X_i}  p_X(x) \,  \prod_{i
    \not\in I_k}  dx_i =  \int_{\Rset^{d-k}} p_X(x) \,  \prod_{i \not\in
      I_k} dx_i
\]
%
En particular, la funci\'on densidad  de probabilidad marginal que caracteriza a
la variable aleatoria  $X_i$ es la ley que se obtiene  integrando la densidad de
probabilidad conjunta sobre todas las variables excepto la $i$-\'esima.

\

\SZ{Reordenamiento y relaci\'on de mayorizaci\'on  : a ver como trasladar lo que
  ya estaba  en en cap.  2 mas los  ejemplos, paginas~\pageref{def:SZ:rearreglo}
  y~\pageref{def:SZ:MayorizacionC}.}


% ================================= Transformacion

\subseccion{Transformaci\'on de variables y vectores aleatorios}
\label{sec:MP:Transformacion}

En  esta  secci\'on nos  interesamos  al  effect de  una  variable  o un  vector
aleatorio. Por  ejemplo, en un juego con  dos dados, nos podemos  interesar a la
ley de la suma que dar\'ia el n\'umero de casilla de que debemos adelantar en un
juego de la oca.
%
\begin{teorema}[Transformaci\'on medible de un vector aleatorio]
  Sea  \  $X:  (\Omega,\A)  \mapsto  (\Rset^d ,  \B(\Rset^d))$  \  una  variable
  aleatoria,   y  \   $g:  (\Rset^d   ,  \B(\Rset^d))   \mapsto   (\Rset^{d'}  ,
  \B(\Rset^{d'}))$ \  una funci\'on  medible. Entonces,  \ $Y =  g(X)$ \  es una
  variable aleatoria  \ $(\Omega,\A)  \mapsto (\Rset^{d'} ,  \B(\Rset^{d'}))$. \
  Adem\'as, la medida imagen \ $P_Y$ \ es vinculada \ a \ $P_X$ \ por
  %
  \[
  \forall \, B \in \B(\Rset^{d'}), \quad P_Y(B) = P_X(g^{-1}(B))
  \]
\end{teorema}
%
\begin{proof}
  Este resultado es obvio. $g$ siendo medible, para todo $B \in \B(\Rset^{d'})$,
  por definici\'on $g^{-1}(B) \in \B(\Rset^d)$.  Adem\'as, si $P_X$ es la medida
  (de  probabilidad) asociado  al  espacio de  salida  de $g$,  el resultado  es
  consecuencia del teorema~\ref{th:MP:MedidaImagen}.
\end{proof}
%
\noindent (Ver ej.~\cite{JacPro03, AthLah06, Bog07:v2, Coh13}).


Es sencillo  probar de que  cualquier combinaci\'on de funciones  medibles queda
medible, cualquier  producto (adecuado) de  functiones medible queda  medible, y
que si $\{ f_k \}_{k=1}^{d'}$ son $(\B(\Rset^d),\B(\Rset))$-medible, entonces $f
=          (f_1         ,          \ldots         ,          f_{d'})$         es
$(\B(\Rset^d),\B(\Rset^{d'}))$-medible~\cite{AthLah06}.

\SZ{No se  todav\'ia si  ser\'a \'util tratar  del caso  de limite de  series de
  funciones medibles (quizas, tratando de los momentos/integraci\'on).}


Mencionamos  de que si  $\X =  X(\Omega)$ es  discreto, entonces  $\Y =  g(\X) =
Y(\Omega)$ ser\'a discreto tambi\'en, y:
%
\begin{teorema}[Funci\'on de masa por transformaci\'on medible]
  Sean   $X$,   vector  aleatorio   $d$-dimensional   discreto,  $g:(\Rset^d   ,
  \B(\Rset^d)) \mapsto (\Rset^{d'} , \B(\Rset^{d'}))$ una funci\'on medible, e \
  $Y =  g(X)$ necesariamente discreto  $d'$-dimensional sobre $\Y =  g(\X)$.  La
  distribuci\'on de $Y$ es relacionada a la de $X$ por la relaci\'on
  %
  \[
  \forall \, y \in \Y, \quad p_Y(y) = \sum_{x \in g^{-1}(y)} p_X(x)
  \]
\end{teorema}
%
\begin{proof}
El resultado es inmediato.
\end{proof}
%
\noindent En particular,  si $g$ es inyectiva (necesariamente  biyectiva de $\X$
en $\Y$),  el vector  de probabilidad queda  invariante, $p_Y =  p_X$; solamente
cambian los estados.

Es  importante mencionar de  que con  $\Y$ discreto,  $\X$ no  es necesariamente
discreto~\cite{AthLah06}. Por ejemplo, $Y = \un_{X>0}$  es tal que $\Y \{ 0 \, ;
\, 1 \}$ a pesar de que $\X$ pueder no discreto.

Tratar de las variables aleatorias  continuas resuelta mas delicado. Vimos en el
ejemplo   precediente  de   que  el   caracter  continuo   puede   perderse  por
transformaci\'on. De la misma manera, en un ejemplo de la secci\'on precediente,
vimos  que  $Y =  X_1  \un_{X_2>0}$ con  $X_i$  independientes  uniformes es  ni
continua,  ni  discreta.  En  el  enfoque  de  variables  continuas,  una  clase
importante  de funciones  en la  cual  no vamos  a interesar  son las  funciones
continuas (y diferenciables):
%
\begin{lema}[Continuidad y caracter medible]
  Sea   $g:   \Rset^d   \mapsto   \Rset^{d'}$   continua.   Entonces,   $g$   es
  $(\B(\Rset^d),\B(\Rset^{d'}))$-medible.
\end{lema}
%
\begin{proof}
  Por continuidad,  la pre-imagen de  un abierto de  $\Rset^{d'}$ por $g$  es un
  abierto  de $\Rset^d$  y entonces  es en  $\B(\Rset^d)$. La  prueba  se cierra
  recordandose  de  la   definici\'on  de  $\B(\Rset^{d'})$,  $\sigma$-\'algebra
  generada por los abiertos de $\Rset^{d'}$.
\end{proof}

En lo  que sigue, nos interesamos  m\'as especialmente al caso  de funciones $g:
(\Rset^d ,  \B(\Rset^d)) \mapsto (\Rset^d ,  \B(\Rset^d))$.  De hecho,  si $d' <
d$,   es    sencillo   llegar   al   caso    considerado   a\~nandiendo   $d-d'$
transformaciones. Por ejemplo, con $d = 2$  si nos interesamos a $X_1 + X_2$, se
puede considerar $\begin{bmatrix} X_1 + X_2 & X_2 - X_1\end{bmatrix}^t$ y llegar
a la variable de  inter\'es por calculo de marginal. Si $d'  > d$ la situaci\'on
es  m\'as  delicada,  $g(Y)$  viviendo  sobre una  variedad  $d$-dimensional  de
$\Rset^{d'}$.

En  el caso  de vectores  aleatorios continuos  $X$ admitiendo  una  densidad de
probabilidad,  una pregunta  natural  es entonces  de  saber si  se conserva  la
continuidad y la existencia de una densidad, as\'i que su forma. La respuesta es
dada por el teorema siguiente~\cite{Bre88, JacPro03, AthLah06, Coh13, HogMck13}:
%
\begin{teorema}[Densidad de probabilidad por transformaci\'on continua inyectiva diferenciable]
  Sean $X$, vector aleatorio  $d$-dimensional continuo y admitiendo una densidad
  de probabilidad  $p_X$, \ $g:\Rset^d  \mapsto \Rset^d$ una  funci\'on continua
  inyectiva y diferenciable tal que
  %  ~\footnote{\modif{De  hecho,  se   puede  extender  el  resultado  para  un
  %      determinente del  Jacobiano cancelandose  en  un conjunto  de punto  de
  %     medida  de Lebesgue nula y en  los $y$ donde se  cancela el determinente
  %       del  Jacobiano,  la   densidad  va   a  ser   divergente  (divergencia
  %     integrable).}}
 $\left| \Jac_g \right| > 0$,
  %
 donde $\Jac_g$ denota la  matriz de componentes \ $\frac{\partial g_i}{\partial
   x_j}$, \ matriz Jacobiana de  la transformaci\'on \ $g \equiv \begin{bmatrix}
   g_1(x_1 , \ldots , x_d) & \cdots & g_d(x_1 , \ldots , x_d) \end{bmatrix}^t$ \
 y \ $|\cdot|$ representa el valor absoluto del determinante de la matriz. Sea \
 $Y = g(X)$.   Entonces $Y$ es continua admitiendo  una densidad de probabilidad
 $p_Y$ de soporte $\Y = g(\X) = Y(\Omega)$ tal que
  %
  \[
  \forall \,  y \in  \Y, \quad p_Y(y)  = p_X(g^{-1}(y))  \left| \Jac_{g^{-1}}(y)
  \right|
  \]
\end{teorema}
%
\begin{proof}
Por definici\'on, $X$ admitiendo una densidad y $g$ siendo medible,
%
\[
\forall \, B  \in \B(\Rset^d), \quad P_Y(B) =  P_X(g^{-1}(B)) = \int_{g^{-1}(B) \cap \X}
p_X(x) \, dx
\]
%
Por cambio de variable $x =  g^{-1}(y)$ ($g$ siendo inyectiva, el antecedante es
\'unico por definic\'on) y notando de que $g\left( g^{-1}(B) \cap \X \right) = B
\cap \Y$,
%
\[
\forall \, B \in \B(\Rset^d), \quad  P_Y(B) = \int_{B \cap \Y} p_X(g^{-1}(y)) \,
\left| \Jac_{g^{-1}}(y) \right| \, dy
\]
%
lo que cierra la prueba.
\end{proof}

El caso escalar puede ser visto como caso particular, dando:
%
\begin{corolario}
  Sean  $X$,   variable  aleatoria  continua   y  admitiendo  una   densidad  de
  probabilidad $p_X$, $g:\Rset \mapsto  \Rset$ una funci\'on continua, inyectiva
  y  diferenciable e  \ $Y  = g(X)$.   Entonces $Y$  es continua  admitiendo una
  densidad de probabilidad $p_Y$ tal que
  %
  \[
  \forall  \,   y  \in  \Y,   \quad  p_Y(y)  =  p_X(g^{-1}(y))   \left|  \frac{d
      g^{-1}(y)}{dy} \right|
  \]
\end{corolario}
%
\noindent  De hecho,  se puede  ver estos  resultados esquematicamente  como una
``conservaci\'on'' de  probabilidad, $p_X(x)  dx = p_Y(y)  dy$, el  volumen $dy$
siendo relacionado al $dx$ a traves de la Jacobiana.

Una forma  alternativa de derivar  este resultado es  partir de la  funci\'on de
repartici\'on, notando  de que $g$  es necesariamente monotona~\footnote{Fijense
  de que  $P(X \ge x) =  1 - P(X <  x) = 1  - P(X \le x)  + P(X = x)$,  pero $X$
  siendo continua, $ P(X  = x) = 0$.}: si $y \not\in  \Y$, necesariamente $p_Y =
0$ ($F_Y(y) = 1$ \ si \ $y > \sup \Y$ \ y \ $F_Y(y) = 0$ \ si \ $y < \inf \Y$) \
y para cualquier \ $y \in \Y$,
%
\[
F_Y(y) = P(Y \le y) = P(g(X) \le y) =
\left\{\begin{array}{lll}
P(X \le g^{-1}(y)) = F_X(g^{-1}(y)) & \mbox{si} & g \quad \mbox{es creciente}\\[2.5mm]
%
P(X \ge g^{-1}(y)) = 1 - F_X(g^{-1}(y)) & \mbox{si} & g \quad \mbox{es decreciente}
\end{array}\right.
\]
%
El  resultado  se  obtiene  calculando  las  derivadas  del  primer  y  \'ultimo
t\'erminos respecto de la variable transformada $y$.

Si $g$ no es inyectiva, $g^{-1}$  es multivaluada o multiforme. En este caso, se
puede todav\'ia  tratar el problema, particionando $\Rset^d$  en conjuntos donde
$g$ es inyectiva, dando
%
\begin{teorema}
  Sean $X$, vector aleatorio  $d$-dimensional continuo y admitiendo una densidad
  de  probabilidad   $p_X$,  $g:(\Rset^d  ,  \B(\Rset^d))   \mapsto  (\Rset^d  ,
  \B(\Rset^d))$  una  funci\'on continua  y  diferenciable.  Denotamos  $\left\{
    \X_{[k]} \right\}_{k=0}^m$ la partici\'on  de $\X$ tal que $\left| \Jac_g(y)
  \right| = 0$ sobre  $\X_{[0]}$ y para todos $k \ge 1$,  \ $g: \X_{[k]} \mapsto
  \Y$ \ sea inyectiva y tal que \ $\left| \Jac_g(y) \right| > 0$. \ Suponemos de
  que  $\X_{[0]}$ sea  de medida  de Lebesgue  nula, notamos  \ $g_k^{-1}$  \ la
  funci\'on inversa  de \ $g$  \ sobre \  $g(\X_{[k]})$ \ (rama $k$-esima  de la
  funci\'on multivaluada $g^{-1}$), \  $\Jac_{g_k^{-1}}$ \ su matriz Jacobiana y
  \ $I(y) = \{ k, \: y \in g(\X_{[k]}) \}$ \ los indices tales que \ $y$ \ tiene
  un      inverso     por      $g_k$.      Eso      es      ilustrado     figura
  Fig.~\ref{fig:MP:TransformacionVA}  para $d  = 1$.   Entonces $Y$  es continua
  admitiendo una densidad de probabilidad $p_Y$ tal que
  %
  \[
  \forall  \, y  \in \Y,  \quad p_Y(y)  = \sum_{k  \in  I(y)} p_X(g_k^{-1}(y))
  \left| \Jac_{g_k^{-1}}(y) \right|
  \]
  %
  En el caso escalar $d = 1$ eso se formula
  %
  \[
  \forall \, y \in \Y, \quad  p_Y(y) = \sum_{k \in I(y)} p_X(g_k^{-1}(y)) \left|
    \frac{d g_k^{-1}(y)}{dy} \right|
  \]
\end{teorema}
%
\begin{proof}
  Sufice escribir  \ $B  = \bigcup_{k =  0}^m \left(  B \cap g(\X_k)  \right)$ \
  uni\'on de borelianos disjuntos, notar  de que por consecuencia \ $g^{-1}(B) =
  \bigcup_{k =0}^m g^{-1}\left( B \cap  g(\X_k) \right)$ \ uni\'on de borelianos
  disjuntos \  y \  por linearidad escribir  la integraci\'on  sobre $g^{-1}(B)$
  como la  suma de  integrales sobre $g^{-1}\left(  B \cap g(\X_k)  \right)$. Se
  cierra la  prueba notando de  que \ $g^{-1}\left(  B \cap g(\X_0)  \right)$ es
  necesario  de medida de  Lebesgue nula,  siendo la  integral nula  y de  que \
  $g^{-1}\left( B \cap g(\X_k) \right) = g_k^{-1}\left( B \cap g(\X_k) \right)$.
\end{proof}
%
Por ejemplo, sea  $X$ definido sobre \  $\X = \Rset$ \ y  la transformaci\'on de
variables \ $Y =  X^2$.  Se tiene \ $y = g(x)  = x^2$, continua diferenciable de
derivada nula sobre \ $\X_{[0]} = \{ 0 \}$, de medida nula, cuyas inversas son \
$g_1^{-1}(y) = \sqrt{y}$  \ sobre $\X_{[1]} = \Rset_-^*$ \ y  \ $g_2^{-1}(y) = -
\sqrt{y}$ sobre $\X_{[2]} = \Rset_+^*$;  luego \ $p_Y(y) = \frac{p_X(\sqrt{y}) +
  p_X(-\sqrt{y})}{2 \sqrt{y}}$, \ sobre $\Y = \Rset_+^*$.

De nuevo, en el caso escalar, se puede salir de la funci\'on de repartici\'on
%
\[
F_Y(y) =  P(Y \le y) = P(  g(X) \le y )  = \sum_{k=1}^m P\left( X  \in \X_{[k]} \cap
  g_k^{-1}(-\infty \, ; \, y] \right)
\]
%
($\X_{[0]}$  siendo  de medida  nula,  sobre  este  dominio la  probabilidad  es
cero). Sea $\Y_{[k]} = g_k(\X_{[k]})$. Ahora, si $y \not\in I(y)$,
%
\[
P\left(   X   \in  \X_k   \cap   g_k^{-1}(-\infty  \,   ;   \,   y]  \right)   =
\left\{\begin{array}{lll}
%
P(X \in \X_{[k]}) & \mbox{si} & y > \sup \Y_{[k]}\\[2.5mm]
%
0 & \mbox{si} & y < \inf \Y_{[k]}\\[2.5mm]
\end{array}\right.
\]
%
dando una derivada nula. Si $y \in I(y)$,
%
\[
P\left(   X   \in  \X_k   \cap   g_k^{-1}(-\infty  \,   ;   \,   y]  \right)   =
\left\{\begin{array}{lll}
%
F_X(g_k^{-1}(y)) - F_X(\inf \Y_{[k]}) & \mbox{si} & g_k \quad \mbox{es creciente}\\[2.5mm]
%
F_X(\sup \Y_{[k]}) - F_X(g_k^{-1}(y))  & \mbox{si} & g_k \quad \mbox{es decreciente}
\end{array}\right.
\]
%
El  resultado  sigue  diferenciando  este  resultado. Eso  es  ilustrado  figura
Fig.~\ref{fig:MP:TransformacionVA}.

\begin{figure}[h!]
\begin{center} \input{TIKZ_MP/TransformacionVA} \end{center}
%
\leyenda{(a): Ilustraci\'on  de una transformaci\'on  $g$ no inyectiva,  tal que
  $\X_{[0]} = \{ x, \: g'(x) = 0 \}$, representado por las lineas punteadas ($x$
  correspondiente), es de medida de  Lebesgue nula.  Los $\X_{[k]}$ son descrito
  debajo de cada dominio.  La linea discontinua  da un nivel $y$ y los puntos en
  el eje $x$ representan $g_k^{-1}(y), \: k \in I(y)$; en el ejemplo, $I(y) = \{
  1  \,  ;  \,  2 \}$  \  y,  suponiendo  de  que  $\X  = \Rset$,  \  $F_Y(y)  =
  F_X(g_1^{-1}(y)) + 1-F_X(g_2^{-1}(y))$.}
\label{fig:MP:TransformacionVA}
\end{figure}

Una  tercera alternativa,  a pesar  que sea  delicado, es  de apoyarse  sobre la
teoria de las  distribuciones y expresar como \  $\displaystyle p_Y(y) = \int_\X
p_X(x) \,  \delta(y-g(x)) \, dx$,  donde se usa  la expansi\'on de  la funci\'on
delta  en  t\'erminos de  sus  ceros:  \  $\delta(y-g(x)\,)= \sum_{k  \in  I(y)}
\frac{1}{\left|      g_k'\left(      g_k^{-1}      (y)     \right)      \right|}
\delta(x-g_k^{-1}(y))$~\cite{ManWol95}.

Es  importante  notar  de  que  la  condici\'on $\X_{[0]}$  de  medida  nula  es
importante. El el caso contrario,  $Y$ no queda continua. Por ejemplo, considera
$X$ uniforme sobre  \ $\X = (  3 \, ; \,  3)$ \ y \ $Y  = g(X)$ \ con  \ $g(x) =
\left(  1 + \cos\left(  (|x|-1) \frac{\pi}{2}  \right) \right)  \un_{(1 \,  ; \,
  3)}(|x|) +  2 \un_{[0 \, ;  1]}(|x|)$.  Esta funci\'on  es representado figura
Fig.~\ref{fig:MP:TransformacionVANoContinua}-(a).    Claramente,  \  $g$   \  es
continua y diferenciable sobre $\X$, pero con \ $\X_{[0]} = [ -2 \, ; \, 1]$ que
no  es  de medida  nula.   Saliendo  de $F_Y(y)  =  P(g(X)  \le  y)$ se  calcula
sencillamente  $F_Y(y)  = \frac23  \left(  1  -  \frac1\pi \arccos(y-1)  \right)
\un_{[0  \,  ; \,  2)}  +  \un_{[ 2  \,  ;  \,  +\infty)}(y)$, ilustrada  figura
Fig.~\ref{fig:MP:TransformacionVANoContinua}-(b).   Claramente   \  $F_Y$  \  es
discontinua en \ $y = 2$: \ $Y$ \ no es continua.

\begin{figure}[h!]
\begin{center} \input{TIKZ_MP/TransformacionVANoContinua} \end{center}
%
\leyenda{En (a)  se dibuja $g(x) =  \left( 1 +  \cos\left( (1-|x|) \frac{\pi}{2}
    \right)   \right)   \un_{(1  \,   ;   \,  3)}(|x|)   +   2   \un_{[0  \,   ;
    1]}(|x|)$. Suponiendo de que $\X = (-3 \, ; \, 3)$, claramente $\X_{[0]} = [
  -1 \,  ; \, 1]$ no  es de medida nula,  dando para $X$ uniforme  sobre $\X$ la
  variable $Y = g(X)$ no continua de funci\'on de repartici\'on representenda en
  (b).  }
\label{fig:MP:TransformacionVANoContinua}
\end{figure}


%|q(y^1,\ldots,y^d)\ dy^1\cdots dy^d| = |p(x^1,\ldots,x^d) \ dx^1\cdots dx^d| .

%% Ejercicio: Estudiar el caso multivaluado / Resolver un ej. 

\

\aver{\SZ{No toque todav\'ia. Se puede hacerlo con vectores. Caso circular\ldots}

\hfill

Una  \emph{variable  aleatoria  compleja}   $Z=X+i  Y$  puede  interpretarse  en
t\'erminos de las  dos variables aleatorias reales $X$ e $Y$.  La pdf asociada \
$P(z)=p(x,y)$ est\'a dada por la  funci\'on densidad de probabilidad conjunta de
las variables reales. La condici\'on de normalizaci\'on se escribe
%
$$
\int P(z) \, d^2 z = 1
$$
%
donde $d^2 z=dx\,dy$.
}


% ================================= Vector discreto

\modif{
\subseccion{Leyes condicionales}
\label{sec:MP:LeyesCondicionales}

Tratando de un par de vectores aleatorios  \ $X$ \ e \ $Y$, una pregunta natural
puede ser de caracterisar el vector  $Y$ si ``observamos $X = x$''. En palabras,
la pregunta es de describir la lei de $Y$ ``sabiendo de que $X = x$''.

Un caso  sencillo a  estudiar es cuando  $\X =  X(\Omega)$ es discreto.  En este
caso, para  cualquier $x  \in \X$, tenemos  $P_X(x) = P(X  = x)  \ne 0$ y  de la
definici\'on  de  la  probabilidad condicional  Def.~\ref{def:ProbaCondicional},
$P(Y \in A | X = x) = \frac{P(Y  \in A \cap X = x}{P(X=x)}$ define una medida de
probabilidad que notaremos
%
\[
P_{Y|X=x}(A) = P(Y \in A | X = x)
\]
%

}


%%%%%%%%%%%%%


\SZ{hablar de simulaci\'on? Metoto inverso, mezcla, rejeccion, a traves de la condicional para el caso vectorial?}