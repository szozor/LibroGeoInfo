\seccion{Variables aleatorias y distribuciones de probabilidad}
\label{s:variablealeatoria}

{\it  En  un  experimento  o  un  dado  proceso,  los  posibles  resultados  son
  t\'ipicamente  n\'umeros reales, siendo  cada n\'umero  un evento.   Luego los
  resultados  son mutuamente  excluyentes. Se  considera a  esos  n\'umeros como
  valores de una  \emph{variable aleatoria} $X$ a valores  reales, que puede ser
  discreta, continua o ninguna (mixta).}

Formalmente, la noci\'on de variable aleatoria se var a apoyar sobre la noci\'on
de funci\'on medible. M\'as adelante, vamos a necesitar definir la integraci\'on
de manera general, m\'as all\'a del enfoque de Riemann (``a la Lebesgue'') as\'i
que la  noci\'on de derivada de  una medida con  respeto a una otra  para defnir
densidades de  probabilidades al  imagen de densidad  de masa en  mec\'anica por
ejemplo~\cite{Leb04, Leb18, KolFom61, AthLah06, Bog07:v1, Coh13}.


% ================================= Medida, integral, densidades

\subseccion{Consideraciones preliminarias \modif{-- teoria  de la medida y de la
    integraci\'on.}}
\label{sec:MP:VAPreliminaria}

La  primera noci\'on  que subtiende  a la  definici\'on formal  de  una variable
aleatoria es la de funci\'on medible:

\begin{definicion}[Funci\'on medible]
  Sean  \ $(\Omega,\A)$  \ y  \ $(\Upsilon,\B)$  \ dos  espacios  medibles.  Una
  funci\'on $f: \Omega \mapsto \Upsilon$ es dicha {\it $(\A,\B)$-medible} si
  %
  \[
  \forall \,  B \in  \B, \quad  A \equiv f^{-1}(B)  = \left\{  \omega \in  A: \,
    f(\omega) \in B \right\} \: \in \: \A.
  \]
  %
  Dicho de  otra manera,  la pre-imagen  de un elemento  dada de  $\B$ (elemento
  medible)  partenece  a  $\A$  (elemento  medible).  A  veces,  se  dice  m\'as
  simplemente de que $f: (\Omega,\A) \mapsto (\Upsilon,\B)$ es medible por abuso
  de escritura.
\end{definicion}

Adem\'as, saliendo de un espacio de medida y una funci\'on $f$ medible, se puede
definir una medida imagen  sobre el espacio de llegada~\cite{AthLah06, Bog07:v1,
  Coh13}:
%
\begin{teorema}[Teorema de la medida imagen]\label{Th:MP:MedidaImagen}
  Sean  \ $(\Omega,\A,\mu)$  \  un espacio  de  medida, \  $(\Upsilon,\B)$ \  un
  espacio  medible  y  una  funci\'on  $f:  (\Omega,\A)  \mapsto  (\Upsilon,\B)$
  medible. Sea $\mu_f$ tal que
  %
  \[
  \forall \,  B \in  \B, \quad  \mu_f(B) = \mu\left( f^{-1}(B) \right).
  \]
  %
  Entonces, $\mu_f$ es una medida sobre el espacio medible $(\Upsilon,\B)$ \ \ie
  \ $(\Upsilon,\B,\mu_f)$ \ define un espacio de medida.  Adem\'as, $\mu(\Omega)
  =  \mu_f(\Upsilon)$ (posiblemente  infinitas).  $\mu_f$ es  dicha {\it  medida
    imagen de $\mu$ por $f$}.
\end{teorema}
%
\begin{proof}
  Por  definici\'on,  claramente $\mu_f  \ge  0$ \  y  por  definici\'on de  una
  funci\'on,  $f^{-1}(\emptyset)  =   \emptyset$  \  dando  $\mu_f(\emptyset)  =
  \mu(\emptyset) =  0$.  Luego,  si para  un conjunto numerable  $\{ B_j  \}$ de
  elementos  de $\B$  disjuntos entre  s\'i, las  preimagenes de  los  $B_j$ son
  disjuntos tambi\'en entre  s\'i (para $k \ne j$ no se  puede tener $\omega \in
  f^{-1}(B_j) \cap f^{-1}(B_k)$ si no $\omega$ tendr\'ia dos imagenes distinctas
  por  $f$).   Entonces  \  $f^{-1}\left(  \bigcup_j  B_j  \right)  =  \bigcup_j
  f^{-1}(B_j)$.   Eso implica  de que  \  $\mu_f\left( \bigcup_j  B_j \right)  =
  \mu\left(  f^{-1}\left( \bigcup_j  B_j \right)  \right) =  \mu\left( \bigcup_j
    f^{-1}(B_j)  \right)  =  \sum_j   \mu\left(  f^{-1}(B_j)  \right)  =  \sum_j
  \mu_f(B_j)$.   Finalmente,  necesariamente  $f^{-1}(\Upsilon)  =  \Omega$  (es
  incluida y $f(\Omega)$ siendo en $\Upsilon$ son necesariamente iguales) lo que
  cierra  la prueba~\footnote{De  hecho, se  puede sencillamente  probar  que la
    preimagen de una  uni\'on numerable (que sean disjuntos o  no) es la uni\'on
    de las  preimagenes; lo  mismo occure para  la intersecci\'on y  adem\'as la
    preimagen  del  complemento es  el  complemento  de  la preimagen.   Eso  es
    conocido como {\it leyes de de Morgan}~\cite{AthLah06, Coh13, HogMck13} (ver
    tambi\'en~\cite[Cap.~1]{KolFom57}
    y~\cite[Caps.~5~\&~6]{KolFom61}).\label{foot:MP:Jacobiana}}
\end{proof}

\

Un espacio  jugando un rol particular es  $\Rset^d$, a lo cual  se puede asociar
una    $\sigma$-\'algebra    particular    \modif{es    conocido    como    {\it
    $\sigma$-\'algebra de Borel}}~\cite{AthLah06, Bog07:v1, Bog07:v2, Coh13}:
%
\begin{definicion}[$\Rset^d$ y Borelianos]
  Para  cualquier  $d  \ge  1$  entero,  llamamos  Borelianos  $\B(\Rset^d)$  de
  $\Rset^d$  la $\sigma$-\'algebra  m\'as peque\~na  generada por  los productos
  cartesianos   $\displaystyle   \optimes_{i=1}^d  (-\infty   \,   ;  \,   b_i]$
  \big(equivalentemente,  por los  abiertos de  $\Rset^d$, o  tambi\'en  por los
  productos cartesianos de intervalos  $\displaystyle \optimes_{i=1}^d (a_i \, ;
  \, b_i]$\big), \ie uniones numerables, intersecciones numerables, complementos
  de    estos   intervalos.    $\B(\Rset^d)$    es   tambi\'en    llamado   {\it
    $\sigma$-\'algebra de Borel de $\Rset^d$}.
\end{definicion}

\

Se necesita ahora definir la  noci\'on de integraci\'on de una funci\'on medible
con respeto a una medida:
%
\begin{definicion}[Medida e intergraci\'on]
  Para una medida  cualquiera, sobre un espacio de  medida $(\Omega,\A,\mu)$, se
  define la integraci\'on a partir de
  %
  \[
  \forall \, A \in \A,  \quad \int_A d\mu(\omega) = \int_\Omega \un_A(\omega) \,
  d\mu(\omega) = \mu(A),
  \]
  %
  donde
  %
  \[
  \un_A(\omega) = \left\{
  \begin{array}{clr}
  1 & \mbox{si} \quad \omega \in A\\
  0 & \mbox{si no}
  \end{array} \right.
  \]
  %
  es  la funci\'on  indicadora del  conjunto $A$.   $d\mu(\omega)$ se  escribe a
  veces  tambi\'en $\mu(d\omega)$, medida  de un  ``infinitesimo''.  Claramente,
  por  propiedades  de una  medida,  para $  A_i,  A_j$  disjuntos $\un_{A_i}  +
  \un_{A_j}  =  \un_{A_i \cup  A_i}$,  dando  $\displaystyle \int_\Omega  \left(
    \un_{A_i} + \un_{A_j} \right) d\mu(\omega) = \mu(A_i \cup A_j) = \int_\Omega
  \un_{A_i} d\mu(\omega)  + \int_\Omega \un_{A_j} d\mu(\omega)$  y entonces, sin
  perdida  de  generalidad~\footnote{Si  $A_i,  A_j$ no  son  disjuntos,  sufice
    considerar $A_i\backslash A_j, \: A_j\backslash  A_j, A_i \cap A_j$ \ con $A
    \backslash B = \{ \omega: \omega \in  A \: \mbox{y} \: \omega \not\in B\}$ \
    y respectivamente los coefficientes \  $a_i, \: a_j, \: a_i +
    a_j$.}   para  un  conjunto  $\{  A_j  \}$  numerable,  con  los  $A_j$
  disjuntos, y $\{ a_j \}$ reales no negativos, la integral de la funci\'on
  escalonada \ $\displaystyle \sum_j a_j \un_{A_j}$ \ es dada por
  %
  \[
  \int_\Omega \left( \sum_j a_j \un_{A_j}(\omega) \right) \, d\mu(\omega) =
  \sum_j a_j \int_\Omega \un_{A_j}(\omega) \, d\mu(\omega).
  \]
  %
\end{definicion}


Antes de definir la integraci\'on de una funci\'on real, medible, cualquiera, el
\'ultimo paso que falta es el siguiente:
%
\begin{teorema}[Funci\'on medible como limite]\label{Th:MP:MedibleLimite}
  Sea $g: (\Omega,\A) \mapsto  (\Rset,\B(\Rset))$, no negativa y medible, existe
  una sucesi\'on  $\{ g_n \}_{n  \in \Nset}$ creciente de  funciones escalonadas
  que converge simplemente (punto a punto) hacia $g$.
\end{teorema}
%
\begin{proof}
  La  sucesi\'on  $\displaystyle g_n  =  \sum_{k=0}^{n  2^n-1} \frac{k}{2^n}  \,
  \un_{g^{-1}\left(  \left[  \frac{k}{2^n}   \,  ;  \,  \frac{k+1}{2^n}  \right)
    \right)} + n \, \un_{g^{-1}\left( \left[ n \, ; \, +\infty \right) \right)}$
  es escalonada, creciente  y converge hacia $g$ \  (fijense que esta sucesi\'on
  comparte la idea subtendido a la integraci\'on de Riemann).
\end{proof}

De  este resultado, se  puede generalizar  la noci\'on  de integraci\'on  de una
funci\'on real:
%
\begin{definicion}[Integraci\'on de una funci\'on real]\label{Def:MP:IntegracionReal}
  Sea $g: (\Omega,\A)  \mapsto (\Rset,\B(\Rset))$, no negativa y  medible, y $\{
  g_n  \}_{n  \in  \Nset}$  creciente  de  funciones  escalonadas  que  converge
  simplemente hacia $g$. Por definici\'on,
  %
  \[
  \int_{\Omega}  g(\omega) \,  d\mu(\omega)  = \lim_{n  \to \infty}  \int_\Omega
  g_n(\omega) \, d\mu(\omega).
  \]
  %
  Fijense de que el limite puede ser infinita.\newline Sea ahora $g: (\Omega,\A)
  \mapsto (\Rset,\B(\Rset))$  medible cualquiera.  Se  verifica sencillamente de
  que  tambi\'en   $|g|$  es   medible  y,  por   definici\'on,  $g$   es  dicha
  $\mu$-integrable si la integral de $|g|$ es finita,
  %
  \[
  g   \:  \mbox{es}   \:  \mu\mbox{-integrable}   \quad   \Leftrightarrow  \quad
  \int_\Omega |g(\omega)| \, d\mu(\omega) < +\infty.
  \]
  %
  Por  fin,  se escribe  $g  =  g_+  + g_-$  con  $g_+  =  \max(g,0)$ y  $g_-  =
  \min(g,0)$. Es sencillo ver de que si  \ \modif{$g$ \ es medible,} \ $g_+$ \ y
  \ $g_-$ \ son medibles. Si \ $g$ \ es $\mu$-integrable, necesariamente \ $g_+$
  \ y \ $g_-$ \ son $\mu$-integrables, y, por definici\'on
  %
  \[
  \int_\Omega   g(\omega)   \,  d\mu(\omega)   =   \int_\Omega  g_+(\omega)   \,
  d\mu(\omega) - \int_\Omega \left( - g_-(\omega) \right) \, d\mu(\omega).
  \]
\end{definicion}

\modif{
\SZ{Poner eso en un apendice?}

A continuaci\'on, damos unos teoremas que ser\'an muy \'util m\'as adelante, sin
detallar las  pruebas. Por eso,  se puede referirse  a~\cite{AthLah06, Bog07:v1,
  Coh13}.
%
\begin{teorema}[Teorema de convergencia monotona]
  Sea  \ $\{  f_n \}_{n  \in  \Nset}$ \  una sucesi\'on  creciente de  funciones
  medibles  sobre $(\Omega,\A,\mu)$,  positivas, convergiendo  simplemente hacia
  una funci\'on \ $f$ \ medible. Entonces
  %
  \[
  \lim_{n  \to  +\infty}  \int_\Omega  f_n(\omega)  d\mu(\omega)  =  \int_\Omega
  f(\omega) d\mu(\omega).
  \]
\end{teorema}
%
De hecho se proba este teorema a partir de la definici\'on de la definici\'on de
la integraci\'on. Este teorema da una condici\'on simple permitiendo intercambia
integraci\'on y limite.

\begin{corolario}
  Sea \ $\{  f_n \}_{n \in \Nset}$ \ una sucesi\'on  de funciones medibles sobre
  $(\Omega,\A,\mu)$,  positivas,   tal  que  la  serie   $\sum_n  f_n$  converge
  simplemente hacia una funci\'on \ $f$, $\mu$-integrable. Entonces
  %
  \[
  \int_\Omega  \sum_{n   \in  \Nset}  f_n(\omega)   d\mu(\omega)  =  \int_\Omega
  f(\omega) d\mu(\omega).
  \]
\end{corolario}
%
Es  una  consecuencia del  teorema  de  convergencia  monotona, considerando  la
sucesi\'on creciente $\{ \sum_{k=0}^n f_n \}_{n \in \Nset}$.

\begin{teorema}[Teorema de convergencia dominada]
  Sea  \ $\{  f_n \}_{n  \in  \Nset}$ \  una sucesi\'on  creciente de  funciones
  medibles sobre $(\Omega,\A,\mu)$  convergiendo simplemente hacia una funci\'on
  \ $f$, medible.  Suponemos que existe una funci\'ion  \ $g$ \ $\mu$-integrable
  que  domina  la  sucesi\'on,  \ie  $\forall  \, \omega  \in  \Omega,  \quad  |
  f_n(\omega) | \le g(\omega)$. Entonces
  %
  \[
  \lim_{n  \to  +\infty}  \int_\Omega  f_n(\omega)  d\mu(\omega)  =  \int_\Omega
  f(\omega) d\mu(\omega).
  \]
\end{teorema}
%
Este  teorema  da  una  condici\'on  suficiente  muy \'util  y  muy  usada  para
asegurarse de que se puede intercambiar limite e integraci\'on.

El   \'ultimo  teorema   que  vamos   a  necesitar   permite   intercambiar  dos
integraci\'ones.  Antes,  necesitamos definir  la  noci\'on  de espacio  medible
producto y medida producto.
%
\begin{definicion}[Espacio medible producto, medida producto]
  Sean dos  espacios de  medida \  $(\Omega_1, \A_1, \mu_1)$  \ y  \ $(\Omega_2,
  \A_2, \mu_2)$. Llamamos  {\it espacio medible producto} el  espacio $(\Omega ,
  \A)$ el  espacio del producto  cartesiano $\Omega = \Omega_1  \times \Omega_2$
  con  la $\sigma$-\'algebra $\A$  generada por  los productos  cartesianos $A_1
  \times A_2$  donde $A_i  \in \A_i$. Al  final, llamamos medida  producto $\mu$
  definida sobre $\A$ tal que $\forall  \: (A_1,A_2) \in \A_1 \times \A_2, \quad
  \mu(A_1 \times A_2) = \mu_1(A_1) \mu_2(A_2)$.
\end{definicion}

\begin{teorema}[Teorema de Fubini]\label{Th:MP:Fubini}
  Sea  $(\Omega,\A,\mu)$  espacio de  medida  producto  de  \ $(\Omega_1,  \A_1,
  \mu_1)$ \  y \ $(\Omega_2,  \A_2, \mu_2)$ donde  $\mu$ es la  medida producto.
  Sea $f$ funci\'on medible sobre $(\Omega,\A,\mu)$ y suponemos la funci\'on
  %
  \[
  g(\omega_1)   =  \int_{\Omega_2}   \left|   f(\omega_1,\omega_2)  \right|   \,
  d\mu_2(\omega_2) \quad \mu_1\mbox{-integrable}.
  \]
  %
  Entonces, $f$ \ es $\mu$-integrable y
  %
  \[
  \int_{\Omega_1  \times \Omega_2}  f(\omega) \,  d\mu(\omega)  = \int_{\Omega_1}
  \left(    \int_{\Omega_2}   f(\omega)    \,   d\mu_2(\omega_2)    \right)   \,
  d\mu_1(\omega_1)   =  \int_{\Omega_2}   \left(  \int_{\Omega_1}   f(\omega)  \,
    d\mu_1(\omega_1) \right) \, d\mu_2(\omega_2)
  \]
  %
  (obviamente, se puede intercambiar los roles de los $\Omega_i$ en este teorema).
\end{teorema}
%
\begin{teorema}[Integral a par\'ametro: continuidad y diferenciabilidad]
  Sea $I$ un compacto de $\Rset^d$ y $\{ f(\cdot,t) \}_{t \in I}$ una familia de
  funciones  medibles  sobre $(\Omega,\A,\mu)$,  tal  que $f(\omega,\cdot)$  sea
  continua sobre $I$. Si existe una funci\'on \ $g$ \ $\mu$-integrable tal que
  %
  \[
  \forall \:  t \in I, \quad  \forall \: \omega \in  \Omega, \quad |f(\omega,t)|
  \le g(\omega),
  \]
  %
  entonces la funci\'on
  %
  \[
  t  \mapsto \int_\Omega  f(\omega,t)  \, d\mu(\omega)  \quad \mbox{es  continua
    sobre \ } I.
  \]
  %
  Adem\'as, si \ $f(\omega,\cdot)$ \ es  diferenciable sobre \ $I$ \ y si existe
  una funci\'on $\mu$-integrable \ $h$ \ tal que
  %
  \[
  \forall \: t \in I, \quad  \forall \: \omega \in \Omega, \quad \left| \nabla_t
    f(\omega,t) \right| \le h(\omega),
  \]
  %
  donde   $\nabla_t$    es   gradiente,    \ie   el   vector    de   componentes
  $\frac{\partial}{\partial  t_i}$,  entonces la  funci\'on  \ $\displaystyle  t
  \mapsto \int_\Omega  f(\omega,t) \, d\mu(\omega)$  \ es diferenciable  sobre \
  $I$ \ y
  %
  \[
  \nabla_t  \int_\Omega  f(\omega,t)  \,  d\mu(\omega)  =  \int_\Omega  \nabla_t
  f(\omega,t) \, d\mu(\omega).
  \]
\end{teorema}
%
Basicamente, este teorema es  consecuencia del teorema de convergencia dominada.
}

\

Seguimos esta secci\'on con la noci\'on  de derivada de una medida con respeto a
una otra, dando una definici\'on muy general de una densidad:
%
\begin{definicion}[Densidad de una medida]\label{def:MP:DensidadMedida}
  Sean  $\mu$  y  $\nu$  dos  medidas  cualquieras  sobre  une  espacio  medible
  $(\Omega,\A)$.  Si  existe una funci\'on  real no negativa $p:  \Omega \mapsto
  \Rset_+$ medible tal que
  %
  \[
  \forall \, A \in \A, \quad \nu(A) = \int_A p(\omega) d\mu(\omega),
  \]
  %
  $p$ \ es llamada densidad de \ $\nu$ \ con respeto a \ $\mu$, denotada
  %
  \[
  p = \frac{d\nu}{d\mu},
  \]
  %
  tambi\'en llamada derivada de Radon-Nikod\'ym.
\end{definicion}

\modif{Fijense  de  que dos  funciones  pueden  cumplir  esta definici\'on,  por
  ejemplo  si  son diferentes  en  un  conjunto de  medida  \  $\mu$  \ igual  a
  cero. M\'as generalmente viene ac\'a la noci\'on de igualdad casi siempre:}
%
\begin{definicion}[Igualidad $\mu$-casi siempre]
  Dos funciones  medibles \ $p_1$  \ y \  $p_2$ \ son dichas  iguales $\mu$-casi
  siempre,
  %
  \[
  p_1 = p_2 \quad (\mu-c.s.)
  \]
  %
  si y solamente son iguales excepto sobre un conjunto de medida nula,
  %
  \[
  \mu\left( \left\{ \omega: \: p_1(\omega) \ne p_2(\omega) \right\} \right) = 0.
  \]
\end{definicion}
%
\noindent Ahora, si  dos funciones \ $p_1  = p_2 \quad (\mu-c.s.)$, y  $C$ es el
conjunto donde no son iguales, notando \ $A \backslash C = \{ \omega: \omega \in
A \:  \mbox{y} \:  \omega \not\in B\}$,  de \ $\displaystyle  \int_A p_1(\omega)
d\mu(\omega) = \int_{A\backslash C} p_1(\omega) d\mu(\omega) = \int_{A\backslash
  C} p_2(\omega) d\mu(\omega) = \int_A p_2(\omega) d\mu(\omega)$ \ se ve que dos
funciones iguales casi  siempre pueden ser densidad de una  medida con respeto a
una otra.

\modif{
Es sencillo ver  de que si $\mu(A)  = 0$, necesariamente $\nu(B) =  0$:
%
\begin{definicion}[Absoluta continuidad]
  Sea \ $\mu$ \ y \ $\nu$ \ dos medidas sobre un espacio medible \ $(\Omega,\A)$
  dicha {\it  absolutamente continua}  con respeto a  $\mu$, denotado  \[\nu \ll
  \mu,\] si $\forall  \: A \in \A, \quad  \mu(A) = 0 \: \Rightarrow  \: \nu(A) =
  0$.
\end{definicion}
%
De    hecho,     se    muestra     la    reciproca    del     la    definici\'on
Def.~\ref{def:MP:DensidadMedida} resultado a trav\'es de lo que es conocido como
teorema de Radon-Nikod\'ym~\cite{Nik30, AthLah06, Bog07:v1, Coh13}:
%
\begin{teorema}[Radon-Nikod\'ym]\label{Th:MP:RadonNikodym}
  Sean dos medidas $\mu$ \ y \ $\nu$, entonces
  %
  \[
  \nu \ll \mu \quad \Longleftrightarrow  \quad \nu \: \mbox{ admite una densidad
    con respeto a } \: \mu.
  \]
  %
  Adem\'as, esta densidad $\frac{d\nu}{d\mu}$ es \'unica en el sentido de que si
  dos funciones cumplen la definici\'on, son iguales $\mu$-casi siempre.
\end{teorema}
}

En todo lo que  sigue, hablaremos de ``la'' densidad de una  medida, salvo si se
necesita  explicitamente  tener  en  cuenta esta  sutileza.

\

\modif{Unas medidas que  juegan un rol particular son las  medidas de Lebesgue o
  medidas discretas}.
%
\begin{definicion}[Medida de Lebesgue]\label{Def:MP:Lebesgue}
  La medida de  Lebesgue $\mu_L$ sobre $(\Rset^d,\B(\Rset^d))$ la,  tal que para
  cualquier porducto cartesiano de intervalos,
  %
  \[
  \mu_L\left(  \optimes_{i=1}^d  (a_i  \,  ;  \, b_i)  \right)  =  \prod_{i=1}^d
  (b_i-a_i).
  \]
  %
\end{definicion}
%
\modif{Ac\'a, notamos dos hechos interesantes
%
\begin{itemize}
\item $\forall \:  A \in \A, \quad  \mu_L(A) = |A|$ \ donde  $|\cdot|$ denota el
  volumen de unconjunto (puede ser infinito).
%
\item Para una funci\'on \ $g$ \ suficientemente ``suave'', la integraci\'on con
  respeto a la medida de  Lebesgue coincide naturalmente con la integraci\'on de
  Rieman.
\end{itemize}
}
%
\modif{La medida de Lebesgue siendo  as\'i natural tratando de la integraci\'on,
  e}n  lo  que  sigue,   tratando  de  igualdad  $\mu_L$-casi  siempre,  diremos
simplemente  ``casi siempre''  $(c.s.)$, subentiendo  que  es con  respeto a  la
medida  de  Lebesgue. \modif{De  la  misma  manera,  hablando de  densidad,  sin
  precisiones, ser\'a a entender con respeto a $\mu_L$.

  Al  ``opuesto'' de  la medida  de  Lebesgue, medidas  discretas son  tambi\'en
  particulares. La m\'as  ``elemental'' es conocida como {\it  medida de Dirac},
  dando lugar a medidas discretas:
%
\begin{definicion}[Medida de Dirac y medida discreta]\label{Def:MP:Dirac}
  La medida de Dirac en un punto  \ $x_0$, \ denotada \ $\delta_{x_0}$ \ es tal
  que
  %
  \[
  \forall   \  B  \in   \B(\Rset^d),  \quad   \delta_{x_0}(B)  =   \un_B(x_0)  =
  \left\{ \begin{array}{ll}
  %
  1 & \mbox{si } \: x_0 \in B\\[2.5mm]
  %
  0 & \mbox{si no}
  %
  \end{array}\right..
  \]
  %
  Dado un conjunto \ $\X \{  x_i \}_i$ \ discreto (finito o infinito numerable),
  llamaremos {\it medida discreta} la medida definida por
  %
  \[
  \mu_\X = \sum_i \delta_{x_i}
  \]
  %
  (en general, son definidas como combinaci\'on lineales positivas, este siendo un caso particular).
\end{definicion}
%
Fijense de que, para $f$ medible, tenemos
%
\[
\int_B f(x) \, d\delta_{x_k}(x) = f(x_k).
\]
%
Se  proba  saliendo  de   \  $f$  \  de  la  forma  \  $f   =  \un_C$  \  y  del
teorema~\ref{Th:MP:MedibleLimite}     conjuntamente     a    la     definici\'on
Def.~\ref{Def:MP:IntegracionReal}.  }

\

Con estas series  de definiciones, tenemos todo lo  necesario para introducir la
definici\'on de variables/vectores aleatoria(o)s reales y sus caracterizaciones.


% ================================= VA y distribuci\'on de probabilidad

\subseccion{Variables aleatorias, vectores aleatorios y distribuci\'on de probabilidad}
\label{sec:MP:VAGeneral}

Empezamos con la  noci\'on de variable aleatoria real, que  queremos ver como el
resultado de un experimento o de un evento dado~\cite{AthLah06, Coh13, Bre88}:
%
\begin{definicion}[Variable aleatoria real]
  Una variable aleatoria real es una funci\'on medible
  %
  \[
  X: (\Omega,\A,P) \mapsto (\Rset,\B(\Rset),P_X)
  \]
  %
  donde la medida  $P_X$ sobre $\B(\Rset)$ es la medida imagen  de $P$.  \ $P_X$
  es frecuentemente llamada {\it distribuci\'on  de probabilidad} o {\it ley} de
  la variable aleatoria $X$. En lo que sigue, escribiremos los eventos
  %
  \[
  (X \in B) \equiv X^{-1}(B) = \{ \omega \in \Omega: \: X(\omega) \in B \},
  \]
  %
  as\'i que, por definici\'on,
  %
  \[
  P_X(B) = P(X \in B)
  \]
\end{definicion}
%
Para  ilustrar esta definici\'on,  tomando el  ejemplo de  un dado,  $\Omega$ es
discreto y representa  las caras, mientras de que los  numeros ser\'an la imagen
de $\Omega$ por $X$ (ej. $X(\omega_j) = j, \quad j = 1, \ldots , 6$).

Fijense de que, por las  propiedades de una medida sobre una $\sigma$-\'algebra,
para caracterizar completamente la  distribuci\'on $P_X$ es suficiente conocerla
sobre  los intervalos de  la forma  $(-\infty \,  ; \,  b]$. Eso  da lugar  a la
definici\'on  de  la funci\'on  de  repartici\'on~\cite{AthLah06, Coh13,  Bre88,
  HogMck13}:
%
\begin{definicion}[Funci\'on de repartici\'on]
  Por  definici\'on,  la  funci\'on  de  repartici\'on  $F_X$  de  una  variable
  aleatoria es definida por
  %
  \[
  F_X(x) = P_X((-\infty \, ; \, x]) = P(X \le x).
  \]
  %
  A veces, por abuso de terminologia,  se denomina $F_X$ como ley de la variable
  aleatoria. Se  encuentra tambi\'en  en la literatura  la terminologia  de {\it
    funci\'on cumulativa} (cdf por cumulative density function en ingl\'es).
\end{definicion}
%
Naturalmente, de las propiedades de una medida de probabilidad,
%
\begin{itemize}
\item $0 \le F_X(x) \le 1$;
%
\item $\displaystyle \, \lim_{x \to -\infty} F_X(x) = 0$ \ y \ $\displaystyle \,
  \lim_{x \to +\infty} F_X(x) = 1$  (viene de $P_X(\emptyset) = 0$ y $P_X(\Rset)
  = 1$);
%
\item  $F_X$ es creciente  \big(viene de  que \  $x_1 \le  x_2 \:  \Leftrightarrow \:
  (-\infty \, ; \, x_1] \subseteq (-\infty \, ; \, x_2]$\big);
%
\item $F_X$ no es necesariamente continua  (lo vamos a ver m\'as adelante), pero
  en cada punto $x$ es continua a su derecha (ver punto anterior).
\end{itemize}


Cuando se trabaja  con $d\geq 2$ variables aleatorias  es conveniente definir un
{\it vector aleatorio}  de dimensi\'on $d$, y apelar para  su estudio a nociones
del \'algebra  lineal y  a notaci\'on matricial.   Se tiene el  vector aleatorio
$d$-dimensional \ $X = \begin{bmatrix} X_1 & \cdots & X_d \end{bmatrix}^t$ donde
$\cdot^t$  denota  la  transpuesta,  caracterizado por  $d$-uplas  de  variables
aleatorias reales.   Como en  el caso  univariado, se define  este vector  de la
manera siguiente~\cite{AthLah06, Coh13, Bre88}:
%
\begin{definicion}[Vector aleatorio real]
  Un vector aleatorio real es una funci\'on medible
  %
  \[
  X: (\Omega,\A,P) \mapsto (\Rset^d,\B(\Rset^d),P_X).
  \]
  %
  donde  $\B(\Rset^d)$  son  los  borelianos  de  $\Rset^d$,  $\sigma$-\'algebra
  generada por  los productos cartesianos $(-\infty  \, ; \,  b_1] \times \cdots
  \times (-\infty \,  ; \, b_d]$ y donde la medida  $P_X$ sobre $\B(\Rset^d)$ es
  la medida  imagen de  $P$ llamada {\it  distribuci\'on de probabilidad}  de la
  variable aleatoria (o vector aleatorio) \ $X$. Como en el caso escalar,
  %
 \[
 (X \in B) \equiv X^{-1}(B) = \{ \omega \in \Omega: \: X(\omega) \in B \} \qquad
 \mbox{y} \qquad P_X(B) = P(X \in B).
 \]
\end{definicion}
%
\noindent  \modif{Nota: a  veces, tenemos  que  considerar el  caso de  matrices
  aleatorias, o funciones medibles matriz-valuadas. Siendo de que se puede poner
  en biyecci\'on,  una matriz con un  vector (por ejemplo  poniendo cada columna
  ``debajo'' de  su columna antecedante),  no desarollaremos m\'as este  caso, a
  pesar de que  a veces sea m\'as conveniente trabajar con  matrices en lugar de
  su forma en vector.}

\

De las propiedades de una medida sobre una $\sigma$-\'algebra, para caracterizar
completamente la distribuci\'on $P_X$ de nuevo es suficiente conocerla sobre los
elementos de  la forma $\displaystyle  \optimes_{i=1}^d (-\infty \, ;  \, b_i]$,
\ie  la funci\'on  de repartici\'on  multivariada~\cite{AthLah06,  Coh13, Bre88,
  HogMck13}:
%
\begin{definicion}[Funci\'on de repartici\'on multivariada]
  Por  definici\'on,  la  funci\'on  de  repartici\'on  $F_X$  de  un vector
  aleatorio es definida en $x = (x_1 , \ldots , x_d)$ por
  %
  \[
  F_X(x) =  P_X\left( \optimes_{i=1}^d (-\infty \,  ; \, x_i]  \right) = P\left(
    \bigcap_{i=1}^d (X_i \le x_i) \right).
  \]
  %
\modif{Por abuso de escritura, escribiremos en lo que sigue
  \[
  F_x(x) = P(X \le x),
  \]
  %
  subentiendo de que $X \le  x$ es el evento $\displaystyle \bigcap_{i=1}^d (X_i
  \le x_i)$.}
\end{definicion}
%
De nuevo, de las propiedades de una medida de probabilidad,
%
\begin{itemize}
\item $0 \le F_X(x) \le 1$;
%
\item $\displaystyle  \, \lim_{\forall  i, x_i \to  -\infty} F_X(x)  = 0$ \  y \
  $\displaystyle \, \lim_{\forall i, x_i \to +\infty} F_X(x) = 1$;
%
\item $F_X$ es creciente con respecto a cada variable $x_i$.
\end{itemize}
%
Al  final, para  un subconjunto  $I_k =  (i_1,\ldots,i_k)$ de  $1 \le  k  \le d$
elementos de  $\{ 1  , \ldots ,  d \}^k$,  $X_{I_k} = \begin{bmatrix}  X_{i_1} &
  \cdots   &   X_{i_k}\end{bmatrix}^t$  es   obviamente   un  vector   aleatorio
$k$-dimensional. Es entonces sencillo ver de que
%
\[
F_{X_{I_k}}(x_{I_k}) = \lim_{\forall i \not\in I_k, x_i \to +\infty} F_X(x).
%\label{pagina:MP:MarginalesF}
\]
%
(viene de  que $\bigcap_{j=1}^k (X_{i_j}  \le x_{i_j}) =  \left( \bigcap_{j=1}^k
  (X_{i_j} \le x_{i_j}) \right) \bigcap  \left( \bigcap_{i \not\in I_k} (X_i \in
  \Rset)  \right)$). Esta  funci\'on es  dicha {\it  funci\'on  de repartici\'on
  marginale} de $F_X$.

Cerramos estas generalidades con el caso de variables independientes:
%
\begin{definicion}[Independencia]
  Sean $d$  variables aleatorias  $X_i$ y  $X = \begin{bmatrix}  X_1 &  \cdots &
    X_d  \end{bmatrix}^t$.   Los  $X_i$   son  mutuamente  independientes  si  y
  solamente si,  para cualquier ensemble  de conjuntos $B_i$, los  eventos $(X_i
  \in \B_i)$ son mutuamente independientes, \ie
  %
  \[
  P_X\left( \optimes_{i=1}^d B_i \right) = \prod_{i=1}^d P_{X_i}(B_i).
  \]
  %
  Es equivalente a
  %
  \[
  F_X(x) = \prod_{i=1}^d F_{X_i}(x_i).
  \]
  %
  La  ley  del  vector  aleatorio  se factoriza.  \modif{Necesariamente,  $\X  =
    X(\Omega)$  es  de  la  forma  $\X  =  \optimes_i \X_i$  \  con  \  $\X_i  =
    X_i(\Omega)$, producto cartesiano.}
\end{definicion}
%
\noindent Es importante notar de que  no es equivalente a tener la independencia
por pares, como ilustrado en el fin de la seci\'on precediente.

\

M\'as  all\'a de  este  enfoque  general, dos  casos  particulares de  variables
aleatorias son  de inter\'es:  las variables discretas  y las continuas.   En el
primer caso  $X(\Omega)$ es discreto, finito  o no.  La meta  de las susecciones
siguientes es estudiar las particularidades de cada caso.

Par fijar unas notaciones, en todo lo que sigue, escribiremos
%
\[
\X = X(\Omega)
\]
%
conjunto de  llegada de $X$, o conjunto  de valores que puede  tomar la variable
aleatoria.  A  veces, por  razones de simplificaciones,  se considera  $\X$ como
siendo el  espacio muestral  y se olvida  de que  $X$ sea una  funci\'on medible
entre espacios de probabilidades,  \ie se trabaja en $(\Rset^d,\B(\Rset^d),P_X)$
como en el espacio preimagen.



% ================================= Discreta

\subseccion{Variable aleatoria discreta}
\label{sec:MP:VADiscreta}

\begin{definicion}[Variable aleatoria discreta]
  Una  variable aleatoria es  dicha {\it  discreta} cuando  $\X =  X(\Omega)$ es
  discreto,  finito o  infinito numerable.   En  lo que  sigue, denotaremos  por
  $|\X|$  el cardinal  de $\X$,  posiblemente infinito.  En otras  palabras, los
  posibles  valores de  una  variable  aleatoria discreta  $X$  consisten en  un
  conjunto contable (finito  o infinito numerable) de n\'umeros  reales, \ $\X =
  \{ x_j \}$ \ y se puede escribir \ $X$ \ como una {\it variable escalonadas},
  %
  \[
  X = \sum_j x_j \un_{A_j} \quad \mbox{con} \quad A_j = X^{-1}(\{ x_j \}).
  \]
\end{definicion}
%
\noindent (ver ej.  ~\cite{AthLah06, HogMck13}).  Fijense de que  $\Omega$ no es
necesariamente discreto.  Por ejemplo, si  $\omega$ es la posici\'on de un punto
sobre una linea, y \ $X(\omega) = 0$ si $\omega$ es a la izquierda de un umbral, y
$X(\omega) = 1$ si $\omega$  es a su derecha, $\X = \{ 0 \,  ; \, 1 \}$ mientras
de que $\Omega$ no es discreto.

En el  caso de una variable  aleatoria discreta $X$,  las probabilidades $P_X(\{
x_j \})  = P(X = x_j), \:  x_j \in \X$ caracterisan  completamente esta variable
aleatoria~\cite{AthLah06, HogMck13}:
%
\begin{definicion}[Funci\'on de masa de probabilidad]
  Por  definici\'on, la  funci\'on  de  masa de  probabilidad  de $X$,  variable
  aleatoria discreta tomando sus valores sobre $\X$ es dada por
  %
  \[
  p_X(x) \equiv P(X = x) = P_X( \{ x\} ) \quad x \in \X.
  \]
  %
  Por   abuso  de   denominaci\'on,  llamaremos   en  este   libro   $p_X$  {\it
    distribuci\'on de probabilidad}. Adem\'as, usaremos tambi\'en la notaci\'on
  %
  \[
  p_X = \begin{bmatrix} \cdots & p_X(x_j) & \cdots \end{bmatrix}^t
  \]
  %
  dicho {\it vector de probabilidad}, de tama\~no $|\X|$, posiblemente infinito.
\end{definicion}
%
Fijense de  que, $P_X$ siendo  una medida  de probabilidad, $p_X  \ge 0$ \  y es
obviamente normalizada en el sentido de que
%
\[
\sum_{x_j \in \X} p_X(x_j) = 1.
\]
%
En  la  Fig.~\ref{fig:MP:ProbaDiscreta}-(a)   se  muestra  una  representaci\'on
gr\'afica de una distribuci\'on de probabilidad discreta.
%
En particular,
%
\[
\forall \,  B \in  \B(\Rset), \quad  P_X(B) = \sum_{x  \in \X  \cap B}  p_X(x) =
\int_B dP_X(x),
\]
%
lo que da, tratando de la funci\'on de repartici\'on,
%
\[
F_X(x) = \sum_{x_j \le x} p_X(x_j).
\]
%
De  esta forma,  se justifica  la  denominaci\'on {\it  cumulativa} para  $F_X$.
Tambi\'en, se puede ver inmediato de que $F_X$ es una funci\'on discontinua, con
saltos finitos (en  $x_j$, salto de altura $p_X(x_j)$).  Eso es ilustrado figura
Fig.~\ref{fig:MP:ProbaDiscreta}-(b).

\begin{figure}[h!]
\begin{center} \input{TIKZ_MP/DistribucionReparticionDiscreta} \end{center}
%
\leyenda{Ilustraci\'on de una distribuci\'on  de probabilidad discreta (a), y la
  funci\'on de repartici\'on asociada (b), con $\X  = \big\{ \, 1 \, , \, \sqrt3
  \, ,  \, \sqrt5  \, , \,  \sqrt7 \,  , \, \sqrt{11}  \, \big\}$ \  y \  $p_X =
  \protect\begin{bmatrix}  \frac18  & \frac14  &  \frac16  &  \frac18 &  \frac13
    \protect\end{bmatrix}^t$.}
\label{fig:MP:ProbaDiscreta}
\end{figure}

Un caso especial se tiene cuando un  valor $x_k$ es cierto o seguro, y no ocurre
ninguno de los  otros valores $x_j \  (j \ne k)$. La forma  de la distribuci\'on
es: \ \modif{$p_X(x) =  1$ \ si \ $x = x_k$  \ y cero si no, } \  o el vector de
probabilidad  se escribir\'a  \ $p_X  = \un_k$  donde $\un_k$  denotar\'a  es el
vector  (posiblemente de dimensi\'on  infinita) de  componentes \modif{$k$-esima
  igual a  1, las  otras siendo  nulas, lo que  se denota  tambi\'e con  el {\it
    s\'imbolo de Kronecker} \ $\delta_{jk} = 1$ \ si \ $j = k$ \ y cero sino. En
  este libro, evitaremos  usar este s\'imbolo para no  confundirlo con la medida
  de Dirac. Sin embargo,  aparece de que \ $P_X$ \ es  precisamente la medida de
  Dirac en \ $x_k$ (ver definici\'on Def.~\ref{Def:MP:Dirac}).}


Otra   situaci\'on  particular   es  la   de  {\it   equiprobabilidad}   o  {\it
  distribuci\'on uniforme}  cuando $|\X|  = \alpha <  +\infty$.  La forma  de la
distribuci\'on es: \ $p_X(x_j) = \frac1\alpha \quad  \forall \, j = 1 , \ldots ,
\alpha$,    \ie   $p_X    =    \begin{bmatrix}   \frac1\alpha    &   \cdots    &
  \frac1\alpha \end{bmatrix}^t$ \  o, en termino de medida,  $P_X = \frac1\alpha
\sum_{j=1}^\alpha  \delta_{x_j}$.   La funci\'on  de  repartici\'on resulta  una
funci\'on escalonada, con saltos de  altura \ $\frac1\alpha$ en cada $x_j, \quad
1 \le j \le \alpha$.

De manera general, la medida de probabilidad de una variable discreta se escribe
como combinaci\'on convexa de medidas de Dirac,
%
\[
P_X = \sum_j p_j \delta_{x_j}, \qquad p_j = P(X=x_j) \ge 0, \quad \sum_j p_j = 1, 
\]
%
\modif{\ie como una medida\ldots discreta.}

\

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\SZ{Reordenamiento y relaci\'on de mayorizaci\'on  : a ver como trasladar lo que
  ya estaba en en cap.  2 mas los ejemplos, pagina~\pageref{def:SZ:Mayorizacion}
  (cf  pagina~\pageref{prop:SZ:permutacion}).  Todo  tal  cual por  ahora,  pero
  ser\'ia la parte azul a cambiar.}

\aver{
Para comparar dos  distribuciones es \'util reordenar el  vector de probabilidad
permutando  sus  elementos  hasta  listarlos  de forma  descendente.   Se  anota
$p^\downarrow$, de  modo que \  $p^\downarrow_1 \geq p^\downarrow_2  \geq \ldots
\geq  p^\downarrow_N$.   En  el  ejemplo   del  caso  con  certeza  se  tiene  \
$p^\downarrow =  \begin{pmatrix} 1 & 0  & \cdots &  0 \end{pmatrix}^t$, mientras
que la distribuci\'on uniforme no var\'ia.

Se  define  \emph{mayorizaci\'on} del  siguiente  modo,  para distribuciones  de
dimensi\'on  $N$ (con  sus elementos  acomodados  en forma  decreciente): \  una
distribuci\'on $p$  es mayorizada por otra $q$,  y se denota $p\prec  q$, si las
primeras $N-1$  sumas parciales de $p^\downarrow$ y  $q^\downarrow$ satisfacen \
$\sum_{i=1}^n  p^\downarrow_i   \leq  \sum_{i=1}^n  q^\downarrow_i$   para  todo
$n=1,\ldots,N-1$, con \ $\sum_{i=1}^N p_i = 1 = \sum_{i=1}^N q_i$.

Por    ejemplo,   $\begin{pmatrix}    \frac12    &   \frac14    &   \frac18    &
  \frac18 \end{pmatrix}^t  \prec \begin{pmatrix} \frac12  & \frac14 &  \frac14 &
  0 \end{pmatrix}^t$.  Es posible  comparar por mayorizaci\'on distribuciones de
distinta  dimensionalidad, completando con  ceros el  vector de  probabilidad de
menor  dimensi\'on.  Es  importante  resaltar que  la  mayorizaci\'on provee  un
\emph{orden  parcial}  (no  total)  entre distribuciones,  existiendo  pares  de
distribuciones   tales  que   ninguna  mayoriza   a  la   otra.    Por  ejemplo,
$\begin{pmatrix} 0.50 &  0.40 & 0.10 \end{pmatrix}^t$ y  $\begin{pmatrix} 0.70 &
  0.15 & 0.15 \end{pmatrix}^t$ no se comparan por mayorizaci\'on.

Es  interesante  notar  que  la   siguiente  propiedad  es  v\'alida  para  toda
distribuci\'on $p$ de tama\~no~$N$:
%
$$
\begin{pmatrix} \frac1N & \frac1N & \cdots & \frac1N \end{pmatrix}^t \ \prec \ p
\ \prec \ \begin{pmatrix} 1 & 0 & \cdots & 0 \end{pmatrix}^t.
$$
%
En este  sentido, los  casos particulares de  equiprobabilidad y de  certeza, se
dice  que  son  distribuciones  extremas.  Notamos que  uno  implica  ignorancia
m\'axima  en el  resultado de  la variable  mientras que  el otro  corresponde a
conocimiento completo.
%% graficamente 
%
\begin{figure}[h!] %%ojo numeracion de figs !
%\centerline{\includegraphics[width=3cm]{majorizationplot.pdf}} %%rehacer
%
\leyenda{Orden parcial por mayorizaci\'on}
\label{fig:majorizationplot}
\end{figure}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



% ================================= Continua

\subseccion{Variable aleatoria continua}
\label{sec:MP:VAContinua}

En  varios contextos,  puede  tomar valores  en  un conjunto  no numerable,  por
ejemplo cualesquiera de los n\'umeros en un dado intervalo de la recta real.  No
son variables  discretas m\'as. En las  variables que no son  discretas, el caso
particular de inter\'es es el de variables continuas~\cite{AthLah06, HogMck13}:
%
\begin{definicion}[Variable aleatoria continua]
  Una variable  aleatoria \  $X$ \ es  dicha {\it  continua} si su  funci\'on de
  repartici\'on  $F_X$ es  continua sobre  $\Rset$.
\end{definicion}

Cuando  se  puede,  es  conveniente  asociar  una  {\it  funci\'on  densidad  de
  probabilidad} (com\'unmente  anotada por  su sigla en  ingl\'es: pdf  por {\it
  probability   density   function}).   Por   eso,   nos   apoyamos   sobre   la
definici\'on~\ref{def:MP:DensidadMedida}  aplicada a  la medida  de probabilidad
$P_X$:
%
\begin{definicion}[Variable aleatoria admitiendo una densidad de probabilidad]
  Sea $X$ variable  aleatoria continua y \ $P_X$ su  medida de probabilidad. Por
  definici\'on, se dice que $X$  admite una densidad de probabilidad con respeto
  a   una  medida   $\mu$  sobre   $\Rset$  si   $P_X  \ll   \mu$   (teorema  de
  Radon-Nikod\'ym~\ref{Th:MP:RadonNikodym}).\newline En  general, nos enfocamos
  sobre la  medida (dicha de referencia)  $\mu = \mu_L$ de  Lebesgue y denotando
  $d\mu_L(x) \equiv dx$, la definici\'on se reduce a: Si existe una funci\'on no
  negativa \ $p_X$ \ medible sobre $\Rset$ tal que
  %
  \[
  \forall \, B \in \B(\Rset), \quad P_X(B) = \int_B p_X(x) \, dx,
  \]
  %
  entonces $X$  es dicha {\it  admitiendo una densidad}  y \ $p_X$ \  es llamada
  {\it densidad de probabilidad} de  $X$ (subentendido ``con respeto a la medida
  de Lebesgue'').  Notando de que $P_X(B) = P_X(B \cap \X)$, el soporte de $p_X$
  es necesariamente $\X = X(\Omega)$ (\ie $p_X(\widebar{\X}) = 0$ \ y \ $p_X(\X)
  \ne 0$), y
  %
  \[
  \forall \, B \in \B(\Rset), \quad P_X(B) = \int_{B \cap \X} p_X(x) \, dx.
  \]
  %
  Tratando de la funci\'on de repartici\'on \ $F_X$, tenemos entonces
  %
  \[
  F_X(x) = \int_{-\infty}^x p_X(u) \, du
  \]
  %
  (queda valid con cualquier medida $\mu$, densidad con respeto a esta medida de
  referencia,  e integraci\'on  sobre $(-\infty;  x]$ con  la  ``diferencial'' \
  $d\mu(x)$).  Dicho  de otra manera, si  $F_X$ es (continua  y) derivable sobre
  $\Rset$, por lo menos por partes, $X$ admite una densidad de probabilidad (con
  respeto a  la medida de Lebesgue)  y~\footnote{Recuendense que, rigurosamente,
    la igualdad debe ser entendido ``casi siempre''.}
  %
  \[
  p_X(x) = \frac{d F_X(x)}{dx}.
  \]
  %
  Por abuso  de terminologia,  en lo que  sigue llamaremos $p_X$  tambi\'en {\it
    distribuci\'on de  probabilidad}, a pesar de  que no tiene  el mismo sentido
  que la masa de probabilidad del  caso discreto y denotaremos $|\X|$ el volumen
  (o medida de Lebesgue) de $\X$, posiblemente infinito.
\end{definicion}
%
La  escritura  integral de  $F_X$  justifica  de  nuevo la  denominaci\'on  {\it
  cumulativa} para  $F_X$. Adem\'as, se puede  ver por ejemplo que  en este caso
$\displaystyle P(a < X \le b) = \int_a^b p_X(x) \, dx = F_X(b) - F_X(a)$ \ y que
claramente
%
\[
\forall x \in \Rset, \quad P_X(\{x\}) = P(X = x) = 0.
\]
%
$\{ x \}$  es de medida $P_X$ nula  (es el caso de todos  conjuntos numerable de
$\Rset$).

Fijense de  que si  $0 \le  F_X \le  1$, \ $p_X$  puede ser  mayor que  uno. Por
ejemplo, para \ $F_X(x) = 2 \, x  \, \un_{\left[ 0 \, ; \, \frac12 \right)}(x) +
\un_{\left[ \frac12 \,  ; \, +\infty \right)}(x)$, que  define correctamente una
funci\'on  de  repartici\'on,  \  $p_X(x)  =  2  \un_{\left[  \frac12  \,  ;  \,
    +\infty\right)}(x)$. No es  contradictorio en el sentido de  que $p_X$ no es
una probabilidad, sino  que $p_X(x) \, dx$ puede ser  visto como la probabilidad
de hallar a la variable con  valores en el ``intervalo infinitesimal entre $x$ y
$x+dx$''.  Al final, la condici\'on de normalizaci\'on se escribe
%
\[
\int_\X p_X(x) \, dx = \int_\Rset p_X(x) \, dx = 1. 
\] 
%

En la figura Fig.~\ref{fig:MP:ProbaContinua}-(a) se muestra una representaci\'on
gr\'afica de una  funci\'on densidad de probabilidad para  una variable continua
admitiendo una  densidad, y en  Fig.~\ref{fig:MP:ProbaContinua}-(b) la funci\'on
cumulativa correspondiente.
%
\begin{figure}[h!]
\begin{center} \input{TIKZ_MP/DistribucionReparticionContinua} \end{center}
%
\leyenda{Ilustraci\'on de una distribuci\'on  de probabilidad continua (a), y la
  funci\'on de repartici\'on asociada (b), con \ $\X  = [0 \, ; \, 1) \cup [2 \,
  ;  \,  3)$  \  y \  $p_X(x)  =  \frac12  \un_{[0  \,  ; \,  1)}(x)  +  \frac{3
    \sqrt{x-2}}{4} \un_{[2  \, ; \,  3)}(x)$, \ \ie  \ $F_X(x) =  \frac{x}{2} \,
  \un_{[0   \,   ;  \,   1)}(x)   +   \frac12  \un_{[1   \,   ;   \,  2)}(x)   +
  \frac{(x-2)^{\frac32}}{2}  \un_{[2  \,   ;  \,  3)}(x)  +  \un_{[3   \,  ;  \,
    +\infty)}(x)$.  }
\label{fig:MP:ProbaContinua}
\end{figure}

Fijense   de  que   una   variable   aleatoria  puede   ser   ni  continua,   ni
discreta\modif{, como ilustrado en el ejemplo siguiente}
%
\begin{ejemplo}[Ejemplo de variable mixta]\label{Ej:MP:Mixta}
  Sean  $U$ \  y \  $V$ \  variables continuas,  independientes, de  densidad de
  probabilidad \ $p_U  = p_V = \un_{[0 \,  ; \, 1)}$ \ ($U$  \ y \ $V$  \ son dichas
  uniformes sobre $[0 \, ;  \, 1)$) \ y sea \ $X = V  \un_{U < \frac12} + \un_{U
    \ge \frac12}$,  \ es  decir \ $X(\omega)  = V(\omega)$  \ si \  $U(\omega) <
  \frac12$ \ y \ $1$ \ si no.  Entonces de la f\'ormula de probabilidades totales,
  \ $F_X(x) = P(X  \le x) = P\left( (X \le x) \left|  \left( U < \frac12 \right)
    \right.  \right) \,  P\left( U < \frac12  \right) \, + \, P\left(  (X \le x)
    \left|  \left( U  \ge  \frac12 \right)  \right.   \right) \,  P\left( U  \ge
    \frac12 \right) $ \ \ie \ $F_X(x)  = \frac12 P\left( (V \le x) \left| \left(
        U <  \frac12 \right) \right.  \right) \,  + \, P\left( (1  \le x) \left|
      \left( U \ge \frac12 \right)\right. \right)$. \ Ahora, de la independencia
  de \ $U$ \ y \ $V$, \  tenemos \ $F_X(x) = \frac12 F_V(x) + \frac12 \un_{[1 \,
    +\infty)}(x)$ \ es decir
  %
  \[
  F_X(x) = \frac{x}{2} \un_{[0 \, ; \, 1)}(x) + \un_{[1 \, ; \, +\infty)}(x).
  \]
  %
  Esta     funci\'on     de     repartici\'on     es     representada     figura
  Fig.~\ref{fig:MP:ProbaMixta}: es ni discreta,  ni continua.  Entonces, a pesar
  de que $\X = [0 \, ; \, 1]$  \ sea un intervalo, $X$ no es continua (y tampoco
  no puede ser discreta).
  %
  \begin{figure}[h!]
  \begin{center} \input{TIKZ_MP/ReparticionMixta} \end{center}
  %
  \leyenda{Funci\'on  de repartici\'on  $F_X(x) =  \frac{x}{2} \un_{[0  \,  ; \,
      1)}(x)  + \un_{[1  \, ;  \, +\infty)}(x)$  asociada a  \ $X  = V  \un_{U <
      \frac12}  + \un_{U  \ge  \frac12}$ \  con  \ $U$  \ y  \  $V$ \  variables
    continuas uniformes sobre $\X  = [0 \, ; \, 1)$.  No  es tipo escalon, as\'i
    que $X$  no es  discreta. A  pesar de  que $\X =  [0 \,  ; \,  1]$ \  sea un
    intervalo,  de  la presencia  del  salto  en $x  =  1$,  tampoco  $X$ no  es
    continua.}
  \label{fig:MP:ProbaMixta}
  \end{figure}
  %
\end{ejemplo}
%\item Sea  $U$ \ variable  continua uniforme sobre $[0  \, ; \,  1)$ \ y \  $X =
%  \un_{U \not\in \Qset}$. Claramente  $X$ no es continua, pero $\X =  [0 \, ; \,
%  1)   \backslash    \Qset$   \   siendo   no   numerable,    $X$   tampoco   es
%  discreta~\footnote{\SZ{$X = 1$ casi siempre\ldots quizas m\'as adelante}}.
%\end{itemize}


\modif{Volvemos a las variables  discretas \ $X$ \ sobre $\X =  \{ x_j \}_j$, de
  medida   de    probabilidad   de    la   forma   \    $P_X   =    \sum_j   p_j
  \delta_{x_j}$.   Considerando  la   medida   discreta  \   $\mu_\X  =   \sum_j
  \delta_{x_j}$,  es claro  de que  \ $P_X  \ll \mu_\X$.  Entonces, formalmente,
  $P_X$ admite  una densidad con  respeto a la  medida discreta $\mu_\X$  y esta
  densidad, definida sobre $\X$  es $p_X(x) = P(X = x)$. A  pesar de que sea una
  tautolog\'ia, este justifica  de que usamos la escritura  $p_X$ (minuscula) en
  el caso  discreto como en  el caso  continuo, y de  que hablamos (por  abus de
  terminolog\'ia) de distribuci\'on de probabilidad en ambos caso.}

Recordamonos de  que cualquier  medida de probabilidad  (caso continuo o  no) se
escribe tambi\'en con una integral \ $\displaystyle P_X(B) = \int_B dP_X(x)$ \ y
que en el caso discreto cierto \ $X = x_k$, \ la medida de probabilidad $P_X$ es
la medida de  Dirac. A veces, por  abuso de escritura \ $dP_X(x)$  es denotado \
$\delta_{x_k}(x) \,  dx$ \ o \ $\delta(x-x_k)  \, dx$ \ donde  ahora $\delta$ es
llamada {\it distribuci\'on (delta) de Dirac}.  Se puede ver este Dirac como una
densidad de  probabilidad $p_X(x)$ \modif{con  respeto a la medida  de Lebesgue}
pero no  es una funci\'on ``ordinaria''  dando de que $P_X$  no es diferenciable
con respeto a la medida de Lebesgue.  Se la llama {\it funci\'on generalizada} o
{\it  distribuci\'on  de Schwartz}~\footnote{La  teor\'ia  de la  distribuciones
  vali\'o a Laurent Schwarz la medalla Field en 1950.  Entre otros en el trabajo
  de Schwartz, se prob\'o que el Dirac, visto como distribuci\'on de Schwartz, o
  funci\'on   generalizada,   tiene    una   ``representaci\'on   integral''   \
  $\displaystyle \delta(x) =  \frac{1}{2\pi} \int_{-\infty}^{\infty} e^{\imath t
    x} dt$ \  o m\'as rigurosamente transformada de Fourier de  $x \mapsto 1$ en
  el  sentido de  las  funciones generalizadas  o  distribuciones.  Eso  muestra
  claramente  su caracter  no ordinario  (la  integral siendo  divergente en  el
  sentido usual).  Eso va m\'as all\'a de  la meta del cap\'itulo y el lector se
  podr\'a  referir   a~\cite{Sch66,  GelShi64,  GelShi68}   por  ejemplo.}.   En
particular,   $F_X(x)  =   \un_{\Rset_+}(x-x_k)$  y   en  el   sentido   de  las
distribuciones, $\frac{d F_X}{dx} = \delta_{x_k}$.  Adem\'as, se usan en general
las propiedades, para cualquier function \ $f$ \ y real \ $x_0$,
%
\[
f(x) \delta(x-x_0) = f(x_0) \delta(x-x_0) \qquad \mbox{y} \qquad \int_\Rset f(x)
\delta(x-x_0) \, dx = f(x_0),
\]
%
pero hay que entender la integraci\'on a trav\'es de la medida Dirac (insistamos
en   el   hecho   de  que   esta   notaci\'on   es   un  abuso   de   escritura,
ej.~\cite{GelShi64}).  Usando las distribuciones  de Dirac, se puede unificar el
tratamiento de las  variables aleatorias discretas con las  continuas en termino
de  densidad \modif{(con  respeto a  la medida  de Lebesgue)}:  si  una variable
aleatoria discreta toma los valores \ $x_j$  \ con probabilidades \ $p_j = P(X =
x_j)$ \  respectivamente, entonces formalmente  se puede describir  mediante una
variable aleatoria continua \ $X$ \ con ``funci\'on densidad de probabilidad'' \
$p_X(x) =  \sum_j p_j  \, \delta(x-x_j)$. \modif{Insistamos  en el hecho  de que
  rigurosamente  debemos trabajar  con  medidas, como  lo  hemos formalizado  al
  principio de este cap\'itulo.}


% ================================= Vector discreto

\subseccion{Vector aleatorio discreto}
\label{sec:MP:VecDiscreto}

Un ejemplo de vector aleatorio discreto puede verse a trav\'es de un conjunto de
dados (que podr\'ian  ser dependientes si son ligados por  un hilo por ejemplo).

\begin{definicion}[Vector aleatorio discreto]
  Un  vector aleatorio $d$-dimensional  \ $X  = \begin{bmatrix}  X_1 &  \cdots &
    X_d  \end{bmatrix}^t$   \  y  \   $\displaystyle  \X  =   X(\Omega)  \subset
  \optimes_{i=1}^d \X_i$ \  donde \ $\X_i = X_i(\Omega)$. \ $X$  \ es dicho {\it
    discreto} cuando  $\X \subseteq \Nset^d$,  \ es discreto, finito  o infinito
  numerable.  En lo  que sigue, denotaremos tambi\'en por  $|\X|$ el cardinal de
  $\X$, posiblemente infinito.
\end{definicion}

Obviamente, la  medida de probabilidad  en los $\displaystyle  x = (x_1 \,  , \,
\ldots \, , \, x_d)  \in \optimes_{i=1}^d \X_i$ \ caracterisa completamente este
vector aleatorio:
%
\begin{definicion}[Funci\'on de masa de probabilidad conjunta]
  Por  definici\'on,  la  funci\'on  de  masa de  probabilidad  de  $X$,  vector
  aleatorio discreto tomando sus valores sobre $\X \subset \optimes_i \X_i$ \ es
  dada por
  %
  \[
  p_X(x) \equiv  P(X =  x) =  P\left( \bigcap_{i=1}^d \left(  X_i =  x_i \right)
  \right) \quad \forall \, x_i \in \X_i, \: 1 \le i \le d.
  \]
  %
  Se la llama  tambi\'en {\it funci\'on de masa de  probabilidad conjunta de los
    $X_i$}, o, por  abuso de denominaci\'on, la llamaremos  todav\'ia $p_X$ {\it
    distribuci\'on  de probabilidad  (conjunta)}.   Fijense de  que  $\X$ no  es
  necesariamente igual al  producto cartesiano de los $\X_i$,  siende de que una
  probabilidad  conjunta en  este producto  puede ser  nula.\newline En  el caso
  multivariado, la notaci\'on vectorial es  m\'as delicada a usar: $p_X$ ser\'ia
  un ``tensor''  $d$-dimensional (una matriz  para $d = 2$,\ldots).   Pero queda
  posible usar una notaci\'on vectorial, recordandose de que $\Nset^d$ puede ser
  en biyecci\'on  con $\Nset$ y  una biyecci\'on elegida, usarla  para etiquetar
  los componentes  de $p_X$ puesto en  vector.  En el  caso finito \ $\X_i  = \{
  x_{j_i} \}_{j=1}^{\alpha_i}$ \ con \ $\alpha_i = |\X_i| < +\infty$, \ se puede
  organizar  los  componentes tales  que  $p_X(x_{j_1}\, ,  \,  \ldots  \, ,  \,
  x_{j_d})$  sea   la  $\displaystyle  j   =  \sum_{i=1}^{d-1}  (j_i  -   1)  \,
  \prod_{k=i+1}^d \alpha_k \, + \, j_d$-esima componente del vector $p_X$.
%   \  con  \   $\displaystyle  \prod_{k=0}^1  \equiv  1$   \  por
%  convenci\'on.
\end{definicion}
%
\noindent \modif{De nuevo, $p_X$ puede ser  vista como densidad con respeto a la
  medida discreta $\mu_\X$, Def.~\ref{Def:MP:Dirac}.}

Como en  el caso escalar, la  funci\'on de repartici\'on de  un vector aleatorio
discreto $d$-dimensional es echo de hyperplanos $d$-dimensionales constantes.
% , \ie  $F_X$ es constante sobre  $[x_{(j-1)_1} \, , \,  x_{j_1}) \times \cdots
% \times [x_{(j-1)_d} \, , \, x_{j_d})$
Adem\'as, las  componentes son mutuamente  independientes si y solamente  si la
funci\'on de  r\'epartici\'on se factoriza,  o equivalentemente la  funci\'on de
masa se factoriza, \ie
%
\[
X_i  \:  \mbox{mutuamente independientes}  \quad  \Leftrightarrow  \quad p_X  =
p_{X_1} \ldots  p_{X_d}.
\]
%
En notaciones tensoriales, $p_X =  p_{X_1} \otimes \cdots \otimes p_{X_d}$ donde
$\otimes$  denota  el  producto  tensorial  o  externo  entre  los  vectores  de
probabilidades~\footnote{``Tensor''      $d$-dimensional      de     componentes
  $(j_1,\ldots,j_d)$  el  producto $\prod_i  p_{X_i}  (x_{j_i})$.}.  Cuando  los
$\alpha_i$ son finito y la  notaci\'on vectorial de la definici\'on es adoptada,
esta  expresi\'on  queda  valide  donde  $\otimes$  representa  el  producto  de
Kronecker~\footnote{Para   \    $p   =   \begin{bmatrix}   p_1    &   \cdots   &
    p_n  \end{bmatrix}^t$   \  y  \  $q   =  \begin{bmatrix}  q_1   &  \cdots  &
    q_m \end{bmatrix}^t$ \ el producto de  Kronecker es dado por \ $p \otimes q$
  \ vector de tama\~no $n m$ de componente \ $(j-1) m + k$-esima \ el producto \
  $p_j  q_k, \quad 1  \le j  \le n,  \: 1  \le k  \le m$.   Fijense de  que este
  producto es asociativo pero no es comutativo.\label{foot:MP:Kronecker}}.

Al  final, de la  f\'ormula de  calculo de  funci\'on de  repartici\'on marginales
visto  pagina~\pageref{pagina:MP:MarginalesF},   para  un  subconjunto   $I_k  =
(i_1,\ldots,i_k)$ de  $1 \le k  \le d$ elementos  de $\{ 1  , \ldots ,  d \}^k$,
$X_{I_k}  =  \begin{bmatrix}  X_{i_1}  &  \cdots  &  X_{i_k}\end{bmatrix}^t$  la
probabilidad marginal o distribuci\'on marginale de $X_{I_k}$ es dada por
%
\[
p_{X_{I_k}}(x_{I_k}) = \sum_{\forall i \not\in I_k, x_i \in \X_i} p_X(x).
\]



% ================================= Vector continuo

\subseccion{Vector aleatorio continuo}
\label{sec:MP:VecContinuo}

Como para  el caso  de una  variable, se puede  considerar cualquiera  medida de
referencia  $\mu$  sobre  $\Rset^d$   para  definir  una  noci\'on  de  densidad
($d$-variada),  pero  en general  nos  enfocamos  en el  caso  de  la medida  de
Lebesgue.

\begin{definicion}[Vector aleatorio continuo y densidad de probabilidad multivariada]
  Un  vector aleatorio  \  $X$ \  es dicho  {\it  continuo} si  su funci\'on  de
  repartici\'on  $F_X$ es  continua sobre  $\Rset^d$.  Como  en el  caso escalar
  tambi\'en,   por  definici\'on~\ref{def:MP:DensidadMedida}  (y   la  reciproca
  evocaca al  seguir), se dice que  $X$ admite una densidad  de probabilidad con
  respeto a  una medida $\mu$ sobre $\Rset^d$  si $P_X \ll \mu$.   De nuevo, nos
  enfocamos  sobre la medida  (dicha de  referencia) $\mu  = \mu_L$  de Lebesgue
  as\'i  que si  existe una  funci\'on  no negativa  y medible  \ $p_X:  \Rset^d
  \mapsto \Rset$ \ tal que
  %
  \[
  \forall \,  B \in \B(\Rset^d),  \quad P_X(B) =  \int_B p_X(x) \, dx  = \int_{B
    \cap \X} p_X(x) \, dx
  \]
  %
  con $\X  = X(\Omega)$ soporte  de \ $p_X$  \ y \  $d\mu_L(x) \equiv dx  = dx_1
  \cdots dx_d$, entonces  $X$ es dicha {\it admitiendo una  densidad} y $p_X$ es
  llamada {\it densidad de probabilidad} de \ $X$ (`subentendido ``con respeto a
  la medida de Lebesgue''), o  tambi\'en {\it densidad de probabilidad conjunta}
  de los \ $X_i$. En particular,
  %
  \[
  F_X(x) =  \int_{\optimes_{i=1}^d (-\infty \, ;  \, x_i]} p_X(u) \, du
  \]
  %
  o, equivalentemente,  para $F_X$ (continua  y) derivable sobre  $\Rset^d$ (con
  respeto a la medida de Lebesgue), por lo menos por partes,
  %
  \[
  p_X(x) = \frac{\partial^d F_X(x)}{\partial x_1 \cdots \partial x_d}.
  \]
  %
  Usaremos  todav\'ia la terminolog\'ia  (por abuso)  de {\it  distribuci\'on de
    probabilidad} y  denotaremos todav\'ia  \ $|\X|$ \  el volumen (o  medida de
  Lebesgue) de \ $\X$, posiblemente infinito.
\end{definicion}

Como en el caso  escalar, $p_X \ge 0$ \ no es necesario  menor que 1 y satisface
la condici\'on de normalizaci\'on
%
\[
\int_\X p_X(x) \, dx = \int_{\Rset^d} p_X(x) \ dx  = 1.
\]

Mencionamos de que las $d$  variables aleatorias $X_1, \ldots, X_d$, componentes
de un vector aleatorio $X$ son  independientes si y solamente si se factoriza la
funci\'on de repartici\'on, lo que da derivando esta,
%
\[
X_i \:  \mbox{ mutuamente independientes} \quad \Leftrightarrow  \quad p_X(x) =
p_{X_1}(x_1) \ldots p_{X_d}(x_d).
\]


Terminamos esta secci\'on mencionando que, de la f\'ormula de calculo de funci\'on
de  repartici\'on marginales vista  pagina~\pageref{pagina:MP:MarginalesF}, para
un subconjunto $I_k = (i_1,\ldots,i_k)$ de $1  \le k \le d$ elementos de $\{ 1 ,
\ldots   ,  d   \}^k$,   $X_{I_k}   =  \begin{bmatrix}   X_{i_1}   &  \cdots   &
  X_{i_k}\end{bmatrix}^t$  la   {\it  densidad  de   probabilidad  marginal}  de
$X_{I_k}$ es dada por
%
\[
p_{X_{I_k}}(x_{I_k})  = \int_{\times_{i  \not\in  I_k} \X_i}  p_X(x) \,  \prod_{i
    \not\in I_k}  dx_i =  \int_{\Rset^{d-k}} p_X(x) \,  \prod_{i \not\in
      I_k} dx_i.
\]
%
En particular, la funci\'on densidad  de probabilidad marginal que caracteriza a
la variable aleatoria  $X_i$ es la ley que se obtiene  integrando la densidad de
probabilidad conjunta sobre todas las variables excepto la $i$-\'esima.

\

\SZ{Reordenamiento y relaci\'on de mayorizaci\'on  : a ver como trasladar lo que
  ya estaba  en en cap.  2 mas los  ejemplos, paginas~\pageref{def:SZ:rearreglo}
  y~\pageref{def:SZ:MayorizacionC}.}


% ================================= Transformacion

\subseccion{Transformaci\'on de variables y vectores aleatorios}
\label{sec:MP:Transformacion}

En  esta  secci\'on nos  interesamos  al  effect de  una  variable  o un  vector
aleatorio. Por  ejemplo, en un juego con  dos dados, nos podemos  interesar a la
ley de la suma que dar\'ia el n\'umero de casilla de que debemos adelantar en un
juego de la oca.
%
\begin{teorema}[Transformaci\'on medible de un vector aleatorio]
  Sea  \  $X:  (\Omega,\A)  \mapsto  (\Rset^d ,  \B(\Rset^d))$  \  una  variable
  aleatoria,   y  \   $g:  (\Rset^d   ,  \B(\Rset^d))   \mapsto   (\Rset^{d'}  ,
  \B(\Rset^{d'}))$ \  una funci\'on  medible. Entonces,  \ $Y =  g(X)$ \  es una
  variable aleatoria  \ $(\Omega,\A)  \mapsto (\Rset^{d'} ,  \B(\Rset^{d'}))$. \
  Adem\'as, la medida imagen \ $P_Y$ \ es vinculada \ a \ $P_X$ \ por
  %
  \[
  \forall \, B \in \B(\Rset^{d'}), \quad P_Y(B) = P_X(g^{-1}(B)).
  \]
\end{teorema}
%
\begin{proof}
  Este resultado es obvio. $g$ siendo medible, para todo $B \in \B(\Rset^{d'})$,
  por definici\'on $g^{-1}(B) \in \B(\Rset^d)$.  Adem\'as, si $P_X$ es la medida
  (de  probabilidad) asociado  al  espacio de  salida  de $g$,  el resultado  es
  consecuencia  del   teorema  de  la   medida  imagen~\ref{Th:MP:MedidaImagen},
  pagina~\pageref{Th:MP:MedidaImagen}.
\end{proof}
%
\noindent (Ver ej.~\cite{JacPro03, AthLah06, Bog07:v2, Coh13}).


Es sencillo  probar de que  cualquier combinaci\'on de funciones  medibles queda
medible, cualquier  producto (adecuado) de  functiones medible queda  medible, y
que si $\{ f_k \}_{k=1}^{d'}$ son $(\B(\Rset^d),\B(\Rset))$-medible, entonces $f
=          (f_1         ,          \ldots         ,          f_{d'})$         es
$(\B(\Rset^d),\B(\Rset^{d'}))$-medible~\cite{AthLah06}.

% \SZ{No se  todav\'ia si ser\'a \'util  tratar del caso de limite  de series de
%   funciones medibles.}


Mencionamos  de que si  $\X =  X(\Omega)$ es  discreto, entonces  $\Y =  g(\X) =
Y(\Omega)$ ser\'a discreto tambi\'en, y:
%
\begin{teorema}[Funci\'on de masa por transformaci\'on medible]
  Sean   $X$,   vector  aleatorio   $d$-dimensional   discreto,  $g:(\Rset^d   ,
  \B(\Rset^d)) \mapsto (\Rset^{d'} , \B(\Rset^{d'}))$ una funci\'on medible, e \
  $Y =  g(X)$ necesariamente discreto  $d'$-dimensional sobre $\Y =  g(\X)$.  La
  distribuci\'on de $Y$ es relacionada a la de $X$ por la relaci\'on
  %
  \[
  \forall \, y \in \Y, \quad p_Y(y) = \sum_{x \in g^{-1}(y)} p_X(x).
  \]
\end{teorema}
%
\begin{proof}
El resultado es inmediato.
\end{proof}
%
\noindent En particular,  si $g$ es inyectiva (necesariamente  biyectiva de $\X$
en $\Y$),  el vector  de probabilidad queda  invariante, $p_Y =  p_X$; solamente
cambian los estados.

Es  importante mencionar de  que con  $\Y$ discreto,  $\X$ no  es necesariamente
discreto~\cite{AthLah06}. Por ejemplo, $Y = \un_{X>0}$  es tal que $\Y = \{ 0 \,
; \, 1 \}$ a pesar de que $\X$ puede ser no discreto.

Tratar de las variables aleatorias  continuas resuelta mas delicado. Vimos en el
ejemplo   precediente  de   que  el   caracter  continuo   puede   perderse  por
transformaci\'on. De la misma manera, en un ejemplo de la secci\'on precediente,
vimos  que  $Y =  X_1  \un_{X_2>0}$ con  $X_i$  independientes  uniformes es  ni
continua,  ni  discreta.  En  el  enfoque  de  variables  continuas,  una  clase
importante  de funciones  en la  cual  no vamos  a interesar  son las  funciones
continuas (y diferenciables):
%
\begin{lema}[Continuidad y caracter medible]
  Sea   $g:   \Rset^d   \mapsto   \Rset^{d'}$   continua.   Entonces,   $g$   es
  $(\B(\Rset^d),\B(\Rset^{d'}))$-medible.
\end{lema}
%
\begin{proof}
  Por continuidad,  la pre-imagen de  un abierto de  $\Rset^{d'}$ por $g$  es un
  abierto  de $\Rset^d$  y entonces  es en  $\B(\Rset^d)$. La  prueba  se cierra
  recordandose  de  la   definici\'on  de  $\B(\Rset^{d'})$,  $\sigma$-\'algebra
  generada por los abiertos de $\Rset^{d'}$.
\end{proof}

En lo  que sigue, nos interesamos  m\'as especialmente al caso  de funciones $g:
(\Rset^d ,  \B(\Rset^d)) \mapsto (\Rset^d ,  \B(\Rset^d))$.  De hecho,  si $d' <
d$,   es    sencillo   llegar   al   caso    considerado   a\~nandiendo   $d-d'$
transformaciones. Por ejemplo, con $d = 2$  si nos interesamos a $X_1 + X_2$, se
puede considerar $\begin{bmatrix} X_1 + X_2 & X_2 - X_1\end{bmatrix}^t$ y llegar
a la variable de  inter\'es por calculo de marginal. Si $d'  > d$ la situaci\'on
es  m\'as  delicada,  $g(Y)$  viviendo  sobre una  variedad  $d$-dimensional  de
$\Rset^{d'}$.

En  el caso  de vectores  aleatorios continuos  $X$ admitiendo  una  densidad de
probabilidad,  una pregunta  natural  es entonces  de  saber si  se conserva  la
continuidad y la existencia de una densidad, as\'i que su forma. La respuesta es
dada por el teorema siguiente~\cite{Bre88, JacPro03, AthLah06, Coh13, HogMck13}:
%
\begin{teorema}[Densidad de probabilidad por transformaci\'on continua inyectiva diferenciable]
  Sean $X$, vector aleatorio  $d$-dimensional continuo y admitiendo una densidad
  de probabilidad  $p_X$, \ $g:\Rset^d  \mapsto \Rset^d$ una  funci\'on continua
  inyectiva y diferenciable tal que
  %  ~\footnote{\modif{De  hecho,  se   puede  extender  el  resultado  para  un
  %      determinente del  Jacobiano cancelandose  en  un conjunto  de punto  de
  %     medida  de Lebesgue nula y en  los $y$ donde se  cancela el determinente
  %       del  Jacobiano,  la   densidad  va   a  ser   divergente  (divergencia
  %     integrable).}}
 $\left| \Jac_g \right| > 0$,
  %
 donde $\Jac_g$ denota la  matriz de componentes \ $\frac{\partial g_i}{\partial
   x_j}$, \ matriz Jacobiana de  la transformaci\'on \ $g \equiv \begin{bmatrix}
   g_1(x_1 , \ldots , x_d) & \cdots & g_d(x_1 , \ldots , x_d) \end{bmatrix}^t$ \
 y \ $|\cdot|$ representa el valor absoluto del determinante de la matriz. Sea \
 $Y = g(X)$.   Entonces $Y$ es continua admitiendo  una densidad de probabilidad
 $p_Y$ de soporte $\Y = g(\X) = Y(\Omega)$ tal que
  %
  \[
  \forall \,  y \in  \Y, \quad p_Y(y)  = p_X(g^{-1}(y))  \left| \Jac_{g^{-1}}(y)
  \right|.
  \]
\end{teorema}
%
\begin{proof}
Por definici\'on, $X$ admitiendo una densidad y $g$ siendo medible,
%
\[
\forall \, B  \in \B(\Rset^d), \quad P_Y(B) =  P_X(g^{-1}(B)) = \int_{g^{-1}(B) \cap \X}
p_X(x) \, dx.
\]
%
Por cambio de variable $x =  g^{-1}(y)$ ($g$ siendo inyectiva, el antecedante es
\'unico por definic\'on) y notando de que $g\left( g^{-1}(B) \cap \X \right) = B
\cap \Y$,
%
\[
\forall \, B \in \B(\Rset^d), \quad  P_Y(B) = \int_{B \cap \Y} p_X(g^{-1}(y)) \,
\left| \Jac_{g^{-1}}(y) \right| \, dy
\]
%
lo que  cierra la prueba~\footnote{\modif{La  aparici\'on de la  Jacobiana viene
    del  mismo  enfoque  que el  cambio  de  variables  en la  integraci\'on  de
    Rieman. De hecho, como  lo hemos visto, $\mu_L(B) = |B|$ es  el volumen y de
    la definici\'on  mismo del determinente,  para cualquier matriz  cuadrada el
    volumen se escribe \ $\mu_L(M B) = |M  B| = |M| |B| = |M| \mu_L(B)$ donde la
    misma escritura  $|\cdot|$ representa el valor absoluto  del determinente de
    una matriz. Esta notaci\'on se justifica precisamente por su significaci\'on
    de volumen, y el resultado es inmediato para $g(x) = M x$. La forma general,
    para una transformaci\'on  m\'as general a partir de  un desarollo de Taylor
    al orden 1~\cite{AthLah06, Coh13}.}}.
\end{proof}

El caso escalar puede ser visto como caso particular, dando:
%
\begin{corolario}
  Sean  $X$,   variable  aleatoria  continua   y  admitiendo  una   densidad  de
  probabilidad $p_X$, $g:\Rset \mapsto  \Rset$ una funci\'on continua, inyectiva
  y  diferenciable e  \ $Y  = g(X)$.   Entonces $Y$  es continua  admitiendo una
  densidad de probabilidad $p_Y$ tal que
  %
  \[
  \forall  \,   y  \in  \Y,   \quad  p_Y(y)  =  p_X(g^{-1}(y))   \left|  \frac{d
      g^{-1}(y)}{dy} \right|.
  \]
\end{corolario}
%
\noindent  De hecho,  se puede  ver estos  resultados esquematicamente  como una
``conservaci\'on'' de  probabilidad, $p_X(x)  dx = p_Y(y)  dy$, el  volumen $dy$
siendo  relacionado  al  $dx$ a  traves  de  la  Jacobiana \modif{(ver  nota  de
  pie~\ref{foot:SZ:Jacobiana})}.

Una forma alternativa de derivar  este \modif{corrolario consiste a salir} de la
funci\'on   de   repartici\'on,   notando   de   que   $g$   es   necesariamente
monotona~\footnote{Fijense de que $P(X \ge x) = 1 -  P(X < x) = 1 - P(X \le x) +
  P(X =  x)$, pero $X$ siendo  continua, $ P(X =  x) = 0$.}: si  $y \not\in \Y$,
necesariamente $p_Y = 0$ ($F_Y(y) = 1$ \ si \ $y > \sup \Y$ \ y \ $F_Y(y) = 0$ \
si \ $y < \inf \Y$) \ y para cualquier \ $y \in \Y$,
%
\[
F_Y(y) = P(Y \le y) = P(g(X) \le y) =
\left\{\begin{array}{lll}
P(X \le g^{-1}(y)) = F_X(g^{-1}(y)) & \mbox{si} & g \quad \mbox{es creciente}\\[2.5mm]
%
P(X \ge g^{-1}(y)) = 1 - F_X(g^{-1}(y)) & \mbox{si} & g \quad \mbox{es decreciente}
\end{array}\right..
\]
%
El  resultado  se  obtiene  calculando  las  derivadas  del  primer  y  \'ultimo
t\'erminos respecto de la variable transformada $y$.

Si $g$ no es inyectiva, $g^{-1}$  es multivaluada o multiforme. En este caso, se
puede todav\'ia  tratar el problema, particionando $\Rset^d$  en conjuntos donde
$g$ es inyectiva, dando
%
\begin{teorema}
  Sean $X$, vector aleatorio  $d$-dimensional continuo y admitiendo una densidad
  de  probabilidad   $p_X$,  $g:(\Rset^d  ,  \B(\Rset^d))   \mapsto  (\Rset^d  ,
  \B(\Rset^d))$  una  funci\'on continua  y  diferenciable.  Denotamos  $\left\{
    \X_{[k]} \right\}_{k=0}^m$ la partici\'on  de $\X$ tal que $\left| \Jac_g(y)
  \right| = 0$ sobre  $\X_{[0]}$ y para todos $k \ge 1$,  \ $g: \X_{[k]} \mapsto
  \Y$ \ sea inyectiva y tal que \ $\left| \Jac_g(y) \right| > 0$. \ Suponemos de
  que  $\X_{[0]}$ sea  de medida  de Lebesgue  nula, notamos  \ $g_k^{-1}$  \ la
  funci\'on inversa de  \ $g$ \ sobre \ $g(\X_{[k]})$ \  (rama $k$-\'esima de la
  funci\'on multivaluada $g^{-1}$), \  $\Jac_{g_k^{-1}}$ \ su matriz Jacobiana y
  \ $I(y) = \{ k, \: y \in g(\X_{[k]}) \}$ \ los indices tales que \ $y$ \ tiene
  un      inverso     por      $g_k$.      Eso      es      ilustrado     figura
  Fig.~\ref{fig:MP:TransformacionVA}  para $d  = 1$.   Entonces $Y$  es continua
  admitiendo una densidad de probabilidad $p_Y$ tal que
  %
  \[
  \forall  \, y  \in \Y,  \quad p_Y(y)  = \sum_{k  \in  I(y)} p_X(g_k^{-1}(y))
  \left| \Jac_{g_k^{-1}}(y) \right|.
  \]
  %
  En el caso escalar $d = 1$ eso se formula
  %
  \[
  \forall \, y \in \Y, \quad  p_Y(y) = \sum_{k \in I(y)} p_X(g_k^{-1}(y)) \left|
    \frac{d g_k^{-1}(y)}{dy} \right|.
  \]
\end{teorema}
%
\begin{proof}
  Sufice escribir  \ $B  = \bigcup_{k =  0}^m \left(  B \cap g(\X_k)  \right)$ \
  uni\'on de borelianos disjuntos, notar  de que por consecuencia \ $g^{-1}(B) =
  \bigcup_{k =0}^m g^{-1}\left( B \cap  g(\X_k) \right)$ \ uni\'on de borelianos
  disjuntos \  y \  por linearidad escribir  la integraci\'on  sobre $g^{-1}(B)$
  como la  suma de  integrales sobre $g^{-1}\left(  B \cap g(\X_k)  \right)$. Se
  cierra la  prueba notando de  que \ $g^{-1}\left(  B \cap g(\X_0)  \right)$ es
  necesario  de medida de  Lebesgue nula,  siendo la  integral nula  y de  que \
  $g^{-1}\left( B \cap g(\X_k) \right) = g_k^{-1}\left( B \cap g(\X_k) \right)$.
\end{proof}
%

\begin{ejemplo}[Ejemplo de transformaci\'on no biyectiva]
  Sea $X$ definido sobre  \ $\X = \Rset$ \ y la  transformaci\'on de variables \
  $Y = X^2$.   Se tiene \ $y  = g(x) = x^2$, continua  diferenciable de derivada
  nula  sobre \  $\X_{[0]} =  \{ 0  \}$, de  medida nula,  cuyas inversas  son \
  $g_1^{-1}(y) = \sqrt{y}$ \ sobre \ $\X_{[1]} = \Rset_-^*$ \ y \ $g_2^{-1}(y) =
  -   \sqrt{y}$  sobre   \   $\X_{[2]}   =  \Rset_+^*$;   luego   \  $p_Y(y)   =
  \frac{p_X(\sqrt{y})  +   p_X(-\sqrt{y})}{2  \sqrt{y}}$,   \  sobre  \   $\Y  =
  \Rset_+^*$.
\end{ejemplo}

De nuevo, en el caso escalar, se puede salir de la funci\'on de repartici\'on
%
\[
F_Y(y) =  P(Y \le y) = P(  g(X) \le y )  = \sum_{k=1}^m P\left( X  \in \X_{[k]} \cap
  g_k^{-1}(-\infty \, ; \, y] \right)
\]
%
($\X_{[0]}$  siendo  de medida  nula,  sobre  este  dominio la  probabilidad  es
cero). Sea $\Y_{[k]} = g_k(\X_{[k]})$. Ahora, si $y \not\in I(y)$,
%
\[
P\left(   X   \in  \X_k   \cap   g_k^{-1}(-\infty  \,   ;   \,   y]  \right)   =
\left\{\begin{array}{lll}
%
P(X \in \X_{[k]}) & \mbox{si} & y > \sup \Y_{[k]}\\[2.5mm]
%
0 & \mbox{si} & y < \inf \Y_{[k]}\\[2.5mm]
\end{array}\right.
\]
%
dando una derivada nula. Si $y \in I(y)$,
%
\[
P\left(   X   \in  \X_k   \cap   g_k^{-1}(-\infty  \,   ;   \,   y]  \right)   =
\left\{\begin{array}{lll}
%
F_X(g_k^{-1}(y)) - F_X(\inf \Y_{[k]}) & \mbox{si} & g_k \quad \mbox{es creciente}\\[2.5mm]
%
F_X(\sup \Y_{[k]}) - F_X(g_k^{-1}(y))  & \mbox{si} & g_k \quad \mbox{es decreciente}
\end{array}\right..
\]
%
El  resultado  sigue  diferenciando  este  resultado. Eso  es  ilustrado  figura
Fig.~\ref{fig:MP:TransformacionVA}.

\begin{figure}[h!]
\begin{center} \input{TIKZ_MP/TransformacionVA} \end{center}
%
\leyenda{(a): Ilustraci\'on  de una transformaci\'on  $g$ no inyectiva,  tal que
  $\X_{[0]} = \{ x, \: g'(x) = 0 \}$, representado por las lineas punteadas ($x$
  correspondiente), es de medida de  Lebesgue nula.  Los $\X_{[k]}$ son descrito
  debajo de cada dominio.  La linea discontinua  da un nivel $y$ y los puntos en
  el eje $x$ representan $g_k^{-1}(y), \: k \in I(y)$; en el ejemplo, $I(y) = \{
  1  \,  ;  \,  2 \}$  \  y,  suponiendo  de  que  $\X  = \Rset$,  \  $F_Y(y)  =
  F_X(g_1^{-1}(y)) + 1-F_X(g_2^{-1}(y))$.}
\label{fig:MP:TransformacionVA}
\end{figure}

Una  tercera alternativa,  a pesar  que sea  delicado, es  de apoyarse  sobre la
teoria de las  distribuciones y expresar como \  $\displaystyle p_Y(y) = \int_\X
p_X(x) \,  \delta(y-g(x)) \, dx$,  donde se usa  la expansi\'on de  la funci\'on
delta  en  t\'erminos de  sus  ceros:  \  $\delta(y-g(x)\,)= \sum_{k  \in  I(y)}
\frac{1}{\left|      g_k'\left(      g_k^{-1}      (y)     \right)      \right|}
\delta(x-g_k^{-1}(y))$~\cite{ManWol95}.

Es  importante  notar  de  que  la  condici\'on $\X_{[0]}$  de  medida  nula  es
importante. El el caso contrario,  $Y$ no queda continua \modif{como se lo puede ver en el ejemplo siguiente}.
%
\begin{ejemplo}[Transformaci\'on con $\mu_L\left( \X_{[0]} \right) \ne 0$]
  Sea \ $X$ \  uniforme sobre \ $\X = ( 3 \,  ; \, 3)$ \ y \ $Y  = g(X)$ \ con \
  $g(x) = \left( 1 + \cos\left( (|x|-1) \frac{\pi}{2} \right) \right) \un_{(1 \,
    ; \,  3)}(|x|) + 2 \un_{[0  \, ; 1]}(|x|)$.  Esta  funci\'on es representado
  figura Fig.~\ref{fig:MP:TransformacionVANoContinua}-(a).   Claramente, \ $g$ \
  es continua y  diferenciable sobre $\X$, pero con  \ $\X_{[0]} = [ -1  \, ; \,
  1]$ que no es de medida nula.  Saliendo de $F_Y(y) = P(g(X) \le y)$ se calcula
  sencillamente  $F_Y(y) =  \frac23 \left(  1 -  \frac1\pi  \arccos(y-1) \right)
  \un_{[0  \, ;  \,  2)} +  \un_{[ 2  \,  ; \,  +\infty)}(y)$, ilustrada  figura
  Fig.~\ref{fig:MP:TransformacionVANoContinua}-(b).   Claramente  \  $F_Y$ \  es
  discontinua en \ $y = 2$: \ $Y$ \ no es continua.
  %
  \begin{figure}[h!]
  \begin{center} \input{TIKZ_MP/TransformacionVANoContinua} \end{center}
  %
  \leyenda{En (a) se dibuja $g(x)  = \left( 1 + \cos\left( (1-|x|) \frac{\pi}{2}
      \right)   \right)  \un_{(1   \,  ;   \,  3)}(|x|)   +  2   \un_{[0   \,  ;
      1]}(|x|)$. Suponiendo de que $\X = (-3 \, ; \, 3)$, claramente $\X_{[0]} =
    [ -1 \, ; \, 1]$ no es de medida nula, dando para $X$ uniforme sobre $\X$ la
    variable $Y = g(X)$ no  continua de funci\'on de repartici\'on representenda
    en (b).  }
  \label{fig:MP:TransformacionVANoContinua}
  \end{figure}
\end{ejemplo}

\modif{Un  ejemplo de  cambio  de  transformaci\'on puede  sevir  a calcular  la
  densidad de probabilidad de una suma:
%
\begin{ejemplo}[Distribuci\'on de la suma de vectores aleatorios]\label{Ej:MP:Suma}
  Sean \  $X$ \ e  \ $Y$ \  dos vectores aleatorios conjuntamente  continuos, de
  densidad de  probabilidad conjunta $p_{X,Y}$,  y sea el  vector \[V = X  + Y.\]
  Queremos calcular la a partir de la densidad de probabilidad de $V$.  Por eso,
  se puede considerar la transformaci\'on biyectiva
  %
  \[
  g: (x,y) \mapsto (u,v) = (x,x+y).
  \]
  %
  Entonces
  %
  \[
  g^{-1}(u,v) = (u,v-u)
  \]
  %
  y la matriz Jacobiana es
  %
  \[
  J_{g^{-1}} = \begin{bmatrix} I & -I \\ 0 & I \end{bmatrix}
  \]
  %
  donde $I$ es la matriz identidad $d$-dimensional y $0$ la matriz nula de misma
  dimension. Claramente\ $\left| J_{g^{-1}} \right| = 1$ \ as\'i que
  %
  \[
  p_{U,V}(u,v) = p_{X,Y}(u,v-u)
  \]
  %
  como lo pudimos intuir. Adem\'as, por marginalizaci\'on, inmediatamente
  %
  \[
  p_V(v) = \int_{\Rset^d} p_{X,Y}(u,v-u) \, du.
  \]
  %
  Si \ $X$ \ e \ $Y$  \ son independientes, \ $p_{U,V}(u,v) = p_X(u) p_V(v-u)$ \
  y la f\'ormula integral se escribe
  %
  \[
  p_V(v) = \int_{\Rset^d} p_X(u) p_Y(v-u) \, du = \int_{\Rset^d} p_Y(u) p_X(v-u)
  \, du
  \]
  %
  (por cambio de  variable en la secunda expresi\'on).  Esta f\'ormula es conocida
  como {\it producto de convoluci\'on} entre las funciones~\footnote{\modif{Este
      producto no impone  de que las funciones sean  densidades de probabilidad.
      Una condici\'on suficiente para que existe es que las funciones sean $L^1$
      (ver desigualdad de Cauchy-Bunyakovsky-Schwarz).}} $p_X$ y $p_Y$.
\end{ejemplo}
}


%|q(y^1,\ldots,y^d)\ dy^1\cdots dy^d| = |p(x^1,\ldots,x^d) \ dx^1\cdots dx^d| .

%% Ejercicio: Estudiar el caso multivaluado / Resolver un ej. 

\

\aver{\SZ{No toque todav\'ia. Se puede hacerlo con vectores. Caso circular\ldots}

\hfill

Una  \emph{variable  aleatoria  compleja}   $Z=X+i  Y$  puede  interpretarse  en
t\'erminos de las  dos variables aleatorias reales $X$ e $Y$.  La pdf asociada \
$P(z)=p(x,y)$ est\'a dada por la  funci\'on densidad de probabilidad conjunta de
las variables reales. La condici\'on de normalizaci\'on se escribe
%
$$
\int P(z) \, d^2 z = 1
$$
%
donde $d^2 z=dx\,dy$.
}


% ================================= Vector discreto

\modif{
\subseccion{Leyes condicionales}
\label{sec:MP:LeyesCondicionales}

Tratando de un par de vectores aleatorios  \ $X$ \ e \ $Y$, una pregunta natural
puede ser de caracterizar el vector  $Y$ si ``observamos $X = x$''. En palabras,
la pregunta es de describir la ley de $Y$ ``sabiendo de que $X = x$''. En lo que
sigue, para  fijar las notaciones, consideramos  $(X,Y): ( \Omega  , \A) \mapsto
(\Rset^{d_X} \! \times \Rset^{d_Y} \, , \, \B(\Rset^{d_X} \! \times \Rset^{d_Y})
)$ tal que $X$ sea $d_X$-dimensional e $Y$ sea $d_Y$-dimensional (incluyendo los
casos escalares).


% ---------- Caso discreto

\paragraph{Caso $\boldsymbol{X}$ discreto:}
Un caso  sencillo a estudiar  es cuando $\X  = X(\Omega)$ es discreto.   En este
caso, para  cualquier $x  \in \X$, tenemos  $P_X(x) = P(X  = x)  \ne 0$ y  de la
definici\'on de  la probabilidad condicional Def.~\ref{def:MP:ProbaCondicional},
$P(Y \in A | X = x) = \frac{P(Y \in A \cap X = x)}{P(X=x)}$ define una medida de
probabilidad que llamamos medida de probabilidad condicional y que notaremos
%
\[
P_{Y|X=x}(A) = P(Y \in A | X = x).
\]
%
Siendo una medida de probabilidad, se puede referirse a la subsecci\'on anterior
para  definir  una  funci\'on   de  repartici\'on  tomando  $\displaystyle  A  =
\prod_{i=1}^d (-\infty \, ; \,  y_i]$, caracterisando completamento la medida de
probabilidad:
%
\begin{definicion}[Funci\'on de repartici\'on condicional ($X$ discreto)]
  Por definici\'on, la funci\'on de repartici\'on condicional es,
  %
  \[
  \forall \:  x \in  \X, \: y  \in \Y, \quad  F_{Y|X=x}(y) =  P( \left. Y  \le y
  \right|  X =  x  ) =  \frac{P\left(Y  \le y  \cap X  =  x \right)}{P\left(X  =
      x\right)}.
  \]
\end{definicion}

Ahora, cuando $Y$ est discreta tambi\'en,  se puede definir la funci\'on de masa
discreta  de probabilidad,  y  si $Y$  es  continua admitiendo  una densidad  de
probabilidad, se puede definir una densidad de probabilidad condicional:
%
\begin{definicion}[Funci\'on de masa o densidad de probabilidad condicional ($X$
  discreto)]
  Por  definici\'on,  cuando  $\Y$  est   discreto,  la  funci\'on  de  masa  de
  probabilidad condicional es,
  %
  \[
  \forall \:  x \in  \X, \: y  \in \Y, \quad  p_{Y|X=x}(y) =  P( \left. Y  = y
  \right|  X =  x  ) =  \frac{P\left(Y  = y  \cap X  =  x \right)}{P\left(X  =
      x\right)}.
  \]
  %
  Si $Y$ es continua, es sencillo  ver de que $P_{Y|X=x} \ll P_Y$, i.e., $P_Y(B)
  = 0  \: \Rightarrow  \: P_{Y|X=x}(B) =  0$.  Si  $Y$ adminte una  densidad con
  respeto a la medida de Lebesgue,  $P_Y \ll \mu_L$ medida de Lebesgue, es claro
  de    que   tambi\'en   $P_{Y|X=x}    \ll   \mu_L$,    y   por    teorema   de
  Radon-Nikod\'ym~\ref{Th:MP:RadonNikodym}, admite  una densidad de probabilidad
  (con respeto a la medida de Lebesgue) que denotaremos $p_{Y|X=x}$,
  %
  \[
  \forall \: B, \quad P_{Y|X=x}(B) = \int_B p_{Y|X=x}(y) \, dy.
  \]
  %
  Saliendo de la funci\'on de repartici\'on, obtenemos
  %
  \[
  p_{Y|X=x}(y) = \frac{\partial^{d_Y} F_{Y|X=x}(y)}{\partial y_1 \ldots \partial
    y_{d_Y}}.
  \]
\end{definicion}


% ---------- Caso continuo

\paragraph{Caso $\boldsymbol{X}$ continuo admitiendo una densidad:}
Cuando  $X$ es  continuo, el  problema aparece  m\'as subtile  porque  $P(X=x) =
0$. Entonces, no  se puede usar la definici\'on  de la probabilidad condicional,
el evento $(X=x)$ siendo de probabilidad cero.  Sin embargo, se puede seguir los
pasos  de  R\'enyi~\cite[Cap.~5]{Ren} por  ejemplo  para  resolver el  problema,
llegando a un resultado tan intuitivo que en el caso discreto.

Por eso, sea $B \in \B(\Rset^{d_Y})$ y definimos la medida $\nu_B(A) = P(X \in A
\cap Y  \in B)$ sobre  $(\Rset^{d_Y},\B(\Rset^{d_Y}))$.  Es sencillo ver  de que
$B$ siendo dado, $\nu_B$ define una medida de probabilidad. Adem\'as, $\nu_B \ll
P_X$, i.e., $P_X(A) = P(X \in A) = 0  \: \Rightarrow \: 0 = P(X \in A \cap Y \in
B)  =  \nu_B(A)$.    Por  teorema  de  Radon-Nikod\'ym~\ref{Th:MP:RadonNikodym},
$\nu_B$ admite una densidad $g_B$ con respeto a $P_X$,
%
\[
\forall \: A, \quad P\left( (X \in A)  \cap (Y \in B) \right) = \int_A g_B(x) \,
dP_X(x).
\]
%
Claramente \ $g_B \ge 0$,  \ y de \ $P(X \in A) = P\left(  (X \in A) \cap (Y \in
  B) \right) + P\left(  (X \in A) \cap (Y \in B)  \right)$, \ie $\displaystyle 0
\le P\left( (X \in A) \cap (Y \in B) \right) = \int_A dP_X(x) - \int_A g_B(x) \,
dP_X(x)$, se obtiene \ $0 \le g_B \le  1$.  En realidad, tenemos \ $g_B \le 1$ \
$P_X$-casi  siempre, pero olvidando  esta subtilesa,  llamaremos la  funci\'on \
$g_B$ \ medida  de probabilidad condicional y, por  continuaci\'on, la funci\'on
de repartici\'on condicional:
%
\begin{definicion}[Medida   de  probabilidad   y   funci\'on  de   repartici\'on
  condicional ($X$ continuo)]\label{Def:MP:FRCondicional}
  La medida de probabilidad condicional de $P_{Y|X=x}$ es definida tal que
  %
  \[
  \forall \: A \in \X, B \in \Y,  \quad P\left( (X \in A) \cap (Y \in B) \right)
  = \int_A P_{Y|X=x}(B) \, dP_X(x).
  \]
  %
  Tomando $B  = \optimes_i  (-\infty \, ;  \, y_i]$  se obtiene la  funci\'on de
  repartici\'on condicional a partir de
  %
  \[
  \forall \: A \in \X, y \in \Y, \quad P\left (X \in A) \cap (Y \le y) \right) =
  \int_A F_{Y|X=x}(y) \, dP_X(x).
  \]
  %
  Ad\'emas, si $X$ admite una densidad  de probabilidad $p_X$, $dP_X = p_X dx$ y
  tomando $A = \optimes_i (-\infty \, ; \, x_i]$ se obtiene
  %
  \[
  F_{X,Y}(x,y) = \int_{\optimes_i (-\infty \,  ; \, x_i]} F_{Y|X=x}(y) \, p_X(x)
  \, dx
  \]
  %
  o, por diferenciaci\'on, para cualquier $y \in \Y$,
  %
  \[
  F_{Y|X=x}(y)   =  \frac{\frac{\partial^{d_X}}{\partial  x_1   \ldots  \partial
      x_{d_X}} F_{X,Y}(x,y)}{p_X(x)}.
  \]
\end{definicion}
%
\noindent Nota: Tomando $A = \X$,  de la primera f\'ormula definiendo la medida de
probabilidad condicional  se recupera el \underline{equivalente  continuo} de la
\underline{f\'ormula de probabilidad total}, que  se escribe con la densidad $dP_X
= p_X d\mu_L$ si $X$ admite una densidad.

Al final, si $(X,Y)$ admite una  densidad, en sencillo ver de que $P_{Y|X=x} \ll
\mu_L$,  y entonces  \ $P_{Y|X=x}$  \ admite  una densidad  que  llamaremos {\it
  densidad de probabilidad condicional}. Sean $A \in \B(\X)$ y $B$,
%
\begin{eqnarray*}
P\left( (X \in A) \cap (Y \in B) \right) & = & \int_{A \times B} p_{X,Y}(x,y) \, dx \, dy\\[2mm]
%
& = & \int_B \left( \int_A \frac{p_{X,Y}(x,y)}{p_X(x)} \, dy \right) p_X(x) \, dx
\end{eqnarray*}
%
Entonces, desde de que $p_X(x) \ne 0$, tenemos
%
\[
P_{Y|X=x}(A) = \int_A \frac{p_{X,Y}(x,y)}{p_X(x)} \, dy.
\]
%
\begin{teorema}[Densidad de probabilidad condicional]
  Si  $(X,Y)$ admite  una densidad  de probabilidad,  la medida  de probabilidad
  condicional  $P_{Y|X=x}$  admite  una   densidad,  llamada  {\it  densidad  de
    probabilidad condicional} definida por
  %
  \[
  \forall \: x \in \X, \quad p_{Y|X=x}(y) = \frac{p_{X,Y}(x,y)}{p_X(x)}
  \]
  %
  definida  sobre $\Y$. Claramente,  saliendo de  la funci\'on  de repartici\'on
  condicional, aparece de que
  %
  \[
  p_{Y|X=x} = \frac{\partial^{d_Y}}{\partial y_1 \ldots \partial y_{d_Y}} F_{Y|X=x}.
  \]
\end{teorema}

De hecho, esta  construcci\'on rigurosa coincide con la  intuici\'on que podemos
tener en este  caso continuo. Por ejemplo, podemos  pensar a $F_{Y|X=x}(y)$ como
caso limite de  $P(\left. Y \le y \right|  x \le X \le x+\delta x)  = \frac{P( Y
  \le  y \:  \cap \:  x \le  X \le  x+\delta x)}{P(x  \le X  \le x+\delta  x)} =
\frac{F_{X,Y}(x+\delta  x ,  y) -  F_{X,Y}(x  , y)}{F_X(x+\delta  x) -  F_X(x)}$
cuando \ $\delta  x$ \ tiende a 0.   En el caso escalar, se  calcula por ejemplo
haciendo un  desarollo de Taylor del numerador  y del denominador al  orden 1, o
usando la  regla de l'H\^opital~\footnote{\modif{De hecho, esta  regla es debido
    al  suizo J.   Bernoulli que  tuvo un  acuerdo financiero  con  el Guillaume
    Fran\c{c}ois  Antoine, marqu\'es de  l'H\^opital, permitiendolo  de publicar
    unos resultados de Bernoulli bajo su nombre.}}  para re-obtener la funci\'on
de        repartici\'on       condicional        de        la       definici\'on
Def.~\ref{Def:MP:FRCondicional}. En  el caso multivariado, hace  falta hacer los
desarollos hasta el orden $d_X$ para concluir.

Fijense de  que:
%
\begin{itemize}
\item si $X$ e $Y$ son independientes,
  %
  \[
  p_{Y|X=x} = p_Y;
  \]
%
\item por  la expresi\'on \ $p_{Y|X=x}(y) =  \frac{p_{X,Y}(x,y)}{p_X(x)}$, \ por
  integraci\'on con respeto a $y$ obtenemos la condici\'on de normalizaci\'on
  %
  \[
  \int_{\Rset^{d_Y}} p_{Y|X=x}(y) \, dy = 1;
  \]
%
\item escribiendo  \ $p_{X,Y}(x,y)  = p_{Y|X=x}(y) \,  p_X(x) =  p_{X|Y=y}(x) \,
  p_Y(y)$, \ se obtiene
  %
  \[
  p_{Y|X=x}(y)   =  \frac{p_{X|Y=y}(x) \,   p_Y(y)}{p_X(x)}   =  \frac{p_{X|Y=y}(x)
    \, p_Y(y)}{\displaystyle \int_{\Rset^{d_Y}} p_{X|Y=y}(x) \, p_Y(y) \, dy},
  \]
  %
  equivalente continuo, con densidades, de la f\'ormula de Bayes;
%
\item  por la  expresi\'on  \ $p_{X,Y}(x,y)  =  p_{Y|X=x}(y) \,  p_X(x)$, \  por
  integraci\'on con respeto a $x$ obtenemos
  %
  \[
  p_Y(y) = \int_{\Rset^{d_X}} p_{Y|X=x}(y) \, p_X(x) \, dx,
  \]
  %
  generalizaci\'on de la f\'ormula de  probabilidades totales al caso continuo con
  densidad de probabilidad.
\end{itemize}

Volvemos al ejemplo~\ref{Ej:MP:Suma}, pagina~\pageref{Ej:MP:Suma}:
\begin{ejemplo}[Distribuci\'on condicional de la suma de vectores aleatorios]\label{Ej:MP:SumaCond}
  Sea   \   $V  =   X   +   Y$,  \   con   \   $X$  \   e   \   $Y$  \   vecores
  $d$-dimensionales.  Introduciendo \  $U =  X$  \ obtuvimos  \ $p_{U,V}(u,v)  =
  p_{X,Y}(u,v-u)$  \ dando  tambi\'en \  $\displaystyle p_V(v)  = \int_{\Rset^d}
  p_{X,Y}(u,v-u) \, du$. Entonces, recordandose de que $U = X$, se obtiene
  %
  \[
  p_{V|X=x}(v)            =            \frac{p_{X,Y}(x,v-x)}{p_X(x)}           =
  \frac{p_{X,Y}(x,v-x)}{\displaystyle \int_{\Rset^d} p_{X,Y}(x,v-x) \, dv},
  \]
  %
  dando en el caso \ $X$ \ e \ $Y$ \ \underline{independientes}
  %
  \[
  p_{V|X=x}(v) = p_Y(v-x).
  \]
  %
  Eso corresponde a  la intuci\'on de que, con $V  = X + Y$, fijando  $X = x$ el
  vector aleatorio $V$  es nada mas que $Y$  desplazado de $x$. \underline{Pero}
  hay que  tomar \underline{muchas  precauciones} con este  razonamiento, valide
  \'unicamente  porque  \ $X$  \  e  \ $Y$  \  son  independiente.   En el  caso
  contrario, fijando  $X$ no coincide  con un desplazamiento por  la dependencia
  (esquemat\'icamente, fijando  $X$ no s\'olo mueve  \ $Y$ \  pero ``cambia'' su
  estad\'istica).
\end{ejemplo}

  }


